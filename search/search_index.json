{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"GenJAX","text":"<p>GenJAX is a JAX-based probabilistic programming language that provides a Generative Function Interface (GFI) for writing and composing probabilistic models with programmable inference.</p>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>import jax\nimport jax.numpy as jnp\nfrom genjax import gen, distributions\n\n@gen\ndef coin_flips(n):\n    p = distributions.beta(1.0, 1.0) @ \"bias\"\n    for i in range(n):\n        distributions.bernoulli(p) @ f\"flip_{i}\"\n    return p\n\n# Run inference\nkey = jax.random.PRNGKey(0)\ntrace = coin_flips.simulate(key, (10,))\nprint(f\"Inferred bias: {trace.retval}\")\n</code></pre>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Composable Models: Build complex models from simple components</li> <li>JAX Integration: Leverage JAX's JIT compilation and automatic differentiation</li> <li>Programmable Inference: Combine different inference algorithms seamlessly</li> <li>Pytree Compatible: All GenJAX types work with JAX transformations</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<ul> <li>Installation - Install GenJAX and its dependencies</li> <li>Quick Start - Dive into your first GenJAX program</li> <li>Tutorial - Learn GenJAX concepts step by step</li> </ul>"},{"location":"#learn-more","title":"Learn More","text":"<ul> <li>Core API - Understand the Generative Function Interface</li> <li>Inference Algorithms - Explore MCMC, SMC, and VI</li> <li>Examples - See GenJAX in action</li> </ul>"},{"location":"api/distributions/","title":"Distributions","text":"<p>GenJAX provides a comprehensive set of probability distributions that implement the Generative Function Interface. All distributions can be used directly in <code>@gen</code> functions with the <code>@</code> addressing operator.</p>"},{"location":"api/distributions/#continuous-distributions","title":"Continuous Distributions","text":""},{"location":"api/distributions/#normal-gaussian","title":"Normal (Gaussian)","text":"<pre><code>from genjax import normal\n\n# Standard normal\nx = normal(0, 1) @ \"x\"\n\n# With parameters\ny = normal(mu=5.0, sigma=2.0) @ \"y\"\n\n# In a model\n@gen\ndef model():\n    mean = normal(0, 10) @ \"mean\"\n    data = normal(mean, 1) @ \"data\"\n    return data\n</code></pre> <p>Parameters: - <code>mu</code>: Mean (location parameter) - <code>sigma</code>: Standard deviation (scale parameter, must be positive)</p>"},{"location":"api/distributions/#beta","title":"Beta","text":"<pre><code>from genjax import beta\n\n# Beta(2, 5)\np = beta(2, 5) @ \"probability\"\n\n# Uniform prior (Beta(1, 1))\nuniform_p = beta(1, 1) @ \"uniform\"\n</code></pre> <p>Parameters: - <code>alpha</code>: First shape parameter (must be positive) - <code>beta</code>: Second shape parameter (must be positive)</p> <p>Support: [0, 1]</p>"},{"location":"api/distributions/#gamma","title":"Gamma","text":"<pre><code>from genjax import gamma\n\n# Gamma(shape=2, rate=1)\nx = gamma(2, 1) @ \"x\"\n\n# For inverse scale parameterization\n# Gamma(shape=\u03b1, scale=1/\u03b2) has mean \u03b1/\u03b2\nprecision = gamma(1, 1) @ \"precision\"\n</code></pre> <p>Parameters: - <code>shape</code>: Shape parameter \u03b1 (must be positive) - <code>rate</code>: Rate parameter \u03b2 (must be positive)</p> <p>Support: (0, \u221e)</p>"},{"location":"api/distributions/#exponential","title":"Exponential","text":"<pre><code>from genjax import exponential\n\n# Exponential with rate 2.0\nwaiting_time = exponential(2.0) @ \"wait\"\n\n# Mean = 1/rate, so rate=0.1 gives mean=10\nlong_wait = exponential(0.1) @ \"long_wait\"\n</code></pre> <p>Parameters: - <code>rate</code>: Rate parameter \u03bb (must be positive)</p> <p>Support: [0, \u221e)</p>"},{"location":"api/distributions/#uniform","title":"Uniform","text":"<pre><code>from genjax import uniform\n\n# Uniform on [0, 1]\nu = uniform(0, 1) @ \"u\"\n\n# Uniform on [-5, 5]  \nx = uniform(-5, 5) @ \"x\"\n</code></pre> <p>Parameters: - <code>low</code>: Lower bound - <code>high</code>: Upper bound (must be greater than low)</p> <p>Support: [low, high]</p>"},{"location":"api/distributions/#dirichlet","title":"Dirichlet","text":"<pre><code>from genjax import dirichlet\nimport jax.numpy as jnp\n\n# Symmetric Dirichlet\nprobs = dirichlet(jnp.ones(3)) @ \"probs\"\n\n# Asymmetric Dirichlet\nalphas = jnp.array([1.0, 2.0, 3.0])\nweights = dirichlet(alphas) @ \"weights\"\n</code></pre> <p>Parameters: - <code>alpha</code>: Concentration parameters (array, all elements must be positive)</p> <p>Support: Simplex (sums to 1)</p>"},{"location":"api/distributions/#multivariate-normal","title":"Multivariate Normal","text":"<pre><code>from genjax import multivariate_normal\nimport jax.numpy as jnp\n\n# 2D standard normal\nx = multivariate_normal(\n    jnp.zeros(2), \n    jnp.eye(2)\n) @ \"x\"\n\n# With correlation\nmean = jnp.array([1.0, 2.0])\ncov = jnp.array([[1.0, 0.5], \n                 [0.5, 2.0]])\ny = multivariate_normal(mean, cov) @ \"y\"\n</code></pre> <p>Parameters: - <code>mean</code>: Mean vector - <code>cov</code>: Covariance matrix (must be positive definite)</p>"},{"location":"api/distributions/#discrete-distributions","title":"Discrete Distributions","text":""},{"location":"api/distributions/#bernoulli","title":"Bernoulli","text":"<pre><code>from genjax import bernoulli\n\n# Fair coin\ncoin = bernoulli(0.5) @ \"coin\"\n\n# Biased coin\nbiased = bernoulli(0.7) @ \"biased\"\n\n# In a model\n@gen\ndef coin_flips(n):\n    p = beta(1, 1) @ \"bias\"\n    flips = []\n    for i in range(n):\n        flip = bernoulli(p) @ f\"flip_{i}\"\n        flips.append(flip)\n    return flips\n</code></pre> <p>Parameters: - <code>p</code>: Probability of success (must be in [0, 1])</p> <p>Support: {0, 1} (False, True)</p>"},{"location":"api/distributions/#categorical","title":"Categorical","text":"<pre><code>from genjax import categorical\nimport jax.numpy as jnp\n\n# Three categories with equal probability\nx = categorical(jnp.ones(3) / 3) @ \"x\"\n\n# With specified probabilities\nprobs = jnp.array([0.1, 0.3, 0.6])\ncategory = categorical(probs) @ \"category\"\n\n# In a mixture model\n@gen\ndef mixture(n_components):\n    weights = dirichlet(jnp.ones(n_components)) @ \"weights\"\n\n    # Assign to components\n    assignments = []\n    for i in range(n_data):\n        z = categorical(weights) @ f\"z_{i}\"\n        assignments.append(z)\n    return assignments\n</code></pre> <p>Parameters: - <code>probs</code>: Probability vector (must sum to 1)</p> <p>Support: {0, 1, ..., len(probs)-1}</p>"},{"location":"api/distributions/#poisson","title":"Poisson","text":"<pre><code>from genjax import poisson\n\n# Poisson with rate 3.0\ncount = poisson(3.0) @ \"count\"\n\n# Modeling count data\n@gen\ndef count_model(exposure):\n    rate = gamma(2, 1) @ \"rate\"\n    counts = []\n    for i in range(len(exposure)):\n        count = poisson(rate * exposure[i]) @ f\"count_{i}\"\n        counts.append(count)\n    return counts\n</code></pre> <p>Parameters: - <code>rate</code>: Rate parameter \u03bb (must be positive)</p> <p>Support: {0, 1, 2, ...}</p>"},{"location":"api/distributions/#flip","title":"Flip","text":"<p>Alias for Bernoulli with boolean output:</p> <pre><code>from genjax import flip\n\n# Equivalent to bernoulli but more intuitive for booleans\nif flip(0.8) @ \"success\":\n    reward = normal(10, 1) @ \"reward\"\nelse:\n    reward = normal(0, 1) @ \"reward\"\n</code></pre>"},{"location":"api/distributions/#using-distributions-outside-gen-functions","title":"Using Distributions Outside <code>@gen</code> Functions","text":"<p>All distributions implement the full GFI and can be used directly:</p> <pre><code># Direct sampling (requires explicit key)\nfrom genjax import seed\nimport jax.random as random\n\nkey = random.PRNGKey(0)\nsample = seed(normal.simulate)(key, mu=0, sigma=1)\n\n# Log probability\nlog_prob, _ = normal.assess({\"value\": 1.5}, mu=0, sigma=1)\n\n# Generate with constraints  \ntrace, weight = normal.generate({\"value\": 2.0}, mu=0, sigma=1)\n</code></pre>"},{"location":"api/distributions/#custom-distributions","title":"Custom Distributions","text":"<p>You can create custom distributions by implementing the GFI:</p> <pre><code>from genjax import Distribution\nimport jax.numpy as jnp\n\nclass Laplace(Distribution):\n    \"\"\"Laplace (double exponential) distribution.\"\"\"\n\n    def sample(self, key, loc, scale):\n        u = random.uniform(key, minval=-0.5, maxval=0.5)\n        return loc - scale * jnp.sign(u) * jnp.log(1 - 2 * jnp.abs(u))\n\n    def log_density(self, value, loc, scale):\n        return -jnp.log(2 * scale) - jnp.abs(value - loc) / scale\n\n# Use in a model\n@gen\ndef robust_regression(x):\n    # Laplace errors for robust regression\n    intercept = normal(0, 10) @ \"intercept\"\n    slope = normal(0, 5) @ \"slope\"\n\n    errors = []\n    for i in range(len(x)):\n        # Would need to register as GenJAX distribution\n        error = custom_laplace(0, 1) @ f\"error_{i}\"\n        errors.append(error)\n\n    return intercept + slope * x + jnp.array(errors)\n</code></pre>"},{"location":"api/distributions/#distribution-parameters","title":"Distribution Parameters","text":""},{"location":"api/distributions/#shape-conventions","title":"Shape Conventions","text":"<ul> <li>Scalar parameters: Single values (e.g., <code>normal(0, 1)</code>)</li> <li>Vector parameters: Use JAX arrays (e.g., <code>dirichlet(jnp.ones(3))</code>)</li> <li>Matrix parameters: For multivariate distributions (e.g., <code>multivariate_normal(mean, cov)</code>)</li> </ul>"},{"location":"api/distributions/#broadcasting","title":"Broadcasting","text":"<p>GenJAX distributions support JAX broadcasting:</p> <pre><code># Sample multiple values with different means\nmeans = jnp.array([0.0, 1.0, 2.0])\nx = normal(means, 1.0) @ \"x\"  # Shape: (3,)\n\n# Different means and sigmas\nsigmas = jnp.array([0.5, 1.0, 2.0])  \ny = normal(means, sigmas) @ \"y\"  # Shape: (3,)\n</code></pre>"},{"location":"api/distributions/#common-patterns","title":"Common Patterns","text":""},{"location":"api/distributions/#hierarchical-models","title":"Hierarchical Models","text":"<pre><code>@gen\ndef hierarchical():\n    # Global parameters\n    global_mean = normal(0, 10) @ \"global_mean\"\n    global_std = gamma(1, 1) @ \"global_std\"\n\n    # Group-level parameters\n    group_means = []\n    for g in range(n_groups):\n        group_mean = normal(global_mean, global_std) @ f\"group_{g}_mean\"\n        group_means.append(group_mean)\n\n    # Observations\n    for g in range(n_groups):\n        for i in range(n_obs_per_group):\n            obs = normal(group_means[g], 1.0) @ f\"obs_{g}_{i}\"\n</code></pre>"},{"location":"api/distributions/#prior-predictive-sampling","title":"Prior Predictive Sampling","text":"<pre><code>@gen\ndef model():\n    # Priors\n    theta = beta(2, 2) @ \"theta\"\n\n    # Likelihood\n    successes = 0\n    for i in range(n_trials):\n        if bernoulli(theta) @ f\"trial_{i}\":\n            successes += 1\n\n    return successes\n\n# Sample from prior predictive\ntrace = model.simulate()\nprior_predictive_sample = trace.get_retval()\n</code></pre>"},{"location":"api/distributions/#posterior-predictive","title":"Posterior Predictive","text":"<pre><code># After inference, use posterior samples\nposterior_trace = inference_algorithm(model, data)\ntheta_posterior = posterior_trace.get_choices()[\"theta\"]\n\n# Generate new predictions\n@gen\ndef predictive(theta):\n    predictions = []\n    for i in range(n_future):\n        pred = bernoulli(theta) @ f\"pred_{i}\"\n        predictions.append(pred)\n    return predictions\n\npred_trace = predictive.simulate(theta=theta_posterior)\n</code></pre>"},{"location":"api/generative-functions/","title":"Generative Functions","text":"<p>Generative functions are the core abstraction in GenJAX. They represent probabilistic computations that can be executed, scored, and manipulated through a unified interface.</p>"},{"location":"api/generative-functions/#creating-generative-functions","title":"Creating Generative Functions","text":""},{"location":"api/generative-functions/#the-gen-decorator","title":"The <code>@gen</code> Decorator","text":"<p>Transform regular Python functions into generative functions:</p> <pre><code>from genjax import gen, normal, bernoulli\n\n@gen\ndef weather_model(temp_yesterday):\n    # Sample today's temperature\n    temp_today = normal(temp_yesterday, 5.0) @ \"temp\"\n\n    # Determine if it rains based on temperature\n    rain_prob = 1 / (1 + jnp.exp(0.1 * (temp_today - 20)))\n    rains = bernoulli(rain_prob) @ \"rains\"\n\n    return {\"temperature\": temp_today, \"rains\": rains}\n</code></pre>"},{"location":"api/generative-functions/#addressing-random-choices","title":"Addressing Random Choices","text":"<p>Use the <code>@</code> operator to assign addresses to random choices:</p> <pre><code>@gen\ndef model():\n    # Simple address\n    x = normal(0, 1) @ \"x\"\n\n    # Hierarchical addresses\n    for i in range(3):\n        # Creates addresses: \"group_0\", \"group_1\", \"group_2\"\n        group_mean = normal(0, 1) @ f\"group_{i}\"\n\n        for j in range(5):\n            # Creates: \"obs_0_0\", \"obs_0_1\", ..., \"obs_2_4\"\n            obs = normal(group_mean, 0.1) @ f\"obs_{i}_{j}\"\n</code></pre> <p>Avoid Address Collisions</p> <p>Each address at the same level must be unique. GenJAX will raise an error if you reuse addresses:</p> <pre><code>@gen\ndef bad_model():\n    x = normal(0, 1) @ \"x\"\n    y = normal(1, 1) @ \"x\"  # Error: address \"x\" already used!\n</code></pre>"},{"location":"api/generative-functions/#the-generative-function-interface","title":"The Generative Function Interface","text":"<p>All generative functions implement these methods:</p>"},{"location":"api/generative-functions/#simulate","title":"simulate","text":"<p>Forward sampling from the generative function:</p> <pre><code># Without arguments\ntrace = model.simulate()\n\n# With arguments\ntrace = weather_model.simulate(temp_yesterday=25.0)\n\n# Access the trace\nchoices = trace.get_choices()\nreturn_value = trace.get_retval()\n</code></pre>"},{"location":"api/generative-functions/#assess","title":"assess","text":"<p>Evaluate the log probability density at given choices:</p> <pre><code>choices = {\n    \"temp\": 22.0,\n    \"rains\": True\n}\n\nlog_prob, retval = weather_model.assess(choices, temp_yesterday=25.0)\n# log_prob = log p(temp=22.0, rains=True | temp_yesterday=25.0)\n</code></pre>"},{"location":"api/generative-functions/#generate","title":"generate","text":"<p>Generate a trace with some choices constrained:</p> <pre><code># Observe that it rained\nconstraints = {\"rains\": True}\n\ntrace, weight = weather_model.generate(constraints, temp_yesterday=25.0)\n# weight = log p(rains=True, temp) / q(temp | rains=True)\n</code></pre> <p>The weight is the incremental importance weight, useful for: - Importance sampling - Particle filtering - MCMC acceptance probabilities</p>"},{"location":"api/generative-functions/#update","title":"update","text":"<p>Update an existing trace with new constraints:</p> <pre><code># Original trace\ntrace = weather_model.simulate(temp_yesterday=25.0)\n\n# Update with new observation\nnew_constraints = {\"rains\": False}\nnew_trace, weight, discard = weather_model.update(\n    trace, \n    new_constraints, \n    temp_yesterday=26.0  # Can also change arguments\n)\n</code></pre>"},{"location":"api/generative-functions/#regenerate","title":"regenerate","text":"<p>Selectively regenerate parts of a trace:</p> <pre><code>from genjax import sel\n\n# Regenerate only the temperature\nselection = sel(\"temp\")\nnew_trace, weight, discard = weather_model.regenerate(\n    trace,\n    selection,\n    temp_yesterday=25.0\n)\n</code></pre>"},{"location":"api/generative-functions/#composing-generative-functions","title":"Composing Generative Functions","text":""},{"location":"api/generative-functions/#calling-other-generative-functions","title":"Calling Other Generative Functions","text":"<pre><code>@gen\ndef prior():\n    mean = normal(0, 10) @ \"mean\"\n    std = gamma(1, 1) @ \"std\"\n    return mean, std\n\n@gen\ndef model(n_obs):\n    # Call another generative function\n    mean, std = prior() @ \"prior\"\n\n    # Use the results\n    observations = []\n    for i in range(n_obs):\n        obs = normal(mean, std) @ f\"obs_{i}\"\n        observations.append(obs)\n\n    return jnp.array(observations)\n</code></pre>"},{"location":"api/generative-functions/#using-fixed-values","title":"Using Fixed Values","text":"<p>Wrap deterministic values to preserve them during trace operations:</p> <pre><code>from genjax import Fixed\n\n@gen\ndef model_with_fixed():\n    # This value won't be regenerated\n    fixed_param = Fixed(1.0) @ \"param\"\n\n    # This can be regenerated\n    x = normal(fixed_param, 1.0) @ \"x\"\n\n    return x\n</code></pre>"},{"location":"api/generative-functions/#advanced-patterns","title":"Advanced Patterns","text":""},{"location":"api/generative-functions/#mixture-models","title":"Mixture Models","text":"<pre><code>@gen\ndef mixture_model(data):\n    # Mixture weights\n    weights = dirichlet(jnp.ones(3)) @ \"weights\"\n\n    # Component parameters\n    means = []\n    for k in range(3):\n        mean = normal(0, 10) @ f\"mean_{k}\"\n        means.append(mean)\n\n    # Assign data to components\n    for i, datum in enumerate(data):\n        component = categorical(weights) @ f\"z_{i}\"\n        obs = normal(means[component], 1.0) @ f\"obs_{i}\"\n</code></pre>"},{"location":"api/generative-functions/#recursive-models","title":"Recursive Models","text":"<pre><code>@gen\ndef geometric(p, max_depth=100):\n    \"\"\"Sample from geometric distribution recursively.\"\"\"\n    flip = bernoulli(p) @ f\"flip_0\"\n\n    if flip:\n        return 0\n    else:\n        # Recursive call\n        rest = geometric(p, max_depth-1) @ \"rest\"\n        return 1 + rest\n</code></pre>"},{"location":"api/generative-functions/#state-space-models","title":"State Space Models","text":"<pre><code>@gen\ndef state_space_model(T, observations):\n    # Initial state\n    state = normal(0, 1) @ \"state_0\"\n\n    states = [state]\n    for t in range(1, T):\n        # State transition\n        state = normal(state, 0.1) @ f\"state_{t}\"\n        states.append(state)\n\n        # Observation\n        if observations[t] is not None:\n            obs = normal(state, 0.5) @ f\"obs_{t}\"\n            # Could add constraint: obs == observations[t]\n\n    return jnp.array(states)\n</code></pre>"},{"location":"api/generative-functions/#best-practices","title":"Best Practices","text":"<ol> <li>Use descriptive addresses: Make debugging easier with meaningful names</li> <li>Avoid address collisions: Each address at the same level must be unique</li> <li>Minimize Python loops: Use JAX/GenJAX combinators when possible</li> <li>Type annotations: Help with debugging and documentation</li> <li>Return structured data: Return dictionaries or named tuples for clarity</li> </ol>"},{"location":"api/generative-functions/#common-pitfalls","title":"Common Pitfalls","text":"<p>Python Control Flow in JAX</p> <p>Avoid Python <code>if</code>/<code>for</code> statements when you need JAX compilation:</p> <pre><code># Bad - won't work with JAX transformations\n@gen\ndef bad_model(n):\n    for i in range(n):  # Python loop with traced value!\n        x = normal(0, 1) @ f\"x_{i}\"\n\n# Good - use Scan combinator\nfrom genjax import Scan\n\n@gen\ndef step(carry, i):\n    x = normal(0, 1) @ \"x\"\n    return carry, x\n\nmodel = Scan(step, const(n))\n</code></pre> <p>Performance Tips</p> <ul> <li>Use <code>Fixed</code> for values that don't need regeneration</li> <li>Batch operations with <code>vmap</code> instead of loops</li> <li>Prefer built-in distributions over custom implementations</li> </ul>"},{"location":"api/overview/","title":"Core API Overview","text":"<p>GenJAX provides a powerful and composable API for probabilistic programming. The core concepts are:</p>"},{"location":"api/overview/#generative-functions","title":"Generative Functions","text":"<p>The fundamental abstraction in GenJAX is the generative function - a probabilistic program that can be executed, scored, and manipulated through the Generative Function Interface (GFI).</p>"},{"location":"api/overview/#the-gen-decorator","title":"The <code>@gen</code> Decorator","text":"<p>Transform Python functions into generative functions:</p> <pre><code>from genjax import gen, normal\n\n@gen\ndef my_model(x):\n    # Sample from distributions using @ for addressing\n    z = normal(0, 1) @ \"z\"\n    y = normal(z * x, 0.1) @ \"y\"\n    return y\n</code></pre>"},{"location":"api/overview/#addressing-with","title":"Addressing with <code>@</code>","text":"<p>The <code>@</code> operator assigns addresses to random choices, creating a hierarchical namespace:</p> <pre><code>@gen\ndef hierarchical_model():\n    # Top-level choice\n    global_mean = normal(0, 1) @ \"global_mean\"\n\n    # Nested choices\n    for i in range(3):\n        local_mean = normal(global_mean, 0.5) @ f\"group_{i}/mean\"\n        for j in range(5):\n            obs = normal(local_mean, 0.1) @ f\"group_{i}/obs_{j}\"\n</code></pre>"},{"location":"api/overview/#generative-function-interface-gfi","title":"Generative Function Interface (GFI)","text":"<p>Every generative function implements these core methods:</p>"},{"location":"api/overview/#simulateargs-trace","title":"<code>simulate(args...) -&gt; Trace</code>","text":"<p>Forward sampling from the model:</p> <pre><code>trace = model.simulate(x=2.0)\nchoices = trace.get_choices()  # {\"z\": 0.5, \"y\": 1.1}\nretval = trace.get_retval()    # 1.1\n</code></pre>"},{"location":"api/overview/#assesschoices-args-log_density-retval","title":"<code>assess(choices, args...) -&gt; (log_density, retval)</code>","text":"<p>Evaluate the log probability density:</p> <pre><code>choices = {\"z\": 0.5, \"y\": 1.0}\nlog_prob, retval = model.assess(choices, x=2.0)\n</code></pre>"},{"location":"api/overview/#generateconstraints-args-trace-weight","title":"<code>generate(constraints, args...) -&gt; (trace, weight)</code>","text":"<p>Generate a trace with some choices constrained:</p> <pre><code>constraints = {\"y\": 1.5}  # Fix observation\ntrace, weight = model.generate(constraints, x=2.0)\n# weight = log p(y=1.5, z) / q(z | y=1.5)\n</code></pre>"},{"location":"api/overview/#updatetrace-constraints-args-new_trace-weight-discard","title":"<code>update(trace, constraints, args...) -&gt; (new_trace, weight, discard)</code>","text":"<p>Update an existing trace with new constraints:</p> <pre><code>new_constraints = {\"y\": 2.0}\nnew_trace, weight, discard = model.update(trace, new_constraints, x=2.0)\n</code></pre>"},{"location":"api/overview/#regeneratetrace-selection-args-new_trace-weight-discard","title":"<code>regenerate(trace, selection, args...) -&gt; (new_trace, weight, discard)</code>","text":"<p>Selectively regenerate parts of a trace:</p> <pre><code>from genjax import sel\n\nselection = sel(\"z\")  # Regenerate only z\nnew_trace, weight, discard = model.regenerate(trace, selection, x=2.0)\n</code></pre>"},{"location":"api/overview/#traces","title":"Traces","text":"<p>Traces record the execution of generative functions:</p> <pre><code>trace = model.simulate(x=2.0)\n\n# Access components\nchoices = trace.get_choices()      # Random choices\nretval = trace.get_retval()        # Return value\nscore = trace.get_score()          # log(1/p(choices))\nargs = trace.get_args()            # Function arguments\ngen_fn = trace.get_gen_fn()        # Source generative function\n</code></pre>"},{"location":"api/overview/#distributions","title":"Distributions","text":"<p>Built-in probability distributions that implement the GFI:</p> <pre><code>from genjax import normal, beta, categorical, bernoulli\n\n# Continuous distributions\nx = normal(mu=0, sigma=1) @ \"x\"\np = beta(alpha=2, beta=2) @ \"p\"\n\n# Discrete distributions  \nk = categorical(probs=jnp.array([0.2, 0.3, 0.5])) @ \"k\"\nb = bernoulli(p=0.7) @ \"b\"\n</code></pre>"},{"location":"api/overview/#combinators","title":"Combinators","text":"<p>Higher-order generative functions for composition:</p>"},{"location":"api/overview/#mapvmap","title":"Map/Vmap","text":"<p>Vectorized execution:</p> <pre><code># Map model over multiple inputs\nvectorized = model.vmap()\ntraces = vectorized.simulate(jnp.array([1.0, 2.0, 3.0]))\n</code></pre>"},{"location":"api/overview/#scan","title":"Scan","text":"<p>Sequential execution with state threading:</p> <pre><code>from genjax import Scan, const\n\n@gen\ndef step(state, x):\n    new_state = normal(state + x, 0.1) @ \"state\"\n    return new_state, new_state\n\nscan_model = Scan(step, const(10))  # 10 steps\ntrace = scan_model.simulate(init_state=0.0, xs=jnp.ones(10))\n</code></pre>"},{"location":"api/overview/#cond","title":"Cond","text":"<p>Conditional execution:</p> <pre><code>from genjax import Cond\n\n@gen\ndef model_a():\n    return normal(0, 1) @ \"x\"\n\n@gen  \ndef model_b():\n    return normal(5, 2) @ \"x\"\n\ncond_model = Cond(model_a, model_b)\ntrace = cond_model.simulate(condition=True)  # Uses model_a\n</code></pre>"},{"location":"api/overview/#selections","title":"Selections","text":"<p>Target specific addresses for operations:</p> <pre><code>from genjax import sel, Selection, AllSel\n\n# Select specific addresses\ns1 = sel(\"x\")                    # Select \"x\"\ns2 = sel(\"group_0\", \"mean\")      # Select \"group_0/mean\"\n\n# Combine selections\ns_or = sel(\"x\") | sel(\"y\")       # Select x OR y\ns_and = sel(\"x\") &amp; sel(\"y\")      # Select x AND y (intersection)\ns_not = ~sel(\"x\")                # Select everything except x\n\n# Select all\ns_all = Selection(AllSel())      # Select all addresses\n</code></pre>"},{"location":"api/overview/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about Generative Functions in detail</li> <li>Explore available Distributions</li> <li>Understand Traces and their structure</li> <li>Master Combinators for model composition</li> </ul>"},{"location":"getting-started/best-practices/","title":"Best Practices","text":"<p>This guide covers essential best practices for writing efficient and idiomatic GenJAX code.</p>"},{"location":"getting-started/best-practices/#jax-control-flow","title":"JAX Control Flow","text":"<p>GenJAX is built on JAX, which requires special handling of control flow for JIT compilation.</p>"},{"location":"getting-started/best-practices/#avoid-python-control-flow","title":"\u274c Avoid Python Control Flow","text":"<pre><code># BAD: Python for loop\n@gen\ndef bad_model(n):\n    values = []\n    for i in range(n):\n        x = distributions.normal(0, 1) @ f\"x_{i}\"\n        values.append(x)\n    return jnp.array(values)\n</code></pre>"},{"location":"getting-started/best-practices/#use-jax-control-flow","title":"\u2705 Use JAX Control Flow","text":"<pre><code># GOOD: Vectorized operations\n@gen\ndef good_model(n: Const[int]):\n    # Use vmap for vectorized sampling\n    values = distributions.normal(0, 1).vmap().apply(jnp.arange(n))\n    return values\n</code></pre>"},{"location":"getting-started/best-practices/#control-flow-patterns","title":"Control Flow Patterns","text":""},{"location":"getting-started/best-practices/#conditionals","title":"Conditionals","text":"<pre><code># BAD: Python if/else\nif condition:\n    result = model_a()\nelse:\n    result = model_b()\n\n# GOOD: jax.lax.cond\nresult = jax.lax.cond(\n    condition,\n    lambda: model_a(),\n    lambda: model_b()\n)\n</code></pre>"},{"location":"getting-started/best-practices/#loops-with-state","title":"Loops with State","text":"<pre><code># BAD: Python loop with accumulation\ntotal = 0\nfor i in range(n):\n    total += compute(i)\n\n# GOOD: jax.lax.scan\ndef step(carry, i):\n    return carry + compute(i), None\n\ntotal, _ = jax.lax.scan(step, 0, jnp.arange(n))\n</code></pre>"},{"location":"getting-started/best-practices/#static-vs-dynamic-values","title":"Static vs Dynamic Values","text":"<p>Use <code>Const[T]</code> to mark static values that should not become JAX tracers:</p> <pre><code>from genjax import Const\n\n@gen\ndef model(n_samples: Const[int], scale: float):\n    # n_samples is static - safe to use in Python control\n    # scale is dynamic - will be traced by JAX\n    return distributions.normal(0, scale).vmap().apply(jnp.arange(n_samples))\n</code></pre>"},{"location":"getting-started/best-practices/#random-number-generation","title":"Random Number Generation","text":"<p>Always use JAX's functional RNG pattern:</p> <pre><code># Split keys for multiple uses\nkey, subkey1, subkey2 = jax.random.split(key, 3)\n\n# Pass keys explicitly\ntrace1 = model.simulate(subkey1, args)\ntrace2 = model.simulate(subkey2, args)\n</code></pre>"},{"location":"getting-started/best-practices/#vectorization-best-practices","title":"Vectorization Best Practices","text":""},{"location":"getting-started/best-practices/#use-built-in-vectorization","title":"Use Built-in Vectorization","text":"<pre><code># Vectorize distributions\n@gen\ndef vectorized_model(data):\n    # Vectorized prior\n    mu = distributions.normal(0, 1) @ \"mu\"\n\n    # Vectorized likelihood\n    obs = distributions.normal(mu, 0.1).vmap().apply(jnp.arange(len(data)))\n    return obs\n</code></pre>"},{"location":"getting-started/best-practices/#batch-operations","title":"Batch Operations","text":"<pre><code># Process multiple traces efficiently\nkeys = jax.random.split(key, n_chains)\ntraces = jax.vmap(lambda k: model.simulate(k, args))(keys)\n</code></pre>"},{"location":"getting-started/best-practices/#memory-efficiency","title":"Memory Efficiency","text":""},{"location":"getting-started/best-practices/#avoid-materializing-large-intermediate-arrays","title":"Avoid Materializing Large Intermediate Arrays","text":"<pre><code># BAD: Creates large intermediate array\n@gen\ndef inefficient(n):\n    all_samples = distributions.normal(0, 1).vmap().apply(jnp.arange(n))\n    return jnp.mean(all_samples)\n\n# GOOD: Use scan for memory efficiency\n@gen\ndef efficient(n: Const[int]):\n    def step(carry, i):\n        sample = distributions.normal(0, 1) @ f\"sample_{i}\"\n        return carry + sample, None\n\n    total, _ = jax.lax.scan(step, 0.0, jnp.arange(n))\n    return total / n\n</code></pre>"},{"location":"getting-started/best-practices/#type-annotations","title":"Type Annotations","text":"<p>Use type hints for better code clarity and IDE support:</p> <pre><code>from typing import Tuple\nimport jax.numpy as jnp\nfrom genjax import Trace\n\n@gen\ndef typed_model(x: jnp.ndarray) -&gt; jnp.ndarray:\n    mu = distributions.normal(0.0, 1.0) @ \"mu\"\n    y = distributions.normal(mu * x, 0.1) @ \"y\"\n    return y\n\ndef inference_step(trace: Trace, key: jax.random.PRNGKey) -&gt; Tuple[Trace, float]:\n    new_trace = metropolis_hastings(trace, select(\"mu\"), key)\n    return new_trace, new_trace[\"mu\"]\n</code></pre>"},{"location":"getting-started/best-practices/#common-pitfalls","title":"Common Pitfalls","text":""},{"location":"getting-started/best-practices/#1-forgetting-vmap-address-prefixes","title":"1. Forgetting vmap Address Prefixes","text":"<pre><code># When using vmap, addresses are prefixed\nconstraints = {\n    \"vmap/x_0\": 1.0,  # Correct\n    \"x_0\": 1.0,       # Wrong - won't match vmapped choice\n}\n</code></pre>"},{"location":"getting-started/best-practices/#2-using-python-randomness","title":"2. Using Python Randomness","text":"<pre><code># BAD: Python's random module\nimport random\nx = random.normal()\n\n# GOOD: JAX random\nkey, subkey = jax.random.split(key)\nx = jax.random.normal(subkey)\n</code></pre>"},{"location":"getting-started/best-practices/#3-modifying-arrays-in-place","title":"3. Modifying Arrays In-Place","text":"<pre><code># BAD: In-place modification\narr[0] = 1.0\n\n# GOOD: Functional update\narr = arr.at[0].set(1.0)\n</code></pre>"},{"location":"getting-started/best-practices/#performance-tips","title":"Performance Tips","text":"<ol> <li>JIT Compile Inference Loops: Wrap your inference code in <code>jax.jit</code></li> <li>Batch Operations: Use <code>vmap</code> instead of loops when possible</li> <li>Reuse Compiled Functions: JIT compilation has overhead, reuse compiled functions</li> <li>Profile Your Code: Use JAX's profiling tools to identify bottlenecks</li> </ol>"},{"location":"getting-started/best-practices/#testing-best-practices","title":"Testing Best Practices","text":"<pre><code>def test_model_deterministic():\n    \\\"\\\"\\\"Test with fixed random seed for reproducibility\\\"\\\"\\\"\n    key = jax.random.PRNGKey(42)\n    trace = model.simulate(key, args)\n\n    # Test should be deterministic\n    expected_value = 1.234\n    assert jnp.allclose(trace.retval, expected_value)\n\ndef test_gradients():\n    \\\"\\\"\\\"Ensure gradients flow correctly\\\"\\\"\\\"\n    def loss(params):\n        trace = model.generate(key, constraints, params)\n        return -trace.score  # Negative log probability\n\n    grad_fn = jax.grad(loss)\n    grads = grad_fn(params)\n\n    # Check gradients are finite\n    assert jnp.all(jnp.isfinite(grads))\n</code></pre>"},{"location":"getting-started/best-practices/#next-steps","title":"Next Steps","text":"<ul> <li>Review the API Reference for detailed documentation</li> <li>Explore Advanced Topics for deeper JAX integration</li> <li>Check out Examples for real-world patterns</li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>GenJAX can be installed using pip or conda package managers.</p>"},{"location":"getting-started/installation/#using-pip","title":"Using pip","text":"<pre><code>pip install genjax\n</code></pre>"},{"location":"getting-started/installation/#using-condamamba","title":"Using conda/mamba","text":"<pre><code>conda install -c conda-forge genjax\n</code></pre>"},{"location":"getting-started/installation/#development-installation","title":"Development Installation","text":"<p>For development or to get the latest features:</p> <pre><code>git clone https://github.com/femtomc/genjax.git\ncd genjax\npip install -e .\n</code></pre>"},{"location":"getting-started/installation/#dependencies","title":"Dependencies","text":"<p>GenJAX requires: - Python &gt;= 3.12 - JAX &gt;= 0.6.0 - TensorFlow Probability (JAX substrate) - Beartype for runtime type checking - Penzai for visualization</p>"},{"location":"getting-started/quickstart/","title":"Quick Start","text":"<p>Get up and running with GenJAX in minutes! This guide covers the essential concepts through practical examples.</p>"},{"location":"getting-started/quickstart/#installation","title":"Installation","text":"<pre><code>pip install genjax\n</code></pre>"},{"location":"getting-started/quickstart/#your-first-model","title":"Your First Model","text":"<p>Let's start with a simple Bayesian coin flipping model that follows JAX best practices:</p> <pre><code>import jax\nimport jax.numpy as jnp\nfrom genjax import gen, distributions, Const\n\n@gen\ndef coin_model(n_flips: Const[int]):\n    # Prior belief about coin fairness\n    bias = distributions.beta(2.0, 2.0) @ \"bias\"\n\n    # Generate predictions using JAX-friendly vectorized operations\n    # This uses GenJAX's built-in vectorization support\n    flips = distributions.bernoulli(bias).vmap().apply(jnp.arange(n_flips))\n\n    return flips\n</code></pre> <p>JAX Best Practice</p> <p>Notice we use <code>Const[int]</code> for <code>n_flips</code> to indicate it's a static value. This allows JAX to compile efficiently without creating tracers for loop bounds.</p>"},{"location":"getting-started/quickstart/#running-inference","title":"Running Inference","text":""},{"location":"getting-started/quickstart/#forward-sampling","title":"Forward Sampling","text":"<p>Sample from the prior:</p> <pre><code>key = jax.random.PRNGKey(0)\n\n# Simulate without any observations\ntrace = coin_model.simulate(key, (4,))  # 4 flips\n\n# Extract the sampled bias\nbias_sample = trace[\"bias\"]\nprint(f\"Sampled bias: {bias_sample:.3f}\")\n\n# Get the predictions\npredictions = trace.retval\nprint(f\"Predicted flips: {predictions}\")\n</code></pre>"},{"location":"getting-started/quickstart/#conditioning-on-data","title":"Conditioning on Data","text":"<p>Observe some coin flips and infer the bias:</p> <pre><code># Observed data: 1 = Heads, 0 = Tails\nobserved_flips = jnp.array([1, 1, 0, 1])\n\n# Create constraints using JAX-friendly dictionary comprehension\nconstraints = {f\"vmap/flip_{i}\": observed_flips[i] for i in range(4)}\n\n# Generate a trace with these constraints\ntrace = coin_model.generate(key, constraints, (4,))\n\n# Extract posterior sample\nposterior_bias = trace[\"bias\"]\nprint(f\"Posterior bias sample: {posterior_bias:.3f}\")\n</code></pre> <p>Address Format</p> <p>When using <code>vmap</code>, addresses are prefixed with <code>vmap/</code>. This is important for correctly targeting vectorized random choices.</p>"},{"location":"getting-started/quickstart/#using-mcmc","title":"Using MCMC","text":"<p>For more complex models, use Markov Chain Monte Carlo with JAX-friendly patterns:</p> <pre><code>from genjax.inference.mcmc import metropolis_hastings\nfrom genjax import select\n\n# Initialize with constrained trace\nkey, subkey = jax.random.split(key)\ntrace = coin_model.generate(subkey, constraints, (4,))\n\n# Define MCMC kernel\nselection = select(\"bias\")  # Only update the bias\n\n# Run chain using JAX scan for efficiency\ndef mcmc_step(carry, key):\n    trace = carry\n    new_trace = metropolis_hastings(trace, selection, key)\n    return new_trace, new_trace[\"bias\"]  # Return trace and save bias\n\n# Generate keys for each MCMC step\nkeys = jax.random.split(key, 1000)\n\n# Run MCMC chain\nfinal_trace, bias_samples = jax.lax.scan(mcmc_step, trace, keys)\n\n# Analyze posterior (thin by taking every 100th sample)\nthinned_samples = bias_samples[::100]\nposterior_mean = jnp.mean(thinned_samples)\nprint(f\"Posterior mean bias: {posterior_mean:.3f}\")\n</code></pre> <p>JAX Best Practice</p> <p>Using <code>jax.lax.scan</code> instead of Python loops allows: - JIT compilation of the entire MCMC chain - Efficient memory usage - GPU/TPU acceleration</p>"},{"location":"getting-started/quickstart/#a-more-complex-example-linear-regression","title":"A More Complex Example: Linear Regression","text":"<pre><code>@gen\ndef linear_regression(x: jnp.ndarray):\n    # Priors\n    slope = distributions.normal(0.0, 10.0) @ \"slope\"\n    intercept = distributions.normal(0.0, 10.0) @ \"intercept\"\n    noise = distributions.gamma(1.0, 1.0) @ \"noise\"\n\n    # Vectorized likelihood - no Python loops!\n    mu = intercept + slope * x\n    y = distributions.normal(mu, noise).vmap().apply(jnp.arange(len(x)))\n\n    return y\n\n# Generate synthetic data\ntrue_slope = 2.0\ntrue_intercept = 1.0\nx_data = jnp.linspace(-2, 2, 20)\n\nkey, noise_key = jax.random.split(key)\ny_data = true_intercept + true_slope * x_data + jax.random.normal(noise_key, shape=(20,)) * 0.5\n\n# Create constraints for observed y values\nconstraints = {f\"vmap/y_{i}\": y_data[i] for i in range(len(y_data))}\n\n# Use SMC for inference\nfrom genjax.inference.smc import importance_sampling\n\n# Run importance sampling with multiple particles\nkeys = jax.random.split(key, 100)\ntraces = jax.vmap(lambda k: linear_regression.generate(k, constraints, (x_data,)))(keys)\n\n# Extract and analyze posterior samples\nslopes = traces[\"slope\"]  # Shape: (100,)\nintercepts = traces[\"intercept\"]  # Shape: (100,)\n\nprint(f\"Posterior mean slope: {jnp.mean(slopes):.3f} (true: {true_slope})\")\nprint(f\"Posterior mean intercept: {jnp.mean(intercepts):.3f} (true: {true_intercept})\")\n</code></pre> <p>Vectorized Operations</p> <p>GenJAX's <code>vmap()</code> method on distributions allows us to vectorize random choices across array dimensions, avoiding Python loops entirely.</p>"},{"location":"getting-started/quickstart/#jax-genjax-best-practices","title":"JAX &amp; GenJAX Best Practices","text":""},{"location":"getting-started/quickstart/#do","title":"\u2705 DO:","text":"<ul> <li>Use <code>jax.lax.scan</code> for loops with accumulation</li> <li>Use <code>jax.lax.fori_loop</code> for simple iterations</li> <li>Use <code>jax.lax.cond</code> for conditionals</li> <li>Use <code>Const[T]</code> for static values in generative functions</li> <li>Use <code>vmap()</code> for vectorizing operations</li> <li>Use JAX's functional random number generation</li> </ul>"},{"location":"getting-started/quickstart/#dont","title":"\u274c DON'T:","text":"<ul> <li>Use Python <code>for</code> loops in JIT-compiled code</li> <li>Use Python <code>if/else</code> statements with traced values</li> <li>Build Python lists and convert to arrays</li> <li>Use mutable state or side effects</li> </ul>"},{"location":"getting-started/quickstart/#key-concepts-summary","title":"Key Concepts Summary","text":"<ol> <li><code>@gen</code> decorator: Transforms functions into generative functions</li> <li><code>@</code> operator: Assigns addresses to random choices</li> <li>Traces: Immutable records of model execution</li> <li>Constraints: Fix random choices for conditioning</li> <li>Vectorization: Use <code>vmap()</code> for efficient batched operations</li> <li>Static values: Use <code>Const[T]</code> for compile-time constants</li> </ol>"},{"location":"getting-started/quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>Explore the Tutorial for in-depth examples</li> <li>Learn about Inference Algorithms</li> <li>Check out Advanced Examples</li> <li>Read the API Reference</li> </ul>"},{"location":"getting-started/quickstart/#getting-help","title":"Getting Help","text":"<ul> <li>GitHub Issues: github.com/femtomc/genjax/issues</li> <li>Documentation: femtomc.github.io/genjax</li> </ul>"},{"location":"reference/","title":"API Reference","text":"<p>Complete API documentation for GenJAX, automatically generated from source code.</p>"},{"location":"reference/#core-modules","title":"Core Modules","text":""},{"location":"reference/#genjaxcore","title":"genjax.core","text":"<p>Core functionality including the Generative Function Interface (GFI), traces, and the <code>@gen</code> decorator.</p>"},{"location":"reference/#genjaxdistributions","title":"genjax.distributions","text":"<p>Built-in probability distributions that implement the GFI.</p>"},{"location":"reference/#genjaxpjax","title":"genjax.pjax","text":"<p>Probabilistic JAX (PJAX) - foundational probabilistic programming primitives.</p>"},{"location":"reference/#inference","title":"Inference","text":""},{"location":"reference/#genjaxinferencemcmc","title":"genjax.inference.mcmc","text":"<p>Markov Chain Monte Carlo algorithms including Metropolis-Hastings and HMC.</p>"},{"location":"reference/#genjaxinferencesmc","title":"genjax.inference.smc","text":"<p>Sequential Monte Carlo methods for particle-based inference.</p>"},{"location":"reference/#genjaxinferencevi","title":"genjax.inference.vi","text":"<p>Variational inference algorithms and gradient estimators.</p>"},{"location":"reference/#advanced","title":"Advanced","text":""},{"location":"reference/#genjaxadev","title":"genjax.adev","text":"<p>Automatic differentiation of expected values for gradient estimation.</p>"},{"location":"reference/#genjaxstate","title":"genjax.state","text":"<p>State interpreter for inspecting and manipulating probabilistic computations.</p>"},{"location":"reference/#utilities","title":"Utilities","text":""},{"location":"reference/#genjaxsp","title":"genjax.sp","text":"<p>Structural primitives and combinators for building complex models.</p>"},{"location":"reference/#genjaxtiming","title":"genjax.timing","text":"<p>Utilities for benchmarking and performance analysis.</p>"},{"location":"reference/core/","title":"genjax.core","text":"<p>Core functionality for GenJAX including the Generative Function Interface, traces, and model construction.</p>"},{"location":"reference/core/#genjax.core","title":"core","text":""},{"location":"reference/core/#genjax.core.Pytree","title":"Pytree","text":"<p>               Bases: <code>Struct</code></p> <p><code>Pytree</code> is an abstract base class which registers a class with JAX's <code>Pytree</code> system. JAX's <code>Pytree</code> system tracks how data classes should behave across JAX-transformed function boundaries, like <code>jax.jit</code> or <code>jax.vmap</code>.</p> <p>Inheriting this class provides the implementor with the freedom to declare how the subfields of a class should behave:</p> <ul> <li><code>Pytree.static(...)</code>: the value of the field cannot be a JAX traced value, it must be a Python literal, or a constant). The values of static fields are embedded in the <code>PyTreeDef</code> of any instance of the class.</li> <li><code>Pytree.field(...)</code> or no annotation: the value may be a JAX traced value, and JAX will attempt to convert it to tracer values inside of its transformations.</li> </ul> <p>If a field points to another <code>Pytree</code>, it should not be declared as <code>Pytree.static()</code>, as the <code>Pytree</code> interface will automatically handle the <code>Pytree</code> fields as dynamic fields.</p>"},{"location":"reference/core/#genjax.core.Pytree.dataclass","title":"dataclass  <code>staticmethod</code>","text":"<pre><code>dataclass(incoming: None = None, /, **kwargs) -&gt; Callable[[type[R]], type[R]]\n</code></pre><pre><code>dataclass(incoming: type[R], /, **kwargs) -&gt; type[R]\n</code></pre> <pre><code>dataclass(incoming: type[R] | None = None, /, **kwargs) -&gt; type[R] | Callable[[type[R]], type[R]]\n</code></pre> <p>Denote that a class (which is inheriting <code>Pytree</code>) should be treated as a dataclass, meaning it can hold data in fields which are declared as part of the class.</p> <p>A dataclass is to be distinguished from a \"methods only\" <code>Pytree</code> class, which does not have fields, but may define methods. The latter cannot be instantiated, but can be inherited from, while the former can be instantiated: the <code>Pytree.dataclass</code> declaration informs the system how to instantiate the class as a dataclass, and how to automatically define JAX's <code>Pytree</code> interfaces (<code>tree_flatten</code>, <code>tree_unflatten</code>, etc.) for the dataclass, based on the fields declared in the class, and possibly <code>Pytree.static(...)</code> or <code>Pytree.field(...)</code> annotations (or lack thereof, the default is that all fields are <code>Pytree.field(...)</code>).</p> <p>All <code>Pytree</code> dataclasses support pretty printing, as well as rendering to HTML.</p>"},{"location":"reference/core/#genjax.core.Pytree.dataclass--examples","title":"Examples","text":"<p>from genjax import Pytree from jaxtyping import ArrayLike import jax.numpy as jnp</p> <p>@Pytree.dataclass ... class MyClass(Pytree): ...     my_static_field: int = Pytree.static() ...     my_dynamic_field: ArrayLike</p> <p>instance = MyClass(10, jnp.array(5.0)) instance.my_static_field 10 instance.my_dynamic_field  # doctest: +ELLIPSIS Array(5., dtype=float32...)</p> Source code in <code>src/genjax/core.py</code> <pre><code>@dataclass_transform(\n    frozen_default=True,\n)\n@staticmethod\ndef dataclass(\n    incoming: type[R] | None = None,\n    /,\n    **kwargs,\n) -&gt; type[R] | Callable[[type[R]], type[R]]:\n    \"\"\"\n    Denote that a class (which is inheriting `Pytree`) should be treated\n    as a dataclass, meaning it can hold data in fields which are\n    declared as part of the class.\n\n    A dataclass is to be distinguished from a \"methods only\"\n    `Pytree` class, which does not have fields, but may define methods.\n    The latter cannot be instantiated, but can be inherited from,\n    while the former can be instantiated:\n    the `Pytree.dataclass` declaration informs the system _how\n    to instantiate_ the class as a dataclass,\n    and how to automatically define JAX's `Pytree` interfaces\n    (`tree_flatten`, `tree_unflatten`, etc.) for the dataclass, based\n    on the fields declared in the class, and possibly `Pytree.static(...)`\n    or `Pytree.field(...)` annotations (or lack thereof, the default is\n    that all fields are `Pytree.field(...)`).\n\n    All `Pytree` dataclasses support pretty printing, as well as rendering\n    to HTML.\n\n    Examples\n    --------\n\n    &gt;&gt;&gt; from genjax import Pytree\n    &gt;&gt;&gt; from jaxtyping import ArrayLike\n    &gt;&gt;&gt; import jax.numpy as jnp\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; @Pytree.dataclass\n    ... class MyClass(Pytree):\n    ...     my_static_field: int = Pytree.static()\n    ...     my_dynamic_field: ArrayLike\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; instance = MyClass(10, jnp.array(5.0))\n    &gt;&gt;&gt; instance.my_static_field\n    10\n    &gt;&gt;&gt; instance.my_dynamic_field  # doctest: +ELLIPSIS\n    Array(5., dtype=float32...)\n    \"\"\"\n\n    return pz.pytree_dataclass(\n        incoming,\n        overwrite_parent_init=True,\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/core/#genjax.core.Pytree.static","title":"static  <code>staticmethod</code>","text":"<pre><code>static(**kwargs)\n</code></pre> <p>Declare a field of a <code>Pytree</code> dataclass to be static. Users can provide additional keyword argument options, like <code>default</code> or <code>default_factory</code>, to customize how the field is instantiated when an instance of the dataclass is instantiated.` Fields which are provided with default values must come after required fields in the dataclass declaration.</p>"},{"location":"reference/core/#genjax.core.Pytree.static--examples","title":"Examples","text":"<p>from genjax import Pytree from jaxtyping import ArrayLike import jax.numpy as jnp</p> <p>@Pytree.dataclass ... class MyClass(Pytree): ...     my_dynamic_field: ArrayLike ...     my_static_field: int = Pytree.static(default=0)</p> <p>instance = MyClass(jnp.array(5.0)) instance.my_static_field 0 instance.my_dynamic_field  # doctest: +ELLIPSIS Array(5., dtype=float32...)</p> Source code in <code>src/genjax/core.py</code> <pre><code>@staticmethod\ndef static(**kwargs):\n    \"\"\"Declare a field of a `Pytree` dataclass to be static.\n    Users can provide additional keyword argument options,\n    like `default` or `default_factory`, to customize how the field is\n    instantiated when an instance of\n    the dataclass is instantiated.` Fields which are provided with default\n    values must come after required fields in the dataclass declaration.\n\n    Examples\n    --------\n\n    &gt;&gt;&gt; from genjax import Pytree\n    &gt;&gt;&gt; from jaxtyping import ArrayLike\n    &gt;&gt;&gt; import jax.numpy as jnp\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; @Pytree.dataclass\n    ... class MyClass(Pytree):\n    ...     my_dynamic_field: ArrayLike\n    ...     my_static_field: int = Pytree.static(default=0)\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; instance = MyClass(jnp.array(5.0))\n    &gt;&gt;&gt; instance.my_static_field\n    0\n    &gt;&gt;&gt; instance.my_dynamic_field  # doctest: +ELLIPSIS\n    Array(5., dtype=float32...)\n\n    \"\"\"\n    return field(metadata={\"pytree_node\": False}, **kwargs)\n</code></pre>"},{"location":"reference/core/#genjax.core.Pytree.field","title":"field  <code>staticmethod</code>","text":"<pre><code>field(**kwargs)\n</code></pre> <p>Declare a field of a <code>Pytree</code> dataclass to be dynamic. Alternatively, one can leave the annotation off in the declaration.</p> Source code in <code>src/genjax/core.py</code> <pre><code>@staticmethod\ndef field(**kwargs):\n    \"\"\"Declare a field of a `Pytree` dataclass to be dynamic.\n    Alternatively, one can leave the annotation off in the declaration.\"\"\"\n    return field(**kwargs)\n</code></pre>"},{"location":"reference/core/#genjax.core.Const","title":"Const","text":"<p>               Bases: <code>Generic[A]</code>, <code>Pytree</code></p> <p>A Pytree wrapper for Python literals that should remain static.</p> <p>This class wraps Python values that need to stay as literals (not become JAX tracers) when used inside JAX transformations. The wrapped value is marked as static, ensuring it's embedded in the PyTreeDef rather than becoming a traced value.</p> Example <pre><code># Instead of: n_steps: int (becomes tracer in JAX transforms)\n# Use: n_steps: Const[int] (stays as Python int)\n\ndef my_function(n_steps: Const[int]):\n    for i in range(n_steps.value):  # n_steps.value is Python int\n        ...\n</code></pre>"},{"location":"reference/core/#genjax.core.NotFixedException","title":"NotFixedException","text":"<pre><code>NotFixedException(choice_map_status: X)\n</code></pre> <p>               Bases: <code>Exception</code></p> <p>Exception raised when trace verification finds unfixed values.</p> <p>This exception provides a clear visualization of which parts of the choice map are properly fixed (True) vs. unfixed (False), helping users debug model structure issues during constrained inference.</p> Source code in <code>src/genjax/core.py</code> <pre><code>def __init__(self, choice_map_status: X):\n    self.choice_map_status = choice_map_status\n    super().__init__(self._format_message())\n</code></pre>"},{"location":"reference/core/#genjax.core.Fixed","title":"Fixed","text":"<p>               Bases: <code>Generic[A]</code>, <code>Pytree</code></p> <p>A Pytree wrapper that denotes a random choice was provided (fixed), not proposed by a GFI's internal proposal family.</p> <p>This wrapper is used internally by Distribution implementations in <code>generate</code>, <code>update</code>, and <code>regenerate</code> methods to mark values that were constrained or provided externally rather than sampled from the distribution's internal proposal.</p> <p>The <code>Fixed</code> wrapper helps debug model structure issues during inference by tracking which random choices were externally constrained vs. internally proposed.</p>"},{"location":"reference/core/#genjax.core.Trace","title":"Trace","text":"<p>               Bases: <code>Generic[X, R]</code>, <code>Pytree</code></p>"},{"location":"reference/core/#genjax.core.Trace.get_fixed_choices","title":"get_fixed_choices  <code>abstractmethod</code>","text":"<pre><code>get_fixed_choices() -&gt; X\n</code></pre> <p>Get choices preserving Fixed wrappers.</p> <p>Returns the raw choice structure with Fixed wrappers intact, used for verification that values were constrained during inference.</p> Source code in <code>src/genjax/core.py</code> <pre><code>@abstractmethod\ndef get_fixed_choices(self) -&gt; X:\n    \"\"\"Get choices preserving Fixed wrappers.\n\n    Returns the raw choice structure with Fixed wrappers intact,\n    used for verification that values were constrained during inference.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/core/#genjax.core.Trace.verify","title":"verify","text":"<pre><code>verify() -&gt; None\n</code></pre> <p>Verify that all leaf values in the trace choices were fixed (constrained).</p> <p>Checks that all random choices in the trace are wrapped with Fixed, indicating they were provided externally rather than proposed by the GFI's internal proposal family. This helps debug model structure issues during inference.</p> Source code in <code>src/genjax/core.py</code> <pre><code>def verify(self) -&gt; None:\n    \"\"\"Verify that all leaf values in the trace choices were fixed (constrained).\n\n    Checks that all random choices in the trace are wrapped with Fixed,\n    indicating they were provided externally rather than proposed by the\n    GFI's internal proposal family. This helps debug model structure issues\n    during inference.\n\n    Raises:\n        NotFixedException: If any leaf value is not wrapped with Fixed.\n                          The exception includes a detailed choice map showing\n                          which values are fixed vs. unfixed.\n    \"\"\"\n    # Get choices preserving Fixed wrappers\n    choice_values = get_fixed_choices(self)\n\n    # Check if value is Fixed\n    def check_instance_fixed(x):\n        return isinstance(x, Fixed)\n\n    # Flatten the tree to get all leaf choice values\n    leaf_values, tree_def = jtu.tree_flatten(\n        choice_values, is_leaf=check_instance_fixed\n    )\n\n    # Check if all leaves are Fixed\n    all_fixed = all(isinstance(leaf, Fixed) for leaf in leaf_values)\n\n    if not all_fixed:\n        # Create a boolean choice map showing which values are fixed\n        def make_bool_status(x):\n            if isinstance(x, Fixed):\n                return True\n            else:\n                return False\n\n        choice_map_status = jtu.tree_map(\n            make_bool_status, choice_values, is_leaf=check_instance_fixed\n        )\n\n        raise NotFixedException(choice_map_status)\n</code></pre>"},{"location":"reference/core/#genjax.core.Tr","title":"Tr","text":"<p>               Bases: <code>Trace[X, R]</code>, <code>Pytree</code></p> <p>Concrete implementation of the Trace interface.</p> <p>Stores all components of an execution trace including the generative function, arguments, random choices, return value, and score.</p>"},{"location":"reference/core/#genjax.core.Tr.get_fixed_choices","title":"get_fixed_choices","text":"<pre><code>get_fixed_choices() -&gt; X\n</code></pre> <p>Get choices preserving Fixed wrappers.</p> Source code in <code>src/genjax/core.py</code> <pre><code>def get_fixed_choices(self) -&gt; X:\n    \"\"\"Get choices preserving Fixed wrappers.\"\"\"\n    return get_fixed_choices(self._choices)\n</code></pre>"},{"location":"reference/core/#genjax.core.AllSel","title":"AllSel","text":"<p>               Bases: <code>Pytree</code></p> <p>Selection that matches all addresses.</p>"},{"location":"reference/core/#genjax.core.NoneSel","title":"NoneSel","text":"<p>               Bases: <code>Pytree</code></p> <p>Selection that matches no addresses.</p>"},{"location":"reference/core/#genjax.core.StrSel","title":"StrSel","text":"<p>               Bases: <code>Pytree</code></p> <p>Selection that matches a specific string address.</p>"},{"location":"reference/core/#genjax.core.TupleSel","title":"TupleSel","text":"<p>               Bases: <code>Pytree</code></p> <p>Selection that matches a hierarchical tuple address.</p> <p>Tuple addresses represent hierarchical paths like (\"outer\", \"inner\", \"leaf\"). When matched against a single string address, it checks if that string matches the first element of the tuple, and returns a selection for the remaining path.</p>"},{"location":"reference/core/#genjax.core.DictSel","title":"DictSel","text":"<p>               Bases: <code>Pytree</code></p> <p>Selection that matches addresses using a dictionary mapping.</p>"},{"location":"reference/core/#genjax.core.ComplSel","title":"ComplSel","text":"<p>               Bases: <code>Pytree</code></p> <p>Selection that matches the complement of another selection.</p>"},{"location":"reference/core/#genjax.core.InSel","title":"InSel","text":"<p>               Bases: <code>Pytree</code></p> <p>Selection representing intersection of two selections.</p>"},{"location":"reference/core/#genjax.core.Selection","title":"Selection","text":"<p>               Bases: <code>Pytree</code></p> <p>A Selection acts as a filter to specify which random choices in a trace should be regenerated during the <code>regenerate</code> method call.</p> <p>Selections are used in inference algorithms like MCMC to specify which subset of random choices should be updated while keeping others fixed. The Selection determines which addresses (random choice names) match the selection criteria.</p> <p>A Selection wraps one of several concrete selection types: - StrSel: Matches a specific string address - DictSel: Matches addresses using a dictionary mapping - AllSel: Matches all addresses - NoneSel: Matches no addresses - ComplSel: Matches the complement of another selection - InSel: Matches the intersection of two selections - OrSel: Matches the union of two selections</p> Example <pre><code>from genjax.core import sel\n\n# Select a specific address\nselection = sel(\"x\")  # Matches address \"x\"\n\n# Select all addresses\nselection = sel(())   # Matches all addresses\n\n# Select nested addresses\nselection = sel({\"outer\": sel(\"inner\")})  # Matches \"outer\"/\"inner\"\n\n# Use in regenerate\nnew_trace, weight, discard = gen_fn.regenerate(args, trace, selection)\n</code></pre>"},{"location":"reference/core/#genjax.core.GFI","title":"GFI","text":"<p>               Bases: <code>Generic[X, R]</code>, <code>Pytree</code></p> <p>Generative Function Interface - the core abstraction for probabilistic programs.</p> <p>The GFI defines the standard interface that all generative functions must implement. It provides methods for simulation, assessment, generation, updating, and regeneration of probabilistic computations.</p> <p>Mathematical Foundation: A generative function bundles three mathematical objects: 1. Measure kernel P(dx; args) - the probability distribution over choices 2. Return value function f(x, args) -&gt; R - deterministic computation from choices 3. Internal proposal family Q(dx; args, context) - for efficient inference</p> <p>The GFI methods provide access to these mathematical objects and enable: - Forward sampling (simulate) - Density evaluation (assess) - Constrained generation (generate) - Edit moves (update, regenerate)</p> <p>All density computations are in log space for numerical stability. Weights from generate/update/regenerate enable importance sampling and MCMC.</p> Type Parameters <p>X: The type of the random choices (choice map). R: The type of the return value.</p> Core Methods <p>simulate: Sample (choices, retval) ~ P(\u00b7; args) assess: Compute log P(choices; args) generate: Sample with constraints, return importance weight update: Update trace arguments/choices, return incremental importance weight regenerate: Resample selected choices, return incremental importance weight</p> Additional Methods <p>merge: Combine choice maps (for compositional functions) log_density: Convenience method for assess that sums log densities vmap/repeat: Vectorization combinators cond: Conditional execution combinator</p>"},{"location":"reference/core/#genjax.core.GFI.simulate","title":"simulate  <code>abstractmethod</code>","text":"<pre><code>simulate(*args, **kwargs) -&gt; Trace[X, R]\n</code></pre> <p>Sample an execution trace from the generative function.</p> <p>Mathematical specification: - Samples (choices, retval) ~ P(\u00b7; args) where P is the generative function's measure kernel - Returns trace containing choices, return value, score, and arguments</p> <p>The score in the returned trace is log(1/P(choices; args)), i.e., the negative log probability density of the sampled choices.</p> Example Source code in <code>src/genjax/core.py</code> <pre><code>@abstractmethod\ndef simulate(\n    self,\n    *args,\n    **kwargs,\n) -&gt; Trace[X, R]:\n    \"\"\"Sample an execution trace from the generative function.\n\n    Mathematical specification:\n    - Samples (choices, retval) ~ P(\u00b7; args) where P is the generative function's measure kernel\n    - Returns trace containing choices, return value, score, and arguments\n\n    The score in the returned trace is log(1/P(choices; args)), i.e., the negative\n    log probability density of the sampled choices.\n\n    Args:\n        *args: Arguments to the generative function.\n        **kwargs: Keyword arguments to the generative function.\n\n    Returns:\n        A trace containing the sampled choices, return value, score, and arguments.\n\n    Example:\n        &gt;&gt;&gt; # model.simulate(mu, sigma)  # Example usage\n        &gt;&gt;&gt; # choices = trace.get_choices()\n        &gt;&gt;&gt; # score = trace.get_score()  # -log P(choices; mu, sigma)\n        &gt;&gt;&gt; pass  # doctest placeholder\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/core/#genjax.core.GFI.simulate--modelsimulatemu-sigma-example-usage","title":"model.simulate(mu, sigma)  # Example usage","text":""},{"location":"reference/core/#genjax.core.GFI.simulate--choices-traceget_choices","title":"choices = trace.get_choices()","text":""},{"location":"reference/core/#genjax.core.GFI.simulate--score-traceget_score-log-pchoices-mu-sigma","title":"score = trace.get_score()  # -log P(choices; mu, sigma)","text":"<p>pass  # doctest placeholder</p>"},{"location":"reference/core/#genjax.core.GFI.generate","title":"generate  <code>abstractmethod</code>","text":"<pre><code>generate(x: X | None, *args, **kwargs) -&gt; tuple[Trace[X, R], Weight]\n</code></pre> <p>Generate a trace with optional constraints on some choices.</p> <p>Mathematical specification: - Samples unconstrained choices ~ Q(\u00b7; constrained_choices, args) - Computes importance weight: log [P(all_choices; args) / Q(unconstrained_choices; constrained_choices, args)] - When x=None, equivalent to simulate() but returns weight=0</p> <p>The weight enables importance sampling and is crucial for inference algorithms. For fully constrained generation, the weight equals the log density.</p> Example Source code in <code>src/genjax/core.py</code> <pre><code>@abstractmethod\ndef generate(\n    self,\n    x: X | None,\n    *args,\n    **kwargs,\n) -&gt; tuple[Trace[X, R], Weight]:\n    \"\"\"Generate a trace with optional constraints on some choices.\n\n    Mathematical specification:\n    - Samples unconstrained choices ~ Q(\u00b7; constrained_choices, args)\n    - Computes importance weight: log [P(all_choices; args) / Q(unconstrained_choices; constrained_choices, args)]\n    - When x=None, equivalent to simulate() but returns weight=0\n\n    The weight enables importance sampling and is crucial for inference algorithms.\n    For fully constrained generation, the weight equals the log density.\n\n    Args:\n        x: Optional constraints on subset of choices. If None, equivalent to simulate.\n        *args: Arguments to the generative function.\n        **kwargs: Keyword arguments to the generative function.\n\n    Returns:\n        A tuple (trace, weight) where:\n        - trace: contains all choices (constrained + sampled) and return value\n        - weight: log [P(all_choices; args) / Q(unconstrained_choices; constrained_choices, args)]\n\n    Example:\n        &gt;&gt;&gt; # Constrain some choices\n        &gt;&gt;&gt; # constraints = {\"x\": 1.5, \"y\": 2.0}\n        &gt;&gt;&gt; # trace, weight = model.generate(constraints, mu, sigma)\n        &gt;&gt;&gt; # weight accounts for probability of constrained choices\n        &gt;&gt;&gt; pass  # doctest placeholder\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/core/#genjax.core.GFI.generate--constrain-some-choices","title":"Constrain some choices","text":""},{"location":"reference/core/#genjax.core.GFI.generate--constraints","title":"constraints =","text":""},{"location":"reference/core/#genjax.core.GFI.generate--trace-weight-modelgenerateconstraints-mu-sigma","title":"trace, weight = model.generate(constraints, mu, sigma)","text":""},{"location":"reference/core/#genjax.core.GFI.generate--weight-accounts-for-probability-of-constrained-choices","title":"weight accounts for probability of constrained choices","text":"<p>pass  # doctest placeholder</p>"},{"location":"reference/core/#genjax.core.GFI.assess","title":"assess  <code>abstractmethod</code>","text":"<pre><code>assess(x: X, *args, **kwargs) -&gt; tuple[Density, R]\n</code></pre> <p>Compute the log probability density of given choices.</p> <p>Mathematical specification: - Computes log P(choices; args) where P is the generative function's measure kernel - Also computes the return value for the given choices - Requires P(choices; args) &gt; 0 (choices must be valid)</p> Example Source code in <code>src/genjax/core.py</code> <pre><code>@abstractmethod\ndef assess(\n    self,\n    x: X,\n    *args,\n    **kwargs,\n) -&gt; tuple[Density, R]:\n    \"\"\"Compute the log probability density of given choices.\n\n    Mathematical specification:\n    - Computes log P(choices; args) where P is the generative function's measure kernel\n    - Also computes the return value for the given choices\n    - Requires P(choices; args) &gt; 0 (choices must be valid)\n\n    Args:\n        x: The choices to evaluate.\n        *args: Arguments to the generative function.\n        **kwargs: Keyword arguments to the generative function.\n\n    Returns:\n        A tuple (log_density, retval) where:\n        - log_density: log P(choices; args)\n        - retval: return value computed with the given choices\n\n    Example:\n        &gt;&gt;&gt; # log_density, retval = model.assess(choices, mu, sigma)\n        &gt;&gt;&gt; # log_density = log P(choices; mu, sigma)\n        &gt;&gt;&gt; pass  # doctest placeholder\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/core/#genjax.core.GFI.assess--log_density-retval-modelassesschoices-mu-sigma","title":"log_density, retval = model.assess(choices, mu, sigma)","text":""},{"location":"reference/core/#genjax.core.GFI.assess--log_density-log-pchoices-mu-sigma","title":"log_density = log P(choices; mu, sigma)","text":"<p>pass  # doctest placeholder</p>"},{"location":"reference/core/#genjax.core.GFI.update","title":"update  <code>abstractmethod</code>","text":"<pre><code>update(tr: Trace[X, R], x_: X | None, *args, **kwargs) -&gt; tuple[Trace[X, R], Weight, X | None]\n</code></pre> <p>Update a trace with new arguments and/or choice constraints.</p> <p>Mathematical specification: - Transforms trace from (old_args, old_choices) to (new_args, new_choices) - Computes incremental importance weight (edit move):</p> <p>weight = log [P(new_choices; new_args) / Q(new_choices; new_args, old_choices, constraints)]        - log [P(old_choices; old_args) / Q(old_choices; old_args)]</p> <p>where Q is the internal proposal distribution used for updating.</p> Example Source code in <code>src/genjax/core.py</code> <pre><code>@abstractmethod\ndef update(\n    self,\n    tr: Trace[X, R],\n    x_: X | None,\n    *args,\n    **kwargs,\n) -&gt; tuple[Trace[X, R], Weight, X | None]:\n    \"\"\"Update a trace with new arguments and/or choice constraints.\n\n    Mathematical specification:\n    - Transforms trace from (old_args, old_choices) to (new_args, new_choices)\n    - Computes incremental importance weight (edit move):\n\n    weight = log [P(new_choices; new_args) / Q(new_choices; new_args, old_choices, constraints)]\n           - log [P(old_choices; old_args) / Q(old_choices; old_args)]\n\n    where Q is the internal proposal distribution used for updating.\n\n    Args:\n        tr: Current trace to update.\n        x_: Optional constraints on choices to enforce during update.\n        *args: New arguments to the generative function.\n        **kwargs: New keyword arguments to the generative function.\n\n    Returns:\n        A tuple (new_trace, weight, discarded_choices) where:\n        - new_trace: updated trace with new arguments and choices\n        - weight: incremental importance weight for the update (enables MCMC, SMC)\n        - discarded_choices: old choice values that were changed\n\n    Example:\n        &gt;&gt;&gt; # Update trace with new arguments\n        &gt;&gt;&gt; # new_trace, weight, discarded = model.update(old_trace, None, new_mu, new_sigma)\n        &gt;&gt;&gt; # weight = log P(new_choices; new_args) - log P(old_choices; old_args)\n        &gt;&gt;&gt; pass  # doctest placeholder\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/core/#genjax.core.GFI.update--update-trace-with-new-arguments","title":"Update trace with new arguments","text":""},{"location":"reference/core/#genjax.core.GFI.update--new_trace-weight-discarded-modelupdateold_trace-none-new_mu-new_sigma","title":"new_trace, weight, discarded = model.update(old_trace, None, new_mu, new_sigma)","text":""},{"location":"reference/core/#genjax.core.GFI.update--weight-log-pnew_choices-new_args-log-pold_choices-old_args","title":"weight = log P(new_choices; new_args) - log P(old_choices; old_args)","text":"<p>pass  # doctest placeholder</p>"},{"location":"reference/core/#genjax.core.GFI.regenerate","title":"regenerate  <code>abstractmethod</code>","text":"<pre><code>regenerate(tr: Trace[X, R], sel: Selection, *args, **kwargs) -&gt; tuple[Trace[X, R], Weight, X | None]\n</code></pre> <p>Regenerate selected choices in a trace while keeping others fixed.</p> <p>Mathematical specification: - Resamples choices at addresses selected by 'sel' from their conditional distribution - Keeps non-selected choices unchanged - Computes incremental importance weight (edit move):</p> <p>weight = log P(new_selected_choices | non_selected_choices; args)        - log P(old_selected_choices | non_selected_choices; args)</p> <p>When sel selects all addresses, regenerate becomes equivalent to simulate. When sel selects no addresses, weight = 0 and trace unchanged.</p> Example Source code in <code>src/genjax/core.py</code> <pre><code>@abstractmethod\ndef regenerate(\n    self,\n    tr: Trace[X, R],\n    sel: Selection,\n    *args,\n    **kwargs,\n) -&gt; tuple[Trace[X, R], Weight, X | None]:\n    \"\"\"Regenerate selected choices in a trace while keeping others fixed.\n\n    Mathematical specification:\n    - Resamples choices at addresses selected by 'sel' from their conditional distribution\n    - Keeps non-selected choices unchanged\n    - Computes incremental importance weight (edit move):\n\n    weight = log P(new_selected_choices | non_selected_choices; args)\n           - log P(old_selected_choices | non_selected_choices; args)\n\n    When sel selects all addresses, regenerate becomes equivalent to simulate.\n    When sel selects no addresses, weight = 0 and trace unchanged.\n\n    Args:\n        tr: Current trace to regenerate from.\n        sel: Selection specifying which addresses to regenerate.\n        *args: Arguments to the generative function.\n        **kwargs: Keyword arguments to the generative function.\n\n    Returns:\n        A tuple (new_trace, weight, discarded_choices) where:\n        - new_trace: trace with selected choices resampled\n        - weight: incremental importance weight for the regeneration\n        - discarded_choices: old values of the regenerated choices\n\n    Example:\n        &gt;&gt;&gt; # Regenerate choices at addresses \"x\" and \"y\"\n        &gt;&gt;&gt; # selection = sel(\"x\") | sel(\"y\")\n        &gt;&gt;&gt; # new_trace, weight, discarded = model.regenerate(trace, selection, mu, sigma)\n        &gt;&gt;&gt; # weight accounts for probability change due to regeneration\n        &gt;&gt;&gt; pass  # doctest placeholder\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/core/#genjax.core.GFI.regenerate--regenerate-choices-at-addresses-x-and-y","title":"Regenerate choices at addresses \"x\" and \"y\"","text":""},{"location":"reference/core/#genjax.core.GFI.regenerate--selection-selx-sely","title":"selection = sel(\"x\") | sel(\"y\")","text":""},{"location":"reference/core/#genjax.core.GFI.regenerate--new_trace-weight-discarded-modelregeneratetrace-selection-mu-sigma","title":"new_trace, weight, discarded = model.regenerate(trace, selection, mu, sigma)","text":""},{"location":"reference/core/#genjax.core.GFI.regenerate--weight-accounts-for-probability-change-due-to-regeneration","title":"weight accounts for probability change due to regeneration","text":"<p>pass  # doctest placeholder</p>"},{"location":"reference/core/#genjax.core.GFI.merge","title":"merge  <code>abstractmethod</code>","text":"<pre><code>merge(x: X, x_: X, check: ndarray | None = None) -&gt; tuple[X, X | None]\n</code></pre> <p>Merge two choice maps, with the second taking precedence.</p> <p>Used internally for compositional generative functions where choice maps from different components need to be combined. The merge operation resolves conflicts by preferring choices from x_ over x.</p> Source code in <code>src/genjax/core.py</code> <pre><code>@abstractmethod\ndef merge(\n    self, x: X, x_: X, check: jnp.ndarray | None = None\n) -&gt; tuple[X, X | None]:\n    \"\"\"Merge two choice maps, with the second taking precedence.\n\n    Used internally for compositional generative functions where choice maps\n    from different components need to be combined. The merge operation resolves\n    conflicts by preferring choices from x_ over x.\n\n    Args:\n        x: First choice map.\n        x_: Second choice map (takes precedence in conflicts).\n        check: Optional boolean array for conditional selection.\n               If provided, selects x where True, x_ where False.\n\n    Returns:\n        Tuple of (merged choice map, discarded values).\n        - merged: Combined choices with x_ values overriding x values at conflicts\n        - discarded: Values from x that were overridden by x_ (None if no conflicts)\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/core/#genjax.core.GFI.filter","title":"filter  <code>abstractmethod</code>","text":"<pre><code>filter(x: X, selection: Selection) -&gt; tuple[X | None, X | None]\n</code></pre> <p>Filter choice map into selected and unselected parts.</p> <p>Used to partition choices based on a selection, enabling fine-grained manipulation of subsets of choices in inference algorithms. Each GFI implementation specializes this method for its choice type X.</p> Example Source code in <code>src/genjax/core.py</code> <pre><code>@abstractmethod\ndef filter(self, x: X, selection: \"Selection\") -&gt; tuple[X | None, X | None]:\n    \"\"\"Filter choice map into selected and unselected parts.\n\n    Used to partition choices based on a selection, enabling fine-grained manipulation\n    of subsets of choices in inference algorithms. Each GFI implementation specializes\n    this method for its choice type X.\n\n    Args:\n        x: Choice map to filter.\n        selection: Selection specifying which addresses to include.\n\n    Returns:\n        Tuple of (selected_choices, unselected_choices) where:\n        - selected_choices: Choice map containing only selected addresses, or None if no matches\n        - unselected_choices: Choice map containing only unselected addresses, or None if no matches\n        Both have the same structure as X but contain disjoint subsets of addresses.\n\n    Example:\n        &gt;&gt;&gt; # choices = {\"mu\": 1.0, \"sigma\": 2.0, \"obs\": 3.0}\n        &gt;&gt;&gt; # selection = sel(\"mu\") | sel(\"sigma\")\n        &gt;&gt;&gt; # selected, unselected = model.filter(choices, selection)\n        &gt;&gt;&gt; # selected = {\"mu\": 1.0, \"sigma\": 2.0}, unselected = {\"obs\": 3.0}\n        &gt;&gt;&gt; pass  # doctest placeholder\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/core/#genjax.core.GFI.filter--choices","title":"choices =","text":""},{"location":"reference/core/#genjax.core.GFI.filter--selection-selmu-selsigma","title":"selection = sel(\"mu\") | sel(\"sigma\")","text":""},{"location":"reference/core/#genjax.core.GFI.filter--selected-unselected-modelfilterchoices-selection","title":"selected, unselected = model.filter(choices, selection)","text":""},{"location":"reference/core/#genjax.core.GFI.filter--selected-mu-10-sigma-20-unselected-obs-30","title":"selected = {\"mu\": 1.0, \"sigma\": 2.0}, unselected = {\"obs\": 3.0}","text":"<p>pass  # doctest placeholder</p>"},{"location":"reference/core/#genjax.core.Thunk","title":"Thunk","text":"<p>               Bases: <code>Generic[X, R]</code>, <code>Pytree</code></p> <p>Delayed evaluation wrapper for generative functions.</p> <p>A thunk represents a generative function call that has not yet been executed. It captures the function and its arguments for later evaluation.</p>"},{"location":"reference/core/#genjax.core.Vmap","title":"Vmap","text":"<p>               Bases: <code>Generic[X, R]</code>, <code>GFI[X, R]</code></p> <p>A <code>Vmap</code> is a generative function combinator that vectorizes another generative function.</p> <p><code>Vmap</code> applies a generative function across a batch dimension, similar to <code>jax.vmap</code>, but preserves probabilistic semantics. It uses GenJAX's <code>modular_vmap</code> to handle the vectorization of probabilistic computations correctly.</p> <p>Mathematical ingredients: - If callee has measure kernel P_callee(dx; args), then Vmap has kernel   P_vmap(dX; Args) = \u220f_i P_callee(dx_i; args_i) where X = [x_1, ..., x_n] - Return value function f_vmap(X, Args) = [f_callee(x_1, args_1), ..., f_callee(x_n, args_n)] - Internal proposal family inherits from callee's proposal family</p> Example <p>from genjax import normal</p>"},{"location":"reference/core/#genjax.core.Vmap--vectorize-a-normal-distribution","title":"Vectorize a normal distribution","text":"<p>vectorized_normal = normal.vmap(in_axes=(0, None))  # vectorize over first arg</p> <p>mus = jnp.array([0.0, 1.0, 2.0]) sigma = 1.0 trace = vectorized_normal.simulate(mus, sigma) samples = trace.get_choices()  # Array of 3 normal samples</p>"},{"location":"reference/core/#genjax.core.Vmap.filter","title":"filter","text":"<pre><code>filter(x: X, selection: Selection) -&gt; tuple[X | None, X | None]\n</code></pre> <p>Filter vectorized choices using the underlying generative function's filter.</p> <p>For Vmap, choices are vectorized across the batch dimension. We apply the underlying GF's filter to each vectorized choice.</p> Source code in <code>src/genjax/core.py</code> <pre><code>def filter(self, x: X, selection: \"Selection\") -&gt; tuple[X | None, X | None]:\n    \"\"\"Filter vectorized choices using the underlying generative function's filter.\n\n    For Vmap, choices are vectorized across the batch dimension. We apply\n    the underlying GF's filter to each vectorized choice.\n\n    Args:\n        x: Vectorized choice to filter.\n        selection: Selection specifying which addresses to include.\n\n    Returns:\n        Tuple of (selected_choices, unselected_choices) where each is vectorized or None.\n    \"\"\"\n    # Use modular_vmap to apply filter across the batch dimension\n    selected, unselected = modular_vmap(\n        self.gen_fn.filter,\n        in_axes=(0, None),\n        axis_size=self.axis_size.value,\n    )(x, selection)\n\n    return selected, unselected\n</code></pre>"},{"location":"reference/core/#genjax.core.Distribution","title":"Distribution","text":"<p>               Bases: <code>Generic[X]</code>, <code>GFI[X, X]</code></p> <p>A <code>Distribution</code> is a generative function that implements a probability distribution.</p> <p>Distributions are the fundamental building blocks of probabilistic programs. They implement the Generative Function Interface (GFI) by wrapping a sampling function and a log probability density function (logpdf).</p> <p>Mathematical ingredients: - A measure kernel P(dx; args) over a measurable space X given arguments args - Return value function f(x, args) = x (identity function for distributions) - Internal proposal distribution family Q(dx; args, x') = P(dx; args) (prior)</p> Example <p>import jax import jax.numpy as jnp from genjax import Distribution, const</p>"},{"location":"reference/core/#genjax.core.Distribution--create-a-custom-normal-distribution","title":"Create a custom normal distribution","text":"<p>def sample_normal(mu, sigma): ...     key = jax.random.PRNGKey(0)  # In practice, use proper key management ...     return mu + sigma * jax.random.normal(key)</p> <p>def logpdf_normal(x, mu, sigma): ...     return -0.5 * ((x - mu) / sigma)**2 - jnp.log(sigma) - 0.5 * jnp.log(2 * jnp.pi)</p> <p>normal = Distribution(const(sample_normal), const(logpdf_normal), const(\"normal\")) trace = normal.simulate(0.0, 1.0)  # mu=0.0, sigma=1.0</p>"},{"location":"reference/core/#genjax.core.Distribution.sample","title":"sample","text":"<pre><code>sample(*args, **kwargs) -&gt; X\n</code></pre> <p>Sample from the distribution.</p> Source code in <code>src/genjax/core.py</code> <pre><code>def sample(self, *args, **kwargs) -&gt; X:\n    \"\"\"Sample from the distribution.\"\"\"\n    return self._sample.value(*args, **kwargs)\n</code></pre>"},{"location":"reference/core/#genjax.core.Distribution.logpdf","title":"logpdf","text":"<pre><code>logpdf(x: X, *args, **kwargs) -&gt; Weight\n</code></pre> <p>Compute log probability density.</p> Source code in <code>src/genjax/core.py</code> <pre><code>def logpdf(self, x: X, *args, **kwargs) -&gt; Weight:\n    \"\"\"Compute log probability density.\"\"\"\n    return self._logpdf.value(x, *args, **kwargs)\n</code></pre>"},{"location":"reference/core/#genjax.core.Distribution.merge","title":"merge","text":"<pre><code>merge(x: X, x_: X, check: ndarray | None = None) -&gt; tuple[X, X | None]\n</code></pre> <p>Merge distribution choices with optional conditional selection.</p> <p>For distributions, choices are raw values from the sample space. When check is provided, we use jnp.where for conditional selection.</p> Source code in <code>src/genjax/core.py</code> <pre><code>def merge(\n    self, x: X, x_: X, check: jnp.ndarray | None = None\n) -&gt; tuple[X, X | None]:\n    \"\"\"Merge distribution choices with optional conditional selection.\n\n    For distributions, choices are raw values from the sample space.\n    When check is provided, we use jnp.where for conditional selection.\n    \"\"\"\n    if check is not None:\n        # Conditional merge using jnp.where\n        merged = jtu.tree_map(lambda v1, v2: jnp.where(check, v1, v2), x, x_)\n        # No values are truly \"discarded\" in conditional selection\n        return merged, None\n    else:\n        # Without check, Distribution doesn't support merge\n        raise Exception(\n            \"Can't merge: the underlying sample space `X` for the type `Distribution` doesn't support merging without a check parameter.\"\n        )\n</code></pre>"},{"location":"reference/core/#genjax.core.Distribution.filter","title":"filter","text":"<pre><code>filter(x: X, selection: Selection) -&gt; tuple[X | None, X | None]\n</code></pre> <p>Filter choice into selected and unselected parts.</p> <p>For Distribution, the choice is a single value X. Selection either matches the empty address () or it doesn't.</p> Source code in <code>src/genjax/core.py</code> <pre><code>def filter(self, x: X, selection: \"Selection\") -&gt; tuple[X | None, X | None]:\n    \"\"\"Filter choice into selected and unselected parts.\n\n    For Distribution, the choice is a single value X. Selection either\n    matches the empty address () or it doesn't.\n\n    Args:\n        x: Choice value to potentially filter.\n        selection: Selection specifying whether to include the choice.\n\n    Returns:\n        Tuple of (selected_choice, unselected_choice) where exactly one is x and the other is None.\n    \"\"\"\n    is_selected, _ = selection.match(())\n    if is_selected:\n        return x, None\n    else:\n        return None, x\n</code></pre>"},{"location":"reference/core/#genjax.core.Simulate","title":"Simulate  <code>dataclass</code>","text":"<pre><code>Simulate(score: Weight, trace_map: dict[str, Any], parent_fn: GFI = None)\n</code></pre> <p>Handler for simulating generative function executions.</p> <p>Tracks the accumulated score and trace map during simulation.</p>"},{"location":"reference/core/#genjax.core.Fn","title":"Fn","text":"<p>               Bases: <code>Generic[R]</code>, <code>GFI[dict[str, Any], R]</code></p> <p>A <code>Fn</code> is a generative function created from a JAX Python function using the <code>@gen</code> decorator.</p> <p><code>Fn</code> implements the GFI by executing the wrapped function in different execution contexts (handlers) that intercept calls to other generative functions via the <code>@</code> addressing syntax.</p> <p>Mathematical ingredients: - Measure kernel P(dx; args) defined by the composition of distributions in the function - Return value function f(x, args) defined by the function's logic and return statement - Internal proposal distribution family Q(dx; args, x') defined by ancestral sampling</p> <p>The choice space X is a dictionary mapping addresses (strings) to the choices made at those addresses during execution.</p> Example <p>import jax.numpy as jnp from genjax import gen, normal</p> <p>@gen def linear_regression(xs): ...     slope = normal(0.0, 1.0) @ \"slope\" ...     intercept = normal(0.0, 1.0) @ \"intercept\" ...     noise = normal(0.0, 0.1) @ \"noise\" ...     return normal(slope * xs + intercept, noise) @ \"y\"</p> <p>trace = linear_regression.simulate(jnp.array([1.0, 2.0, 3.0])) choices = trace.get_choices()  # dict with keys \"slope\", \"intercept\", \"noise\", \"y\"</p>"},{"location":"reference/core/#genjax.core.Fn.filter","title":"filter","text":"<pre><code>filter(x: dict[str, Any], selection: Selection) -&gt; tuple[dict[str, Any] | None, dict[str, Any] | None]\n</code></pre> <p>Filter choice map into selected and unselected parts.</p> <p>For Fn, choices are stored as dict[str, Any] with string addresses.</p> Source code in <code>src/genjax/core.py</code> <pre><code>def filter(\n    self, x: dict[str, Any], selection: \"Selection\"\n) -&gt; tuple[dict[str, Any] | None, dict[str, Any] | None]:\n    \"\"\"Filter choice map into selected and unselected parts.\n\n    For Fn, choices are stored as dict[str, Any] with string addresses.\n\n    Args:\n        x: Choice dictionary to filter.\n        selection: Selection specifying which addresses to include.\n\n    Returns:\n        Tuple of (selected_choices, unselected_choices) where each is a dict or None.\n    \"\"\"\n    if not x:\n        return None, None\n\n    selected = {}\n    unselected = {}\n    found_selected = False\n    found_unselected = False\n\n    for addr, value in x.items():\n        is_selected, subselection = selection.match(addr)\n        if is_selected:\n            if isinstance(value, dict) and subselection is not None:\n                # Recursively filter nested choices\n                selected_sub, unselected_sub = self.filter(value, subselection)\n                if selected_sub is not None:\n                    selected[addr] = selected_sub\n                    found_selected = True\n                if unselected_sub is not None:\n                    unselected[addr] = unselected_sub\n                    found_unselected = True\n            else:\n                # Include the entire value in selected\n                selected[addr] = value\n                found_selected = True\n        else:\n            # Include the entire value in unselected\n            unselected[addr] = value\n            found_unselected = True\n\n    return (\n        selected if found_selected else None,\n        unselected if found_unselected else None,\n    )\n</code></pre>"},{"location":"reference/core/#genjax.core.ScanTr","title":"ScanTr","text":"<p>               Bases: <code>Generic[X, R]</code>, <code>Trace[X, R]</code></p>"},{"location":"reference/core/#genjax.core.ScanTr.get_fixed_choices","title":"get_fixed_choices","text":"<pre><code>get_fixed_choices() -&gt; X\n</code></pre> <p>Get choices preserving Fixed wrappers.</p> Source code in <code>src/genjax/core.py</code> <pre><code>def get_fixed_choices(self) -&gt; X:\n    \"\"\"Get choices preserving Fixed wrappers.\"\"\"\n    return self.traces.get_fixed_choices()\n</code></pre>"},{"location":"reference/core/#genjax.core.Scan","title":"Scan","text":"<p>               Bases: <code>Generic[X, R]</code>, <code>GFI[X, R]</code></p> <p>A <code>Scan</code> is a generative function combinator that implements sequential iteration.</p> <p><code>Scan</code> repeatedly applies a generative function in a sequential loop, similar to <code>jax.lax.scan</code>, but preserves probabilistic semantics. The callee function should take (carry, x) as input and return (new_carry, output).</p> <p>Mathematical ingredients: - If callee has measure kernel P_callee(dx; carry, x), then Scan has kernel   P_scan(dX; init_carry, xs) = \u220fi P_callee(dx_i; carry_i, xs_i)   where carry = f_callee(x_i, carry_i, xs_i)[0] - Return value function returns (final_carry, [output_1, ..., output_n]) - Internal proposal family inherits from callee's proposal family</p> Example <p>from genjax import gen, normal, Scan, seed, const import jax.numpy as jnp import jax.random as jrand</p> <p>@gen def step(carry, x): ...     noise = normal(0.0, 0.1) @ \"noise\" ...     new_carry = carry + x + noise ...     return new_carry, new_carry  # output equals new carry</p> <p>scan_fn = Scan(step, length=const(3)) init_carry = 0.0 xs = jnp.array([1.0, 2.0, 3.0])</p>"},{"location":"reference/core/#genjax.core.Scan--use-seed-transformation-for-pjax-primitives","title":"Use seed transformation for PJAX primitives","text":"<p>key = jrand.key(0) trace = seed(scan_fn.simulate)(key, init_carry, xs) final_carry, outputs = trace.get_retval() assert len(outputs) == 3  # Should have 3 outputs</p>"},{"location":"reference/core/#genjax.core.Scan.filter","title":"filter","text":"<pre><code>filter(x: X, selection: Selection) -&gt; tuple[X | None, X | None]\n</code></pre> <p>Filter scan choices using the underlying generative function's filter.</p> <p>For Scan, choices are structured according to the scan iterations. We delegate to the underlying callee's filter method.</p> Source code in <code>src/genjax/core.py</code> <pre><code>def filter(self, x: X, selection: \"Selection\") -&gt; tuple[X | None, X | None]:\n    \"\"\"Filter scan choices using the underlying generative function's filter.\n\n    For Scan, choices are structured according to the scan iterations.\n    We delegate to the underlying callee's filter method.\n\n    Args:\n        x: Scan choice structure to filter.\n        selection: Selection specifying which addresses to include.\n\n    Returns:\n        Tuple of (selected_choices, unselected_choices) from the underlying callee.\n    \"\"\"\n    return self.callee.filter(x, selection)\n</code></pre>"},{"location":"reference/core/#genjax.core.CondTr","title":"CondTr","text":"<p>               Bases: <code>Generic[X, R]</code>, <code>Trace[X, R]</code></p>"},{"location":"reference/core/#genjax.core.CondTr.get_fixed_choices","title":"get_fixed_choices","text":"<pre><code>get_fixed_choices() -&gt; X\n</code></pre> <p>Get choices preserving Fixed wrappers.</p> Source code in <code>src/genjax/core.py</code> <pre><code>def get_fixed_choices(self) -&gt; X:\n    \"\"\"Get choices preserving Fixed wrappers.\"\"\"\n    chm, chm_ = map(lambda tr: tr.get_fixed_choices(), self.trs)\n\n    # Use merge with check parameter for conditional selection\n    merged, _ = self.gen_fn.merge(chm, chm_, self.check)\n    return merged\n</code></pre>"},{"location":"reference/core/#genjax.core.Cond","title":"Cond","text":"<p>               Bases: <code>Generic[X, R]</code>, <code>GFI[X, R]</code></p> <p>A <code>Cond</code> is a generative function combinator that implements conditional branching.</p> <p><code>Cond</code> takes a boolean condition and executes one of two generative functions based on the condition, similar to <code>jax.lax.cond</code>, but preserves probabilistic semantics by evaluating both branches and selecting the appropriate one.</p> <p>Mathematical ingredients: - If branches have measure kernels P_true(dx; args) and P_false(dx; args), then   Cond has kernel P_cond(dx; check, args) = P_true(dx; args) if check else P_false(dx; args) - Return value function f_cond(x, check, args) = f_true(x, args) if check else f_false(x, args) - Internal proposal family selects appropriate branch proposal based on condition</p> <p>Note: Both branches are always evaluated during simulation/generation to maintain JAX compatibility, but only the appropriate branch contributes to the final result.</p> Example <p>from genjax import gen, normal, exponential, Cond</p> <p>@gen def positive_branch(): ...     return exponential(1.0) @ \"value\"</p> <p>@gen def negative_branch(): ...     return exponential(2.0) @ \"value\"</p> <p>cond_fn = Cond(positive_branch, negative_branch)</p>"},{"location":"reference/core/#genjax.core.Cond--use-in-a-larger-model","title":"Use in a larger model","text":"<p>@gen def conditional_model(): ...     x = normal(0.0, 1.0) @ \"x\" ...     condition = x &gt; 0 ...     result = cond_fn((condition,)) @ \"conditional\" ...     return result</p>"},{"location":"reference/core/#genjax.core.Cond.filter","title":"filter","text":"<pre><code>filter(x: X, selection: Selection) -&gt; tuple[X | None, X | None]\n</code></pre> <p>Filter conditional choices using the underlying generative function's filter.</p> <p>For Cond, choices are determined by which branch was executed. We delegate to the first callee's filter method.</p> Source code in <code>src/genjax/core.py</code> <pre><code>def filter(self, x: X, selection: \"Selection\") -&gt; tuple[X | None, X | None]:\n    \"\"\"Filter conditional choices using the underlying generative function's filter.\n\n    For Cond, choices are determined by which branch was executed.\n    We delegate to the first callee's filter method.\n\n    Args:\n        x: Conditional choice structure to filter.\n        selection: Selection specifying which addresses to include.\n\n    Returns:\n        Tuple of (selected_choices, unselected_choices) from the underlying callee.\n    \"\"\"\n    return self.callee.filter(x, selection)\n</code></pre>"},{"location":"reference/core/#genjax.core.const","title":"const","text":"<pre><code>const(a: A) -&gt; Const[A]\n</code></pre> <p>Create a Const wrapper for a static value.</p> Example <p>length = const(10)  # Static length for scan</p> Source code in <code>src/genjax/core.py</code> <pre><code>def const(a: A) -&gt; Const[A]:\n    \"\"\"Create a Const wrapper for a static value.\n\n    Args:\n        a: The Python literal to wrap as static.\n\n    Returns:\n        A Const wrapper that keeps the value static in JAX transformations.\n\n    Example:\n        &gt;&gt;&gt; length = const(10)  # Static length for scan\n        &gt;&gt;&gt; # @gen\n        &gt;&gt;&gt; # def model(n: Const[int]):\n        &gt;&gt;&gt; #     scan_gf = Scan(step_fn, length=n.value)\n        &gt;&gt;&gt; #     return scan_gf(args)\n        &gt;&gt;&gt; # trace = model(length, other_args)\n        &gt;&gt;&gt; length.value\n        10\n    \"\"\"\n    return Const(a)\n</code></pre>"},{"location":"reference/core/#genjax.core.const--gen","title":"@gen","text":""},{"location":"reference/core/#genjax.core.const--def-modeln-constint","title":"def model(n: Const[int]):","text":""},{"location":"reference/core/#genjax.core.const--scan_gf-scanstep_fn-lengthnvalue","title":"scan_gf = Scan(step_fn, length=n.value)","text":""},{"location":"reference/core/#genjax.core.const--return-scan_gfargs","title":"return scan_gf(args)","text":""},{"location":"reference/core/#genjax.core.const--trace-modellength-other_args","title":"trace = model(length, other_args)","text":"<p>length.value 10</p>"},{"location":"reference/core/#genjax.core.fixed","title":"fixed","text":"<pre><code>fixed(a: A) -&gt; Fixed[A]\n</code></pre> <p>Create a Fixed wrapper for a constrained value.</p> Source code in <code>src/genjax/core.py</code> <pre><code>def fixed(a: A) -&gt; Fixed[A]:\n    \"\"\"Create a Fixed wrapper for a constrained value.\n\n    Args:\n        a: The value that was provided/constrained externally.\n\n    Returns:\n        A Fixed wrapper indicating the value was not proposed internally.\n    \"\"\"\n    return Fixed(a)\n</code></pre>"},{"location":"reference/core/#genjax.core.get_choices","title":"get_choices","text":"<pre><code>get_choices(x: Trace[X, R] | X) -&gt; X\n</code></pre> <p>Extract choices from a trace or nested structure containing traces.</p> <p>Also strips Fixed wrappers from the choices, returning the unwrapped values. Fixed wrappers are used internally to track constrained vs. proposed values.</p> Source code in <code>src/genjax/core.py</code> <pre><code>def get_choices(x: Trace[X, R] | X) -&gt; X:\n    \"\"\"Extract choices from a trace or nested structure containing traces.\n\n    Also strips Fixed wrappers from the choices, returning the unwrapped values.\n    Fixed wrappers are used internally to track constrained vs. proposed values.\n\n    Args:\n        x: A trace object or nested structure that may contain traces.\n\n    Returns:\n        The random choices, with any nested traces recursively unwrapped and\n        Fixed wrappers stripped.\n    \"\"\"\n    x = x.get_choices() if isinstance(x, Trace) else x\n\n    def _get_choices(x):\n        if isinstance(x, Trace):\n            return get_choices(x)\n        else:\n            return x\n\n    # First unwrap any nested traces\n    x = jtu.tree_map(\n        _get_choices,\n        x,\n        is_leaf=lambda x: isinstance(x, Trace),\n    )\n\n    # Then strip Fixed wrappers\n    def _strip_fixed(x):\n        if isinstance(x, Fixed):\n            return x.value  # Unwrap Fixed wrapper\n        else:\n            return x\n\n    return jtu.tree_map(\n        _strip_fixed,\n        x,\n        is_leaf=lambda x: isinstance(x, Fixed),\n    )\n</code></pre>"},{"location":"reference/core/#genjax.core.get_fixed_choices","title":"get_fixed_choices","text":"<pre><code>get_fixed_choices(x: Trace[X, R] | X) -&gt; X\n</code></pre> <p>Extract choices from a trace or nested structure containing traces, preserving Fixed wrappers.</p> <p>Similar to get_choices() but preserves Fixed wrappers around the choices, which is needed for verification that values were constrained during inference.</p> Source code in <code>src/genjax/core.py</code> <pre><code>def get_fixed_choices(x: Trace[X, R] | X) -&gt; X:\n    \"\"\"Extract choices from a trace or nested structure containing traces, preserving Fixed wrappers.\n\n    Similar to get_choices() but preserves Fixed wrappers around the choices,\n    which is needed for verification that values were constrained during inference.\n\n    Args:\n        x: A trace object or nested structure that may contain traces.\n\n    Returns:\n        The random choices, with any nested traces recursively unwrapped but\n        Fixed wrappers preserved.\n    \"\"\"\n    x = x.get_fixed_choices() if isinstance(x, Trace) else x\n\n    def _get_fixed_choices(x):\n        if isinstance(x, Trace):\n            return get_fixed_choices(x)\n        else:\n            return x\n\n    # Unwrap any nested traces but preserve Fixed wrappers\n    # Note: Unlike get_choices(), we do NOT strip Fixed wrappers\n    return jtu.tree_map(\n        _get_fixed_choices,\n        x,\n        is_leaf=lambda x: isinstance(x, Trace),\n    )\n</code></pre>"},{"location":"reference/core/#genjax.core.get_score","title":"get_score","text":"<pre><code>get_score(x: Trace[X, R]) -&gt; Weight\n</code></pre> <p>Extract the log probability score from a trace.</p> Source code in <code>src/genjax/core.py</code> <pre><code>def get_score(x: Trace[X, R]) -&gt; Weight:\n    \"\"\"Extract the log probability score from a trace.\n\n    Args:\n        x: Trace object to extract score from.\n\n    Returns:\n        The log probability score of the trace.\n    \"\"\"\n    return x.get_score()\n</code></pre>"},{"location":"reference/core/#genjax.core.get_retval","title":"get_retval","text":"<pre><code>get_retval(x: Trace[X, R]) -&gt; R\n</code></pre> <p>Extract the return value from a trace.</p> Source code in <code>src/genjax/core.py</code> <pre><code>def get_retval(x: Trace[X, R]) -&gt; R:\n    \"\"\"Extract the return value from a trace.\n\n    Args:\n        x: Trace object to extract return value from.\n\n    Returns:\n        The return value of the trace.\n    \"\"\"\n    return x.get_retval()\n</code></pre>"},{"location":"reference/core/#genjax.core.sel","title":"sel","text":"<pre><code>sel(*v: tuple[] | str | tuple[str, ...] | dict[str, Any] | None) -&gt; Selection\n</code></pre> <p>Create a Selection from various input types.</p> <p>This is a convenience function to create Selection objects from common patterns. Selections specify which random choices in a trace should be regenerated during inference operations like MCMC.</p> <p>Examples:</p> <pre><code># Select specific address\nsel(\"x\")                    # Matches address \"x\"\n\n# Select hierarchical address\nsel((\"outer\", \"inner\"))     # Matches hierarchical path outer/inner\n\n# Select all addresses\nsel(())                     # Matches all addresses\n\n# Select no addresses\nsel() or sel(None)          # Matches no addresses\n\n# Select nested addresses\nsel({\"outer\": sel(\"inner\")}) # Matches \"outer\"/\"inner\"\n</code></pre> Source code in <code>src/genjax/core.py</code> <pre><code>def sel(*v: tuple[()] | str | tuple[str, ...] | dict[str, Any] | None) -&gt; Selection:\n    \"\"\"Create a Selection from various input types.\n\n    This is a convenience function to create Selection objects from common patterns.\n    Selections specify which random choices in a trace should be regenerated during\n    inference operations like MCMC.\n\n    Args:\n        *v: Variable arguments specifying the selection pattern:\n            - str: Select a specific address (e.g., sel(\"x\"))\n            - tuple[str, ...]: Select hierarchical address (e.g., sel((\"outer\", \"inner\")))\n            - (): Select all addresses (e.g., sel(()))\n            - dict: Select nested addresses (e.g., sel({\"outer\": sel(\"inner\")}))\n            - None or no args: Select no addresses (e.g., sel() or sel(None))\n\n    Returns:\n        Selection object that can be used with regenerate methods\n\n    Examples:\n        ```python\n        # Select specific address\n        sel(\"x\")                    # Matches address \"x\"\n\n        # Select hierarchical address\n        sel((\"outer\", \"inner\"))     # Matches hierarchical path outer/inner\n\n        # Select all addresses\n        sel(())                     # Matches all addresses\n\n        # Select no addresses\n        sel() or sel(None)          # Matches no addresses\n\n        # Select nested addresses\n        sel({\"outer\": sel(\"inner\")}) # Matches \"outer\"/\"inner\"\n        ```\n    \"\"\"\n    assert len(v) &lt;= 1\n    if len(v) == 1:\n        if v[0] is None:\n            return Selection(NoneSel())\n        if v[0] == ():\n            return Selection(AllSel())\n        elif isinstance(v[0], dict):\n            return Selection(DictSel(v[0]))\n        elif isinstance(v[0], tuple) and all(isinstance(s, str) for s in v[0]):\n            # Tuple of strings for hierarchical addresses\n            return Selection(TupleSel(const(v[0])))\n        else:\n            assert isinstance(v[0], str)\n            return Selection(StrSel(const(v[0])))\n    else:\n        return Selection(NoneSel())\n</code></pre>"},{"location":"reference/core/#genjax.core.distribution","title":"distribution","text":"<pre><code>distribution(sampler: Callable[..., Any], logpdf: Callable[..., Any], /, name: str | None = None) -&gt; Distribution[Any]\n</code></pre> <p>Create a Distribution from sampling and log probability functions.</p> Source code in <code>src/genjax/core.py</code> <pre><code>def distribution(\n    sampler: Callable[..., Any],\n    logpdf: Callable[..., Any],\n    /,\n    name: str | None = None,\n) -&gt; Distribution[Any]:\n    \"\"\"Create a Distribution from sampling and log probability functions.\n\n    Args:\n        sampler: Function that takes parameters and returns a sample.\n        logpdf: Function that takes (value, *parameters) and returns log probability.\n        name: Optional name for the distribution.\n\n    Returns:\n        A Distribution instance implementing the Generative Function Interface.\n    \"\"\"\n    return Distribution(\n        _sample=const(sampler),\n        _logpdf=const(logpdf),\n        name=const(name),\n    )\n</code></pre>"},{"location":"reference/core/#genjax.core.tfp_distribution","title":"tfp_distribution","text":"<pre><code>tfp_distribution(dist: Callable[..., Distribution], /, name: str | None = None) -&gt; Distribution[Any]\n</code></pre> <p>Create a Distribution from a TensorFlow Probability distribution.</p> <p>Wraps a TFP distribution constructor to create a GenJAX Distribution that properly handles PJAX's <code>sample_p</code> primitive.</p> Example <p>import tensorflow_probability.substrates.jax as tfp from genjax import tfp_distribution</p> Source code in <code>src/genjax/core.py</code> <pre><code>def tfp_distribution(\n    dist: Callable[..., \"tfd.Distribution\"],\n    /,\n    name: str | None = None,\n) -&gt; Distribution[Any]:\n    \"\"\"Create a Distribution from a TensorFlow Probability distribution.\n\n    Wraps a TFP distribution constructor to create a GenJAX Distribution\n    that properly handles PJAX's `sample_p` primitive.\n\n    Args:\n        dist: TFP distribution constructor function.\n        name: Optional name for the distribution.\n\n    Returns:\n        A Distribution that wraps the TFP distribution.\n\n    Example:\n        &gt;&gt;&gt; import tensorflow_probability.substrates.jax as tfp\n        &gt;&gt;&gt; from genjax import tfp_distribution\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Create a normal distribution from TFP\n        &gt;&gt;&gt; normal = tfp_distribution(tfp.distributions.Normal, name=\"normal\")\n    \"\"\"\n\n    def keyful_sampler(key, *args, sample_shape=(), **kwargs):\n        d = dist(*args, **kwargs)\n        return d.sample(seed=key, sample_shape=sample_shape)\n\n    def logpdf(v, *args, **kwargs):\n        d = dist(*args, **kwargs)\n        return d.log_prob(v)\n\n    return distribution(\n        wrap_sampler(\n            keyful_sampler,\n            name=name,\n        ),\n        wrap_logpdf(logpdf),\n        name=name,\n    )\n</code></pre>"},{"location":"reference/core/#genjax.core.tfp_distribution--create-a-normal-distribution-from-tfp","title":"Create a normal distribution from TFP","text":"<p>normal = tfp_distribution(tfp.distributions.Normal, name=\"normal\")</p>"},{"location":"reference/core/#genjax.core.gen","title":"gen","text":"<pre><code>gen(fn: Callable[..., R]) -&gt; Fn[R]\n</code></pre> <p>Convert a function into a generative function.</p> <p>The decorated function can use the <code>@</code> operator to make addressed random choices from distributions and other generative functions.</p> Example <p>from genjax import gen, normal</p> <p>@gen ... def model(mu, sigma): ...     x = normal(mu, sigma) @ \"x\" ...     y = normal(x, 0.1) @ \"y\" ...     return x + y</p> <p>trace = model.simulate(0.0, 1.0) choices = trace.get_choices()</p> Source code in <code>src/genjax/core.py</code> <pre><code>def gen(fn: Callable[..., R]) -&gt; Fn[R]:\n    \"\"\"Convert a function into a generative function.\n\n    The decorated function can use the `@` operator to make addressed\n    random choices from distributions and other generative functions.\n\n    Args:\n        fn: Function to convert into a generative function.\n\n    Returns:\n        A Fn instance that implements the Generative Function Interface.\n\n    Example:\n        &gt;&gt;&gt; from genjax import gen, normal\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; @gen\n        ... def model(mu, sigma):\n        ...     x = normal(mu, sigma) @ \"x\"\n        ...     y = normal(x, 0.1) @ \"y\"\n        ...     return x + y\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; trace = model.simulate(0.0, 1.0)\n        &gt;&gt;&gt; choices = trace.get_choices()\n        &gt;&gt;&gt; # choices will contain {\"x\": &lt;value&gt;, \"y\": &lt;value&gt;}\n    \"\"\"\n    gf = Fn(source=const(fn))\n    # Copy function metadata to preserve name and module information\n    try:\n        gf.__name__ = fn.__name__\n        gf.__qualname__ = fn.__qualname__\n        gf.__module__ = fn.__module__\n        gf.__doc__ = fn.__doc__\n        gf.__annotations__ = getattr(fn, \"__annotations__\", {})\n    except (AttributeError, TypeError):\n        # If we can't set these attributes (e.g., on frozen dataclasses), continue anyway\n        pass\n    return gf\n</code></pre>"},{"location":"reference/core/#genjax.core.gen--choices-will-contain","title":"choices will contain","text":""},{"location":"reference/core/#key-classes-and-functions","title":"Key Classes and Functions","text":""},{"location":"reference/core/#generativefunction","title":"GenerativeFunction","text":"<p>The base class for all generative functions in GenJAX.</p>"},{"location":"reference/core/#trace","title":"Trace","text":"<p>Represents an execution trace of a generative function.</p>"},{"location":"reference/core/#gen-decorator","title":"@gen Decorator","text":"<p>Transform Python functions into generative functions.</p>"},{"location":"reference/core/#usage-examples","title":"Usage Examples","text":"<pre><code>from genjax import gen, normal\n\n@gen\ndef my_model(x):\n    z = normal(0, 1) @ \"z\"\n    y = normal(z * x, 0.1) @ \"y\"\n    return y\n\n# Use the generative function\ntrace = my_model.simulate(key, (2.0,))\n</code></pre>"},{"location":"reference/distributions/","title":"genjax.distributions","text":"<p>Built-in probability distributions that implement the Generative Function Interface.</p>"},{"location":"reference/distributions/#genjax.distributions","title":"distributions","text":"<p>Standard probability distributions for GenJAX.</p> <p>This module provides a collection of common probability distributions wrapped as GenJAX Distribution objects. All distributions are built using TensorFlow Probability as the backend.</p>"},{"location":"reference/distributions/#genjax.distributions.bernoulli","title":"bernoulli  <code>module-attribute</code>","text":"<pre><code>bernoulli = tfp_distribution(Bernoulli, name='Bernoulli')\n</code></pre> <p>Bernoulli distribution for binary outcomes.</p> Mathematical Formulation <p>PMF: P(X = k) = p^k \u00d7 (1-p)^(1-k) for k \u2208 {0, 1}</p> <p>Where p is the probability of success.</p> <p>Mean: \ud835\udd3c[X] = p Variance: Var[X] = p(1-p) Support: {0, 1}</p> Parameterization <p>Can be specified via: - probs: p \u2208 [0, 1] (probability of success) - logits: log(p/(1-p)) \u2208 \u211d (log-odds)</p> References <p>.. [1] Johnson, N. L., Kotz, S., &amp; Kemp, A. W. (1992). \"Univariate        Discrete Distributions\". Wiley, Chapter 3.</p>"},{"location":"reference/distributions/#genjax.distributions.flip","title":"flip  <code>module-attribute</code>","text":"<pre><code>flip = tfp_distribution(lambda p: Bernoulli(probs=p, dtype=bool_), name='Flip')\n</code></pre> <p>Flip distribution (Bernoulli with boolean output).</p>"},{"location":"reference/distributions/#genjax.distributions.beta","title":"beta  <code>module-attribute</code>","text":"<pre><code>beta = tfp_distribution(Beta, name='Beta')\n</code></pre> <p>Beta distribution on the interval [0, 1].</p> Mathematical Formulation <p>PDF: f(x; \u03b1, \u03b2) = \u0393(\u03b1+\u03b2)/(\u0393(\u03b1)\u0393(\u03b2)) \u00d7 x^(\u03b1-1) \u00d7 (1-x)^(\u03b2-1)</p> <p>Where \u0393 is the gamma function, \u03b1 &gt; 0, \u03b2 &gt; 0.</p> <p>Mean: \ud835\udd3c[X] = \u03b1/(\u03b1+\u03b2) Variance: Var[X] = \u03b1\u03b2/((\u03b1+\u03b2)\u00b2(\u03b1+\u03b2+1)) Mode: (\u03b1-1)/(\u03b1+\u03b2-2) for \u03b1,\u03b2 &gt; 1 Support: [0, 1]</p> Special Cases <ul> <li>Beta(1, 1) = Uniform(0, 1)</li> <li>Beta(\u03b1, \u03b1) is symmetric about 0.5</li> <li>As \u03b1,\u03b2 \u2192 \u221e with \u03b1/(\u03b1+\u03b2) fixed, approaches Normal</li> </ul> References <p>.. [1] Gupta, A. K., &amp; Nadarajah, S. (2004). \"Handbook of Beta        Distribution and Its Applications\". CRC Press.</p>"},{"location":"reference/distributions/#genjax.distributions.categorical","title":"categorical  <code>module-attribute</code>","text":"<pre><code>categorical = tfp_distribution(lambda logits: Categorical(logits), name='Categorical')\n</code></pre> <p>Categorical distribution over discrete outcomes.</p> Mathematical Formulation <p>PMF: P(X = k) = p_k for k \u2208 {0, 1, ..., K-1}</p> <p>Where \u2211_k p_k = 1 and p_k \u2265 0.</p> <p>Mean: \ud835\udd3c[X] = \u2211_k k \u00d7 p_k Variance: Var[X] = \u2211_k k\u00b2 \u00d7 p_k - (\ud835\udd3c[X])\u00b2 Entropy: H[X] = -\u2211_k p_k log(p_k) Support: {0, 1, ..., K-1}</p> Parameterization <ul> <li>logits: \u03b8_k \u2208 \u211d, where p_k = exp(\u03b8_k) / \u2211_j exp(\u03b8_j)</li> <li>Softmax transformation ensures valid probabilities</li> </ul> Connection to Other Distributions <ul> <li>K=2: Equivalent to Bernoulli</li> <li>Generalization of multinomial for single trial</li> </ul> References <p>.. [1] Bishop, C. M. (2006). \"Pattern Recognition and Machine Learning\".        Springer, Section 2.2.</p>"},{"location":"reference/distributions/#genjax.distributions.geometric","title":"geometric  <code>module-attribute</code>","text":"<pre><code>geometric = tfp_distribution(Geometric, name='Geometric')\n</code></pre> <p>Geometric distribution (number of trials until first success).</p> Mathematical Formulation <p>PMF: P(X = k) = (1-p)^(k-1) \u00d7 p for k \u2208 {1, 2, 3, ...}</p> <p>Where p \u2208 (0, 1] is the probability of success.</p> <p>Mean: \ud835\udd3c[X] = 1/p Variance: Var[X] = (1-p)/p\u00b2 CDF: F(k) = 1 - (1-p)^k Support: {1, 2, 3, ...}</p> Memoryless Property <p>P(X &gt; m + n | X &gt; m) = P(X &gt; n)</p> <p>The only discrete distribution with this property.</p> Alternative Parameterization <p>Some define X as failures before first success: P(X = k) = (1-p)^k \u00d7 p for k \u2208 {0, 1, 2, ...}</p> References <p>.. [1] Johnson, N. L., Kotz, S., &amp; Kemp, A. W. (1992). \"Univariate        Discrete Distributions\". Wiley, Chapter 5.</p>"},{"location":"reference/distributions/#genjax.distributions.normal","title":"normal  <code>module-attribute</code>","text":"<pre><code>normal = tfp_distribution(Normal, name='Normal')\n</code></pre> <p>Normal (Gaussian) distribution.</p> Mathematical Formulation <p>PDF: f(x; \u03bc, \u03c3) = (1/\u221a(2\u03c0\u03c3\u00b2)) \u00d7 exp(-(x-\u03bc)\u00b2/(2\u03c3\u00b2))</p> <p>Where \u03bc \u2208 \u211d is the mean, \u03c3 &gt; 0 is the standard deviation.</p> <p>Mean: \ud835\udd3c[X] = \u03bc Variance: Var[X] = \u03c3\u00b2 MGF: M(t) = exp(\u03bct + \u03c3\u00b2t\u00b2/2) Support: \u211d</p> Standard Normal <p>Z = (X - \u03bc)/\u03c3 ~ N(0, 1)</p> <p>\u03a6(z) = P(Z \u2264 z) = \u222b_{-\u221e}^z (1/\u221a(2\u03c0)) exp(-t\u00b2/2) dt</p> Properties <ul> <li>Maximum entropy distribution for fixed mean and variance</li> <li>Stable under convolution: X\u2081 + X\u2082 ~ N(\u03bc\u2081+\u03bc\u2082, \u03c3\u2081\u00b2+\u03c3\u2082\u00b2)</li> <li>Central Limit Theorem: Sample means converge to Normal</li> </ul> References <p>.. [1] Patel, J. K., &amp; Read, C. B. (1996). \"Handbook of the Normal        Distribution\". Marcel Dekker, 2nd edition.</p>"},{"location":"reference/distributions/#genjax.distributions.uniform","title":"uniform  <code>module-attribute</code>","text":"<pre><code>uniform = tfp_distribution(Uniform, name='Uniform')\n</code></pre> <p>Uniform distribution on an interval.</p> Mathematical Formulation <p>PDF: f(x; a, b) = 1/(b-a) for x \u2208 [a, b], 0 otherwise</p> <p>Where a &lt; b define the support interval.</p> <p>Mean: \ud835\udd3c[X] = (a + b)/2 Variance: Var[X] = (b - a)\u00b2/12 CDF: F(x) = (x - a)/(b - a) for x \u2208 [a, b] Support: [a, b]</p> Properties <ul> <li>Maximum entropy distribution on bounded interval</li> <li>All moments exist: \ud835\udd3c[X^n] = (b^(n+1) - a^(n+1))/((n+1)(b-a))</li> <li>Order statistics have Beta distributions</li> </ul> Connection to Other Distributions <ul> <li>Standard uniform U(0,1) generates other distributions</li> <li>-log(U) ~ Exponential(1)</li> <li>U^(1/\u03b1) ~ Power distribution</li> </ul> References <p>.. [1] Johnson, N. L., Kotz, S., &amp; Balakrishnan, N. (1995).        \"Continuous Univariate Distributions\". Wiley, Vol. 2, Chapter 26.</p>"},{"location":"reference/distributions/#genjax.distributions.exponential","title":"exponential  <code>module-attribute</code>","text":"<pre><code>exponential = tfp_distribution(Exponential, name='Exponential')\n</code></pre> <p>Exponential distribution for positive continuous values.</p> Mathematical Formulation <p>PDF: f(x; \u03bb) = \u03bb exp(-\u03bbx) for x \u2265 0</p> <p>Where \u03bb &gt; 0 is the rate parameter.</p> <p>Mean: \ud835\udd3c[X] = 1/\u03bb Variance: Var[X] = 1/\u03bb\u00b2 CDF: F(x) = 1 - exp(-\u03bbx) Support: [0, \u221e)</p> Memoryless Property <p>P(X &gt; s + t | X &gt; s) = P(X &gt; t)</p> <p>The only continuous distribution with this property.</p> Connection to Other Distributions <ul> <li>Special case of Gamma(1, \u03bb)</li> <li>-log(U) ~ Exponential(1) where U ~ Uniform(0,1)</li> <li>Minimum of n Exponential(\u03bb) ~ Exponential(n\u03bb)</li> <li>Sum of n Exponential(\u03bb) ~ Gamma(n, \u03bb)</li> </ul>"},{"location":"reference/distributions/#genjax.distributions.poisson","title":"poisson  <code>module-attribute</code>","text":"<pre><code>poisson = tfp_distribution(Poisson, name='Poisson')\n</code></pre> <p>Poisson distribution for count data.</p> Mathematical Formulation <p>PMF: P(X = k) = (\u03bb^k / k!) \u00d7 exp(-\u03bb) for k \u2208 {0, 1, 2, ...}</p> <p>Where \u03bb &gt; 0 is the rate parameter (expected count).</p> <p>Mean: \ud835\udd3c[X] = \u03bb Variance: Var[X] = \u03bb MGF: M(t) = exp(\u03bb(e^t - 1)) Support: {0, 1, 2, ...}</p> Properties <ul> <li>Mean equals variance (equidispersion)</li> <li>Sum of Poissons: X\u2081 ~ Pois(\u03bb\u2081), X\u2082 ~ Pois(\u03bb\u2082) \u21d2 X\u2081+X\u2082 ~ Pois(\u03bb\u2081+\u03bb\u2082)</li> <li>Limit of Binomial: Bin(n,p) \u2192 Pois(np) as n\u2192\u221e, p\u21920, np=\u03bb</li> </ul> Connection to Other Distributions <ul> <li>Poisson process: Inter-arrival times ~ Exponential(\u03bb)</li> <li>Large \u03bb: Approximately Normal(\u03bb, \u03bb)</li> <li>Conditional on rate: If \u03bb ~ Gamma(\u03b1,\u03b2), then X ~ NegBin(\u03b1, \u03b2/(1+\u03b2))</li> </ul> References <p>.. [1] Johnson, N. L., Kotz, S., &amp; Kemp, A. W. (1992). \"Univariate        Discrete Distributions\". Wiley, Chapter 4. .. [2] Haight, F. A. (1967). \"Handbook of the Poisson Distribution\".        Wiley.</p>"},{"location":"reference/distributions/#genjax.distributions.multivariate_normal","title":"multivariate_normal  <code>module-attribute</code>","text":"<pre><code>multivariate_normal = tfp_distribution(MultivariateNormalFullCovariance, name='MultivariateNormal')\n</code></pre> <p>Multivariate normal distribution.</p> Mathematical Formulation <p>PDF: f(x; \u03bc, \u03a3) = (2\u03c0)^(-k/2) |det(\u03a3)|^(-1/2) exp(-\u00bd(x-\u03bc)^T \u03a3^(-1) (x-\u03bc))</p> <p>Where \u03bc \u2208 \u211d^k is the mean vector, \u03a3 is k\u00d7k positive definite covariance.</p> <p>Mean: \ud835\udd3c[X] = \u03bc Covariance: Cov[X] = \u03a3 MGF: M(t) = exp(t^T\u03bc + \u00bdt^T\u03a3t) Support: \u211d^k</p> Properties <ul> <li>Linear transformations: If Y = AX + b, then Y ~ N(A\u03bc + b, A\u03a3A^T)</li> <li>Marginals are Normal: X_i ~ N(\u03bc_i, \u03a3_{ii})</li> <li>Conditional distributions are Normal with closed-form parameters</li> <li>Maximum entropy for fixed mean and covariance</li> </ul> Special Cases <ul> <li>\u03a3 = \u03c3\u00b2I: Spherical/isotropic Gaussian</li> <li>\u03a3 diagonal: Independent components</li> <li>k = 1: Univariate normal</li> </ul> References <p>.. [1] Mardia, K. V., Kent, J. T., &amp; Bibby, J. M. (1979). \"Multivariate        Analysis\". Academic Press, Chapter 3. .. [2] Tong, Y. L. (1990). \"The Multivariate Normal Distribution\".        Springer-Verlag.</p>"},{"location":"reference/distributions/#genjax.distributions.dirichlet","title":"dirichlet  <code>module-attribute</code>","text":"<pre><code>dirichlet = tfp_distribution(Dirichlet, name='Dirichlet')\n</code></pre> <p>Dirichlet distribution for probability vectors.</p> Mathematical Formulation <p>PDF: f(x; \u03b1) = [\u0393(\u2211\u1d62\u03b1\u1d62)/\u220f\u1d62\u0393(\u03b1\u1d62)] \u00d7 \u220f\u1d62 x\u1d62^(\u03b1\u1d62-1)</p> <p>Where x \u2208 \u03b4_{k-1} (probability simplex), \u03b1\u1d62 &gt; 0 are concentrations.</p> <p>Mean: \ud835\udd3c[X\u1d62] = \u03b1\u1d62 / \u2211\u2c7c\u03b1\u2c7c Variance: Var[X\u1d62] = [\u03b1\u1d62(\u03b1\u2080-\u03b1\u1d62)] / [\u03b1\u2080\u00b2(\u03b1\u2080+1)], where \u03b1\u2080 = \u2211\u2c7c\u03b1\u2c7c Support: \u03b4_{k-1} = {x \u2208 \u211d^k : x\u1d62 \u2265 0, \u2211\u1d62x\u1d62 = 1}</p> Properties <ul> <li>Conjugate prior for categorical/multinomial</li> <li>Marginals: X\u1d62 ~ Beta(\u03b1\u1d62, \u2211\u2c7c\u2260\u1d62\u03b1\u2c7c)</li> <li>Aggregation property: (X\u1d62 + X\u2c7c, X_rest) follows lower-dim Dirichlet</li> <li>Neutral element: Dir(1, 1, ..., 1) = Uniform on simplex</li> </ul> Connection to Other Distributions <ul> <li>k=2: Dir(\u03b1\u2081, \u03b1\u2082) equivalent to Beta(\u03b1\u2081, \u03b1\u2082)</li> <li>Gamma construction: If Y\u1d62 ~ Gamma(\u03b1\u1d62, 1), then Y/\u2211Y ~ Dir(\u03b1)</li> <li>Log-normal approximation for large \u03b1</li> </ul> References <p>.. [1] Kotz, S., Balakrishnan, N., &amp; Johnson, N. L. (2000). \"Continuous        Multivariate Distributions\". Wiley, Vol. 1, Chapter 49. .. [2] Ng, K. W., Tian, G. L., &amp; Tang, M. L. (2011). \"Dirichlet and        Related Distributions\". Wiley.</p>"},{"location":"reference/distributions/#genjax.distributions.binomial","title":"binomial  <code>module-attribute</code>","text":"<pre><code>binomial = tfp_distribution(Binomial, name='Binomial')\n</code></pre> <p>Binomial distribution for count data with fixed number of trials.</p> Mathematical Formulation <p>PMF: P(X = k) = C(n,k) \u00d7 p^k \u00d7 (1-p)^(n-k) for k \u2208 {0, 1, ..., n}</p> <p>Where n is the number of trials, p is success probability, and C(n,k) = n!/(k!(n-k)!) is the binomial coefficient.</p> <p>Mean: \ud835\udd3c[X] = np Variance: Var[X] = np(1-p) MGF: M(t) = (1 - p + pe<sup>t)</sup>n Support: {0, 1, 2, ..., n}</p> Properties <ul> <li>Sum of Bernoulli: X = \u2211\u1d62 Y\u1d62 where Y\u1d62 ~ Bernoulli(p)</li> <li>Additivity: Bin(n\u2081,p) + Bin(n\u2082,p) = Bin(n\u2081+n\u2082,p)</li> <li>Symmetry: If p = 0.5, then P(X = k) = P(X = n-k)</li> </ul> Approximations <ul> <li>Normal: For large n, np(1-p) &gt; 10, approximately N(np, np(1-p))</li> <li>Poisson: For large n, small p, np = \u03bb moderate, approximately Pois(\u03bb)</li> </ul> References <p>.. [1] Johnson, N. L., Kotz, S., &amp; Kemp, A. W. (1992). \"Univariate        Discrete Distributions\". Wiley, Chapter 3.</p>"},{"location":"reference/distributions/#genjax.distributions.gamma","title":"gamma  <code>module-attribute</code>","text":"<pre><code>gamma = tfp_distribution(Gamma, name='Gamma')\n</code></pre> <p>Gamma distribution for positive continuous values.</p> Mathematical Formulation <p>PDF: f(x; \u03b1, \u03b2) = (\u03b2^\u03b1 / \u0393(\u03b1)) \u00d7 x^(\u03b1-1) \u00d7 exp(-\u03b2x) for x &gt; 0</p> <p>Where \u03b1 &gt; 0 is the shape, \u03b2 &gt; 0 is the rate (or \u03b8 = 1/\u03b2 is scale).</p> <p>Mean: \ud835\udd3c[X] = \u03b1/\u03b2 = \u03b1\u03b8 Variance: Var[X] = \u03b1/\u03b2\u00b2 = \u03b1\u03b8\u00b2 Mode: (\u03b1-1)/\u03b2 for \u03b1 \u2265 1 Support: (0, \u221e)</p> Special Cases <ul> <li>\u03b1 = 1: Exponential(\u03b2)</li> <li>\u03b1 = k/2, \u03b2 = 1/2: Chi-squared(k)</li> <li>Integer \u03b1: Erlang distribution</li> </ul> Properties <ul> <li>Additivity: Gamma(\u03b1\u2081,\u03b2) + Gamma(\u03b1\u2082,\u03b2) = Gamma(\u03b1\u2081+\u03b1\u2082,\u03b2)</li> <li>Scaling: cX ~ Gamma(\u03b1, \u03b2/c) for c &gt; 0</li> <li>Conjugate prior for Poisson rate, exponential rate</li> </ul> Connection to Other Distributions <ul> <li>If X\u1d62 ~ Gamma(\u03b1\u1d62, 1), then X\u1d62/\u2211X\u2c7c ~ Dirichlet(\u03b1)</li> <li>Inverse: 1/X ~ InverseGamma(\u03b1, \u03b2)</li> </ul> References <p>.. [1] Johnson, N. L., Kotz, S., &amp; Balakrishnan, N. (1994). \"Continuous        Univariate Distributions\". Wiley, Vol. 1, Chapter 17.</p>"},{"location":"reference/distributions/#genjax.distributions.log_normal","title":"log_normal  <code>module-attribute</code>","text":"<pre><code>log_normal = tfp_distribution(LogNormal, name='LogNormal')\n</code></pre> <p>Log-normal distribution (exponential of normal random variable).</p> Mathematical Formulation <p>If Y ~ N(\u03bc, \u03c3\u00b2), then X = exp(Y) ~ LogNormal(\u03bc, \u03c3\u00b2)</p> <p>PDF: f(x; \u03bc, \u03c3) = (1/(x\u03c3\u221a(2\u03c0))) \u00d7 exp(-(ln(x)-\u03bc)\u00b2/(2\u03c3\u00b2)) for x &gt; 0</p> <p>Mean: \ud835\udd3c[X] = exp(\u03bc + \u03c3\u00b2/2) Variance: Var[X] = (exp(\u03c3\u00b2) - 1) \u00d7 exp(2\u03bc + \u03c3\u00b2) Mode: exp(\u03bc - \u03c3\u00b2) Support: (0, \u221e)</p> Properties <ul> <li>Multiplicative: If X\u1d62 ~ LogN(\u03bc\u1d62, \u03c3\u1d62\u00b2) independent, then \u220fX\u1d62 is log-normal</li> <li>Not closed under addition (sum of log-normals is not log-normal)</li> <li>Heavy right tail: all moments exist but grow rapidly</li> <li>Median: exp(\u03bc)</li> </ul> Applications <ul> <li>Income distributions</li> <li>Stock prices (geometric Brownian motion)</li> <li>Particle sizes</li> <li>Species abundance</li> </ul> References <p>.. [1] Crow, E. L., &amp; Shimizu, K. (Eds.). (1988). \"Lognormal Distributions:        Theory and Applications\". Marcel Dekker. .. [2] Limpert, E., Stahel, W. A., &amp; Abbt, M. (2001). \"Log-normal        distributions across the sciences\". BioScience, 51(5), 341-352.</p>"},{"location":"reference/distributions/#genjax.distributions.student_t","title":"student_t  <code>module-attribute</code>","text":"<pre><code>student_t = tfp_distribution(StudentT, name='StudentT')\n</code></pre> <p>Student's t-distribution with specified degrees of freedom.</p> Mathematical Formulation <p>PDF: f(x; \u03bd, \u03bc, \u03c3) = \u0393((\u03bd+1)/2)/(\u0393(\u03bd/2)\u221a(\u03bd\u03c0)\u03c3) \u00d7 [1 + ((x-\u03bc)/\u03c3)\u00b2/\u03bd]^(-(\u03bd+1)/2)</p> <p>Where \u03bd &gt; 0 is degrees of freedom, \u03bc is location, \u03c3 &gt; 0 is scale.</p> <p>Mean: \ud835\udd3c[X] = \u03bc for \u03bd &gt; 1 (undefined for \u03bd \u2264 1) Variance: Var[X] = \u03c3\u00b2\u03bd/(\u03bd-2) for \u03bd &gt; 2 (infinite for 1 &lt; \u03bd \u2264 2) Support: \u211d</p> Properties <ul> <li>Heavier tails than normal (polynomial vs exponential decay)</li> <li>\u03bd \u2192 \u221e: Converges to Normal(\u03bc, \u03c3\u00b2)</li> <li>\u03bd = 1: Cauchy distribution (no mean)</li> <li>\u03bd = 2: Finite mean but infinite variance</li> <li>Symmetric about \u03bc</li> </ul> Standardized Form <p>If T ~ t(\u03bd), then X = \u03bc + \u03c3T ~ t(\u03bd, \u03bc, \u03c3)</p> Connection to Other Distributions <ul> <li>Ratio of normal to chi: If Z ~ N(0,1), V ~ \u03c7\u00b2(\u03bd), then Z/\u221a(V/\u03bd) ~ t(\u03bd)</li> <li>F-distribution: T\u00b2 ~ F(1, \u03bd) if T ~ t(\u03bd)</li> </ul> References <p>.. [1] Lange, K. L., Little, R. J., &amp; Taylor, J. M. (1989). \"Robust        statistical modeling using the t distribution\". JASA, 84(408), 881-896. .. [2] Kotz, S., &amp; Nadarajah, S. (2004). \"Multivariate t-distributions        and their applications\". Cambridge University Press.</p>"},{"location":"reference/distributions/#genjax.distributions.laplace","title":"laplace  <code>module-attribute</code>","text":"<pre><code>laplace = tfp_distribution(Laplace, name='Laplace')\n</code></pre> <p>Laplace (double exponential) distribution.</p>"},{"location":"reference/distributions/#genjax.distributions.half_normal","title":"half_normal  <code>module-attribute</code>","text":"<pre><code>half_normal = tfp_distribution(HalfNormal, name='HalfNormal')\n</code></pre> <p>Half-normal distribution (positive half of normal distribution).</p>"},{"location":"reference/distributions/#genjax.distributions.inverse_gamma","title":"inverse_gamma  <code>module-attribute</code>","text":"<pre><code>inverse_gamma = tfp_distribution(InverseGamma, name='InverseGamma')\n</code></pre> <p>Inverse gamma distribution for positive continuous values.</p>"},{"location":"reference/distributions/#genjax.distributions.weibull","title":"weibull  <code>module-attribute</code>","text":"<pre><code>weibull = tfp_distribution(Weibull, name='Weibull')\n</code></pre> <p>Weibull distribution for modeling survival times and reliability.</p>"},{"location":"reference/distributions/#genjax.distributions.cauchy","title":"cauchy  <code>module-attribute</code>","text":"<pre><code>cauchy = tfp_distribution(Cauchy, name='Cauchy')\n</code></pre> <p>Cauchy distribution with heavy tails.</p>"},{"location":"reference/distributions/#genjax.distributions.chi2","title":"chi2  <code>module-attribute</code>","text":"<pre><code>chi2 = tfp_distribution(Chi2, name='Chi2')\n</code></pre> <p>Chi-squared distribution.</p>"},{"location":"reference/distributions/#genjax.distributions.multinomial","title":"multinomial  <code>module-attribute</code>","text":"<pre><code>multinomial = tfp_distribution(Multinomial, name='Multinomial')\n</code></pre> <p>Multinomial distribution over count vectors.</p>"},{"location":"reference/distributions/#genjax.distributions.negative_binomial","title":"negative_binomial  <code>module-attribute</code>","text":"<pre><code>negative_binomial = tfp_distribution(NegativeBinomial, name='NegativeBinomial')\n</code></pre> <p>Negative binomial distribution for overdispersed count data.</p>"},{"location":"reference/distributions/#genjax.distributions.zipf","title":"zipf  <code>module-attribute</code>","text":"<pre><code>zipf = tfp_distribution(Zipf, name='Zipf')\n</code></pre> <p>Zipf distribution for power-law distributed discrete data.</p>"},{"location":"reference/distributions/#available-distributions","title":"Available Distributions","text":""},{"location":"reference/distributions/#continuous-distributions","title":"Continuous Distributions","text":"<ul> <li>normal: Normal (Gaussian) distribution</li> <li>uniform: Uniform distribution over an interval</li> <li>beta: Beta distribution</li> <li>gamma: Gamma distribution</li> <li>exponential: Exponential distribution</li> <li>cauchy: Cauchy distribution</li> <li>student_t: Student's t-distribution</li> </ul>"},{"location":"reference/distributions/#discrete-distributions","title":"Discrete Distributions","text":"<ul> <li>bernoulli: Bernoulli distribution (binary outcomes)</li> <li>categorical: Categorical distribution over finite outcomes</li> <li>poisson: Poisson distribution</li> <li>binomial: Binomial distribution</li> <li>geometric: Geometric distribution</li> </ul>"},{"location":"reference/distributions/#usage-examples","title":"Usage Examples","text":"<pre><code>from genjax import distributions\n\n# Continuous distributions\nx = distributions.normal(0.0, 1.0) @ \"x\"\np = distributions.beta(2.0, 2.0) @ \"p\"\nrate = distributions.gamma(1.0, 1.0) @ \"rate\"\n\n# Discrete distributions\ncoin = distributions.bernoulli(0.5) @ \"coin\"\ncategory = distributions.categorical(jnp.array([0.2, 0.3, 0.5])) @ \"category\"\ncount = distributions.poisson(3.0) @ \"count\"\n</code></pre>"},{"location":"reference/distributions/#vectorized-sampling","title":"Vectorized Sampling","text":"<p>All distributions support vectorization via <code>vmap()</code>:</p> <pre><code># Sample 100 values from a normal distribution\nsamples = distributions.normal(0, 1).vmap().apply(jnp.arange(100))\n</code></pre>"},{"location":"reference/mcmc/","title":"genjax.inference.mcmc","text":"<p>Markov Chain Monte Carlo algorithms for probabilistic inference.</p>"},{"location":"reference/mcmc/#genjax.inference.mcmc","title":"mcmc","text":"<p>MCMC (Markov Chain Monte Carlo) inference algorithms for GenJAX.</p> <p>This module provides implementations of standard MCMC algorithms including Metropolis-Hastings, MALA (Metropolis-Adjusted Langevin Algorithm), and HMC (Hamiltonian Monte Carlo). All algorithms use the GFI (Generative Function Interface) for efficient trace operations.</p>"},{"location":"reference/mcmc/#genjax.inference.mcmc--references","title":"References","text":"<p>Metropolis-Hastings Algorithm: - Metropolis, N., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. H., &amp; Teller, E. (1953).   \"Equation of state calculations by fast computing machines.\"   The Journal of Chemical Physics, 21(6), 1087-1092. - Hastings, W. K. (1970). \"Monte Carlo sampling methods using Markov chains and their applications.\"   Biometrika, 57(1), 97-109.</p> <p>MALA (Metropolis-Adjusted Langevin Algorithm): - Roberts, G. O., &amp; Tweedie, R. L. (1996). \"Exponential convergence of Langevin distributions   and their discrete approximations.\" Bernoulli, 2(4), 341-363. - Roberts, G. O., &amp; Rosenthal, J. S. (1998). \"Optimal scaling of discrete approximations to   Langevin diffusions.\" Journal of the Royal Statistical Society: Series B, 60(1), 255-268.</p> <p>HMC (Hamiltonian Monte Carlo): - Neal, R. M. (2011). \"MCMC Using Hamiltonian Dynamics\", Handbook of Markov Chain Monte Carlo,   pp. 113-162. URL: http://www.mcmchandbook.net/HandbookChapter5.pdf - Duane, S., Kennedy, A. D., Pendleton, B. J., &amp; Roweth, D. (1987). \"Hybrid Monte Carlo.\"   Physics Letters B, 195(2), 216-222.</p> <p>Implementation Reference: - Gen.jl MALA implementation: https://github.com/probcomp/Gen.jl/blob/master/src/inference/mala.jl - Gen.jl HMC implementation: https://github.com/probcomp/Gen.jl/blob/master/src/inference/hmc.jl</p>"},{"location":"reference/mcmc/#genjax.inference.mcmc.MCMCResult","title":"MCMCResult","text":"<p>               Bases: <code>Pytree</code></p> <p>Result of MCMC chain sampling containing traces and diagnostics.</p>"},{"location":"reference/mcmc/#genjax.inference.mcmc.compute_rhat","title":"compute_rhat","text":"<pre><code>compute_rhat(samples: ndarray) -&gt; FloatArray\n</code></pre> <p>Compute potential scale reduction factor (R-hat) for MCMC convergence diagnostics.</p> <p>Implements the split-R-hat diagnostic from Vehtari et al. (2021), which improves upon the original formulation of Gelman &amp; Rubin (1992) by accounting for non-stationarity within chains.</p> Mathematical Formulation <p>Given M chains each of length N, compute:</p> <p>B = N/(M-1) * \u03a3\u1d62 (\u03b8\u0304\u1d62 - \u03b8\u0304)\u00b2  (between-chain variance) W = 1/M * \u03a3\u1d62 s\u1d62\u00b2             (within-chain variance)</p> <p>where \u03b8\u0304\u1d62 is the mean of chain i, \u03b8\u0304 is the grand mean, and s\u1d62\u00b2 is the sample variance of chain i.</p> <p>The potential scale reduction factor is: R\u0302 = \u221a[(N-1)/N * W + 1/N * B] / W</p> Convergence Criterion <p>R\u0302 &lt; 1.01 indicates good convergence (Vehtari et al., 2021) R\u0302 &lt; 1.1 was the classical threshold (Gelman &amp; Rubin, 1992)</p> References <p>.. [1] Gelman, A., &amp; Rubin, D. B. (1992). \"Inference from iterative        simulation using multiple sequences\". Statistical Science, 7(4), 457-472. .. [2] Vehtari, A., Gelman, A., Simpson, D., Carpenter, B., &amp; B\u00fcrkner, P. C.        (2021). \"Rank-normalization, folding, and localization: An improved R\u0302        for assessing convergence of MCMC\". Bayesian Analysis, 16(2), 667-718.</p> Notes <ul> <li>This implementation uses the basic R-hat without rank-normalization</li> <li>For rank-normalized R-hat (more robust), see [2]</li> <li>Requires at least 2 chains for meaningful computation</li> </ul> Source code in <code>src/genjax/inference/mcmc.py</code> <pre><code>def compute_rhat(samples: jnp.ndarray) -&gt; FloatArray:\n    \"\"\"\n    Compute potential scale reduction factor (R-hat) for MCMC convergence diagnostics.\n\n    Implements the split-R-hat diagnostic from Vehtari et al. (2021), which improves\n    upon the original formulation of Gelman &amp; Rubin (1992) by accounting for\n    non-stationarity within chains.\n\n    Mathematical Formulation:\n        Given M chains each of length N, compute:\n\n        B = N/(M-1) * \u03a3\u1d62 (\u03b8\u0304\u1d62 - \u03b8\u0304)\u00b2  (between-chain variance)\n        W = 1/M * \u03a3\u1d62 s\u1d62\u00b2             (within-chain variance)\n\n        where \u03b8\u0304\u1d62 is the mean of chain i, \u03b8\u0304 is the grand mean, and s\u1d62\u00b2 is\n        the sample variance of chain i.\n\n        The potential scale reduction factor is:\n        R\u0302 = \u221a[(N-1)/N * W + 1/N * B] / W\n\n    Convergence Criterion:\n        R\u0302 &lt; 1.01 indicates good convergence (Vehtari et al., 2021)\n        R\u0302 &lt; 1.1 was the classical threshold (Gelman &amp; Rubin, 1992)\n\n    Args:\n        samples: Array of shape (n_chains, n_samples) containing MCMC samples\n                 from M chains each of length N\n\n    Returns:\n        R-hat statistic. Values close to 1.0 indicate convergence.\n        Returns NaN if n_chains &lt; 2.\n\n    References:\n        .. [1] Gelman, A., &amp; Rubin, D. B. (1992). \"Inference from iterative\n               simulation using multiple sequences\". Statistical Science, 7(4), 457-472.\n        .. [2] Vehtari, A., Gelman, A., Simpson, D., Carpenter, B., &amp; B\u00fcrkner, P. C.\n               (2021). \"Rank-normalization, folding, and localization: An improved R\u0302\n               for assessing convergence of MCMC\". Bayesian Analysis, 16(2), 667-718.\n\n    Notes:\n        - This implementation uses the basic R-hat without rank-normalization\n        - For rank-normalized R-hat (more robust), see [2]\n        - Requires at least 2 chains for meaningful computation\n    \"\"\"\n    n_chains, n_samples = samples.shape\n\n    # For R-hat, we need at least 2 chains and enough samples\n    if n_chains &lt; 2:\n        return jnp.nan\n\n    # Use all samples for simpler computation\n    # Compute chain means\n    chain_means = jnp.mean(samples, axis=1)  # (n_chains,)\n\n    # Between-chain variance\n    B = n_samples * jnp.var(chain_means, ddof=1)\n\n    # Within-chain variance\n    chain_vars = jnp.var(samples, axis=1, ddof=1)  # (n_chains,)\n    W = jnp.mean(chain_vars)\n\n    # Pooled variance estimate\n    var_plus = ((n_samples - 1) * W + B) / n_samples\n\n    # R-hat statistic\n    rhat = jnp.sqrt(var_plus / W)\n\n    return rhat\n</code></pre>"},{"location":"reference/mcmc/#genjax.inference.mcmc.compute_ess","title":"compute_ess","text":"<pre><code>compute_ess(samples: ndarray, kind: str = 'bulk') -&gt; FloatArray\n</code></pre> <p>Compute effective sample size (ESS) for MCMC chains.</p> <p>Estimates the number of independent samples accounting for autocorrelation in Markov chains. Implements simplified versions of bulk and tail ESS from Vehtari et al. (2021).</p> Mathematical Formulation <p>The effective sample size is defined as:</p> <p>ESS = M \u00d7 N / \u03c4</p> <p>where M is the number of chains, N is the chain length, and \u03c4 is the integrated autocorrelation time:</p> <p>\u03c4 = 1 + 2 \u00d7 \u03a3\u2096 \u03c1\u2096</p> <p>where \u03c1\u2096 is the autocorrelation at lag k, summed over positive correlations.</p> Algorithm <ul> <li>Bulk ESS: Uses all samples to estimate central tendency efficiency</li> <li>Tail ESS: Uses quantile differences (0.05 and 0.95) to assess tail behavior</li> </ul> <p>This implementation uses a simplified approximation based on lag-1 autocorrelation: ESS \u2248 N / (1 + 2\u03c1\u2081)</p> <p>Time Complexity: O(M \u00d7 N) Space Complexity: O(1)</p> References <p>.. [1] Geyer, C. J. (1992). \"Practical Markov chain Monte Carlo\".        Statistical Science, 7(4), 473-483. .. [2] Vehtari, A., Gelman, A., Simpson, D., Carpenter, B., &amp; B\u00fcrkner, P. C.        (2021). \"Rank-normalization, folding, and localization: An improved R\u0302        for assessing convergence of MCMC\". Bayesian Analysis, 16(2), 667-718. .. [3] Stan Development Team (2023). \"Stan Reference Manual: Effective        Sample Size\". Version 2.33. Section 15.4.</p> Notes <ul> <li>This is a simplified implementation using lag-1 autocorrelation</li> <li>Full implementation would compute autocorrelation function to first negative</li> <li>Tail ESS focuses on extreme quantiles, useful for credible intervals</li> <li>Bulk ESS focuses on center, useful for posterior expectations</li> </ul> Source code in <code>src/genjax/inference/mcmc.py</code> <pre><code>def compute_ess(samples: jnp.ndarray, kind: str = \"bulk\") -&gt; FloatArray:\n    \"\"\"\n    Compute effective sample size (ESS) for MCMC chains.\n\n    Estimates the number of independent samples accounting for autocorrelation\n    in Markov chains. Implements simplified versions of bulk and tail ESS from\n    Vehtari et al. (2021).\n\n    Mathematical Formulation:\n        The effective sample size is defined as:\n\n        ESS = M \u00d7 N / \u03c4\n\n        where M is the number of chains, N is the chain length, and \u03c4 is the\n        integrated autocorrelation time:\n\n        \u03c4 = 1 + 2 \u00d7 \u03a3\u2096 \u03c1\u2096\n\n        where \u03c1\u2096 is the autocorrelation at lag k, summed over positive correlations.\n\n    Algorithm:\n        - Bulk ESS: Uses all samples to estimate central tendency efficiency\n        - Tail ESS: Uses quantile differences (0.05 and 0.95) to assess tail behavior\n\n        This implementation uses a simplified approximation based on lag-1\n        autocorrelation: ESS \u2248 N / (1 + 2\u03c1\u2081)\n\n    Time Complexity: O(M \u00d7 N)\n    Space Complexity: O(1)\n\n    Args:\n        samples: Array of shape (n_chains, n_samples) containing MCMC samples\n        kind: Type of ESS to compute:\n              - \"bulk\": Efficiency for estimating posterior mean/median\n              - \"tail\": Efficiency for estimating posterior quantiles\n\n    Returns:\n        Effective sample size estimate. Range: [1, M \u00d7 N]\n        Lower values indicate higher autocorrelation.\n\n    References:\n        .. [1] Geyer, C. J. (1992). \"Practical Markov chain Monte Carlo\".\n               Statistical Science, 7(4), 473-483.\n        .. [2] Vehtari, A., Gelman, A., Simpson, D., Carpenter, B., &amp; B\u00fcrkner, P. C.\n               (2021). \"Rank-normalization, folding, and localization: An improved R\u0302\n               for assessing convergence of MCMC\". Bayesian Analysis, 16(2), 667-718.\n        .. [3] Stan Development Team (2023). \"Stan Reference Manual: Effective\n               Sample Size\". Version 2.33. Section 15.4.\n\n    Notes:\n        - This is a simplified implementation using lag-1 autocorrelation\n        - Full implementation would compute autocorrelation function to first negative\n        - Tail ESS focuses on extreme quantiles, useful for credible intervals\n        - Bulk ESS focuses on center, useful for posterior expectations\n    \"\"\"\n    n_chains, n_samples = samples.shape\n\n    if kind == \"tail\":\n        # For tail ESS, use quantile-based approach\n        # Transform samples to focus on tails\n        quantiles = jnp.array([0.05, 0.95])\n        tail_samples = jnp.quantile(samples, quantiles, axis=1)\n        # Use difference between quantiles as the statistic\n        samples_for_ess = tail_samples[1] - tail_samples[0]\n        samples_for_ess = samples_for_ess.reshape(1, -1)\n    else:\n        # For bulk ESS, use all samples\n        samples_for_ess = samples.reshape(1, -1)\n\n    # Simple ESS approximation based on autocorrelation\n    # This is a simplified version - a full implementation would compute\n    # autocorrelation function and find cutoff\n\n    # Compute autocorrelation at lag 1 as rough approximation\n    flat_samples = samples_for_ess.flatten()\n\n    # Autocorrelation at lag 1\n    lag1_corr = jnp.corrcoef(flat_samples[:-1], flat_samples[1:])[0, 1]\n    lag1_corr = jnp.clip(lag1_corr, 0.0, 0.99)  # Avoid division issues\n\n    # Simple ESS approximation: N / (1 + 2*rho)\n    # where rho is the sum of positive autocorrelations\n    effective_chains = n_chains if kind == \"bulk\" else 1\n    total_samples = effective_chains * n_samples\n    ess = total_samples / (1 + 2 * lag1_corr)\n\n    return ess\n</code></pre>"},{"location":"reference/mcmc/#genjax.inference.mcmc.mh","title":"mh","text":"<pre><code>mh(current_trace: Trace[X, R], selection: Selection) -&gt; Trace[X, R]\n</code></pre> <p>Single Metropolis-Hastings step using GFI.regenerate.</p> <p>Uses the trace's generative function regenerate method to propose new values for selected addresses and computes MH accept/reject ratio.</p> State <p>accept: Boolean indicating whether the proposal was accepted</p> Source code in <code>src/genjax/inference/mcmc.py</code> <pre><code>def mh(\n    current_trace: Trace[X, R],\n    selection: Selection,\n) -&gt; Trace[X, R]:\n    \"\"\"\n    Single Metropolis-Hastings step using GFI.regenerate.\n\n    Uses the trace's generative function regenerate method to propose\n    new values for selected addresses and computes MH accept/reject ratio.\n\n    Args:\n        current_trace: Current trace state\n        selection: Addresses to regenerate (subset of choices)\n\n    Returns:\n        Updated trace after MH step\n\n    State:\n        accept: Boolean indicating whether the proposal was accepted\n    \"\"\"\n    target_gf = current_trace.get_gen_fn()\n    args = current_trace.get_args()\n\n    # Regenerate selected addresses - weight is log acceptance probability\n    new_trace, log_weight, _ = target_gf.regenerate(\n        current_trace, selection, *args[0], **args[1]\n    )\n\n    # MH acceptance step in log space\n    log_alpha = jnp.minimum(0.0, log_weight)  # log(min(1, exp(log_weight)))\n\n    # Accept or reject using GenJAX uniform distribution in log space\n    log_u = jnp.log(uniform.sample(0.0, 1.0))\n    accept = log_u &lt; log_alpha\n\n    # Use tree_map to apply select across all leaves of the traces\n    final_trace = jtu.tree_map(\n        lambda new_leaf, old_leaf: jax.lax.select(accept, new_leaf, old_leaf),\n        new_trace,\n        current_trace,\n    )\n\n    # Save acceptance as auxiliary state (can be accessed via state decorator)\n    save(accept=accept)\n\n    return final_trace\n</code></pre>"},{"location":"reference/mcmc/#genjax.inference.mcmc.mala","title":"mala","text":"<pre><code>mala(current_trace: Trace[X, R], selection: Selection, step_size: float) -&gt; Trace[X, R]\n</code></pre> <p>Single MALA (Metropolis-Adjusted Langevin Algorithm) step.</p> <p>MALA uses gradient information to make more efficient proposals than standard Metropolis-Hastings. The proposal distribution is:</p> <p>x_proposed = x_current + step_size^2/2 * \u2207log(p(x)) + step_size * \u03b5</p> <p>where \u03b5 ~ N(0, I) is standard Gaussian noise.</p> <p>This implementation follows the approach from Gen.jl, computing both forward and backward proposal probabilities to account for the asymmetric drift term in the MALA proposal.</p> State <p>accept: Boolean indicating whether the proposal was accepted</p> Source code in <code>src/genjax/inference/mcmc.py</code> <pre><code>def mala(\n    current_trace: Trace[X, R],\n    selection: Selection,\n    step_size: float,\n) -&gt; Trace[X, R]:\n    \"\"\"\n    Single MALA (Metropolis-Adjusted Langevin Algorithm) step.\n\n    MALA uses gradient information to make more efficient proposals than\n    standard Metropolis-Hastings. The proposal distribution is:\n\n    x_proposed = x_current + step_size^2/2 * \u2207log(p(x)) + step_size * \u03b5\n\n    where \u03b5 ~ N(0, I) is standard Gaussian noise.\n\n    This implementation follows the approach from Gen.jl, computing both\n    forward and backward proposal probabilities to account for the asymmetric\n    drift term in the MALA proposal.\n\n    Args:\n        current_trace: Current trace state\n        selection: Addresses to regenerate (subset of choices)\n        step_size: Step size parameter (\u03c4) controlling proposal variance\n\n    Returns:\n        Updated trace after MALA step\n\n    State:\n        accept: Boolean indicating whether the proposal was accepted\n    \"\"\"\n    target_gf = current_trace.get_gen_fn()\n    args = current_trace.get_args()\n    current_choices = current_trace.get_choices()\n\n    # Use the new GFI.filter method to extract selected choices\n    selected_choices, unselected_choices = target_gf.filter(current_choices, selection)\n\n    if selected_choices is None:\n        # No choices selected, return current trace unchanged\n        save(accept=True)\n        return current_trace\n\n    # Create closure to compute gradients with respect to only selected choices\n    log_density_wrt_selected = _create_log_density_wrt_selected(\n        target_gf, args, unselected_choices\n    )\n\n    # Get gradients with respect to selected choices only\n    selected_gradients = jax.grad(log_density_wrt_selected)(selected_choices)\n\n    # Generate MALA proposal for selected choices using tree operations\n    def mala_proposal_fn(current_val, grad_val):\n        # MALA drift term: step_size^2/2 * gradient\n        drift = (step_size**2 / 2.0) * grad_val\n\n        # Gaussian noise term: step_size * N(0,1)\n        noise = step_size * normal.sample(0.0, 1.0)\n\n        # Proposed value\n        return current_val + drift + noise\n\n    def mala_log_prob_fn(current_val, proposed_val, grad_val):\n        # MALA proposal log probability: N(current + drift, step_size)\n        drift = (step_size**2 / 2.0) * grad_val\n        mean = current_val + drift\n        log_probs = normal.logpdf(proposed_val, mean, step_size)\n        # Sum over all dimensions to get scalar log probability\n        return jnp.sum(log_probs)\n\n    # Apply MALA proposal to all selected choices\n    proposed_selected = jtu.tree_map(\n        mala_proposal_fn, selected_choices, selected_gradients\n    )\n\n    # Compute forward proposal log probabilities\n    forward_log_probs = jtu.tree_map(\n        mala_log_prob_fn, selected_choices, proposed_selected, selected_gradients\n    )\n\n    # Update trace with only the proposed selected choices\n    # This ensures discard only contains the keys that were actually changed\n    proposed_trace, model_weight, discard = target_gf.update(\n        current_trace, proposed_selected, *args[0], **args[1]\n    )\n\n    # Get gradients at proposed point with respect to selected choices\n    backward_gradients = jax.grad(log_density_wrt_selected)(proposed_selected)\n\n    # Filter discard to only the selected addresses (in case update includes extra keys)\n    discarded_selected, _ = target_gf.filter(discard, selection)\n\n    # Compute backward proposal log probabilities using the same function\n    backward_log_probs = jtu.tree_map(\n        mala_log_prob_fn,\n        proposed_selected,\n        discarded_selected,\n        backward_gradients,\n    )\n\n    # Sum up log probabilities using tree_reduce\n    forward_log_prob_total = jtu.tree_reduce(jnp.add, forward_log_probs)\n    backward_log_prob_total = jtu.tree_reduce(jnp.add, backward_log_probs)\n\n    # MALA acceptance probability\n    # Alpha = model_weight + log P(x_old | x_new) - log P(x_new | x_old)\n    log_alpha = model_weight + backward_log_prob_total - forward_log_prob_total\n    log_alpha = jnp.minimum(0.0, log_alpha)  # min(1, exp(log_alpha))\n\n    # Accept or reject using numerically stable log comparison\n    log_u = jnp.log(uniform.sample(0.0, 1.0))\n    accept = log_u &lt; log_alpha\n\n    # Select final trace\n    final_trace = jtu.tree_map(\n        lambda new_leaf, old_leaf: jax.lax.select(accept, new_leaf, old_leaf),\n        proposed_trace,\n        current_trace,\n    )\n\n    # Save acceptance for diagnostics\n    save(accept=accept)\n\n    return final_trace\n</code></pre>"},{"location":"reference/mcmc/#genjax.inference.mcmc.hmc","title":"hmc","text":"<pre><code>hmc(current_trace: Trace[X, R], selection: Selection, step_size: float, n_steps: int) -&gt; Trace[X, R]\n</code></pre> <p>Single HMC (Hamiltonian Monte Carlo) step using leapfrog integration.</p> <p>HMC uses gradient information and auxiliary momentum variables to propose distant moves that maintain detailed balance. The algorithm simulates Hamiltonian dynamics using leapfrog integration:</p> <ol> <li>Sample momentum p ~ N(0, I)</li> <li>Simulate Hamiltonian dynamics for n_steps using leapfrog integration:</li> <li>p' = p + (eps/2) * \u2207log(p(x))</li> <li>x' = x + eps * p'</li> <li>p' = p' + (eps/2) * \u2207log(p(x'))</li> <li>Accept/reject using Metropolis criterion with joint (x,p) density</li> </ol> <p>This implementation uses jax.lax.scan for leapfrog integration, making it fully JAX-compatible and JIT-compilable. It follows Neal (2011) equations (5.18)-(5.20) and the Gen.jl HMC implementation structure.</p> State <p>accept: Boolean indicating whether the proposal was accepted</p> Source code in <code>src/genjax/inference/mcmc.py</code> <pre><code>def hmc(\n    current_trace: Trace[X, R],\n    selection: Selection,\n    step_size: float,\n    n_steps: int,\n) -&gt; Trace[X, R]:\n    \"\"\"\n    Single HMC (Hamiltonian Monte Carlo) step using leapfrog integration.\n\n    HMC uses gradient information and auxiliary momentum variables to propose\n    distant moves that maintain detailed balance. The algorithm simulates\n    Hamiltonian dynamics using leapfrog integration:\n\n    1. Sample momentum p ~ N(0, I)\n    2. Simulate Hamiltonian dynamics for n_steps using leapfrog integration:\n       - p' = p + (eps/2) * \u2207log(p(x))\n       - x' = x + eps * p'\n       - p' = p' + (eps/2) * \u2207log(p(x'))\n    3. Accept/reject using Metropolis criterion with joint (x,p) density\n\n    This implementation uses jax.lax.scan for leapfrog integration, making it\n    fully JAX-compatible and JIT-compilable. It follows Neal (2011) equations\n    (5.18)-(5.20) and the Gen.jl HMC implementation structure.\n\n    Args:\n        current_trace: Current trace state\n        selection: Addresses to regenerate (subset of choices)\n        step_size: Leapfrog integration step size (eps)\n        n_steps: Number of leapfrog steps (L)\n\n    Returns:\n        Updated trace after HMC step\n\n    State:\n        accept: Boolean indicating whether the proposal was accepted\n    \"\"\"\n    target_gf = current_trace.get_gen_fn()\n    args = current_trace.get_args()\n    current_choices = current_trace.get_choices()\n\n    # Use the new GFI.filter method to extract selected choices\n    selected_choices, unselected_choices = target_gf.filter(current_choices, selection)\n\n    if selected_choices is None:\n        # No choices selected, return current trace unchanged\n        save(accept=True)\n        return current_trace\n\n    # Create closure to compute gradients with respect to only selected choices\n    log_density_wrt_selected = _create_log_density_wrt_selected(\n        target_gf, args, unselected_choices\n    )\n\n    # Helper functions for momentum\n    def sample_momentum(_):\n        \"\"\"Sample momentum with same structure as reference value.\"\"\"\n        return normal.sample(0.0, 1.0)\n\n    def assess_momentum(momentum_val):\n        \"\"\"Compute log probability of momentum (standard normal).\"\"\"\n        return normal.logpdf(momentum_val, 0.0, 1.0)\n\n    # Initial model score (negative potential energy)\n    prev_model_score = log_density_wrt_selected(selected_choices)\n\n    # Sample initial momentum and compute its score (negative kinetic energy)\n    initial_momentum = jtu.tree_map(sample_momentum, selected_choices)\n    prev_momentum_score = jtu.tree_reduce(\n        jnp.add, jtu.tree_map(assess_momentum, initial_momentum)\n    )\n\n    # Initialize leapfrog variables\n    current_position = selected_choices\n    current_momentum = initial_momentum\n\n    # Leapfrog integration for n_steps using jax.lax.scan\n    # Initial gradient\n    current_gradient = jax.grad(log_density_wrt_selected)(current_position)\n\n    def leapfrog_step(carry, _):\n        \"\"\"Single leapfrog integration step.\"\"\"\n        position, momentum, gradient = carry\n\n        # Half step on momentum\n        momentum = jtu.tree_map(\n            lambda p, g: p + (step_size / 2.0) * g, momentum, gradient\n        )\n\n        # Full step on position\n        position = jtu.tree_map(lambda x, p: x + step_size * p, position, momentum)\n\n        # Get new gradient at new position\n        gradient = jax.grad(log_density_wrt_selected)(position)\n\n        # Half step on momentum (completing the leapfrog step)\n        momentum = jtu.tree_map(\n            lambda p, g: p + (step_size / 2.0) * g, momentum, gradient\n        )\n\n        new_carry = (position, momentum, gradient)\n        return new_carry, None  # No output needed, just carry\n\n    # Run leapfrog integration\n    initial_carry = (current_position, current_momentum, current_gradient)\n    final_carry, _ = jax.lax.scan(leapfrog_step, initial_carry, jnp.arange(n_steps))\n\n    # Extract final position and momentum\n    final_position, final_momentum, _ = final_carry\n\n    # Update trace with proposed final position\n    proposed_trace, model_weight, discard = target_gf.update(\n        current_trace, final_position, *args[0], **args[1]\n    )\n\n    # Compute final model score (negative potential energy)\n    new_model_score = log_density_wrt_selected(final_position)\n\n    # Compute final momentum score (negative kinetic energy)\n    # Note: In HMC, we evaluate momentum at negated final momentum to account for\n    # the reversibility requirement of Hamiltonian dynamics\n    final_momentum_negated = jtu.tree_map(lambda p: -p, final_momentum)\n    new_momentum_score = jtu.tree_reduce(\n        jnp.add, jtu.tree_map(assess_momentum, final_momentum_negated)\n    )\n\n    # HMC acceptance probability\n    # alpha = (new_model_score + new_momentum_score) - (prev_model_score + prev_momentum_score)\n    # This is equivalent to the energy difference: -\u0394H = -(\u0394U + \u0394K)\n    log_alpha = (new_model_score + new_momentum_score) - (\n        prev_model_score + prev_momentum_score\n    )\n    log_alpha = jnp.minimum(0.0, log_alpha)  # min(1, exp(log_alpha))\n\n    # Accept or reject using numerically stable log comparison\n    log_u = jnp.log(uniform.sample(0.0, 1.0))\n    accept = log_u &lt; log_alpha\n\n    # Select final trace\n    final_trace = jtu.tree_map(\n        lambda new_leaf, old_leaf: jax.lax.select(accept, new_leaf, old_leaf),\n        proposed_trace,\n        current_trace,\n    )\n\n    # Save acceptance for diagnostics\n    save(accept=accept)\n\n    return final_trace\n</code></pre>"},{"location":"reference/mcmc/#genjax.inference.mcmc.chain","title":"chain","text":"<pre><code>chain(mcmc_kernel: MCMCKernel)\n</code></pre> <p>Higher-order function that creates MCMC chain algorithms from simple kernels.</p> <p>This function transforms simple MCMC moves (like metropolis_hastings_step) into full-fledged MCMC algorithms with burn-in, thinning, and parallel chains. The kernel should save acceptances via state for diagnostics.</p> Note <p>The mcmc_kernel should use save(accept=...) to record acceptances for proper diagnostics collection.</p> Source code in <code>src/genjax/inference/mcmc.py</code> <pre><code>def chain(mcmc_kernel: MCMCKernel):\n    \"\"\"\n    Higher-order function that creates MCMC chain algorithms from simple kernels.\n\n    This function transforms simple MCMC moves (like metropolis_hastings_step)\n    into full-fledged MCMC algorithms with burn-in, thinning, and parallel chains.\n    The kernel should save acceptances via state for diagnostics.\n\n    Args:\n        mcmc_kernel: MCMC kernel function that takes and returns a trace\n\n    Returns:\n        Function that runs MCMC chains with burn-in, thinning, and diagnostics\n\n    Note:\n        The mcmc_kernel should use save(accept=...) to record acceptances\n        for proper diagnostics collection.\n    \"\"\"\n\n    def run_chain(\n        initial_trace: Trace[X, R],\n        n_steps: Const[int],\n        *,\n        burn_in: Const[int] = const(0),\n        autocorrelation_resampling: Const[int] = const(1),\n        n_chains: Const[int] = const(1),\n    ) -&gt; MCMCResult:\n        \"\"\"\n        Run MCMC chain with the configured kernel.\n\n        Args:\n            initial_trace: Starting trace\n            n_steps: Total number of steps to run (before burn-in/thinning)\n            burn_in: Number of initial steps to discard as burn-in\n            autocorrelation_resampling: Keep every N-th sample (thinning)\n            n_chains: Number of parallel chains to run\n\n        Returns:\n            MCMCResult with traces, acceptances, and diagnostics\n        \"\"\"\n\n        def scan_fn(trace, _):\n            new_trace = mcmc_kernel(trace)\n            return new_trace, new_trace\n\n        if n_chains.value == 1:\n            # Single chain case\n            @state  # Use state decorator to collect acceptances\n            def run_scan():\n                final_trace, all_traces = jax.lax.scan(\n                    scan_fn, initial_trace, jnp.arange(n_steps.value)\n                )\n                return all_traces\n\n            # Run chain and collect state (including accepts)\n            all_traces, chain_state = run_scan()\n\n            # Extract accepts from state\n            accepts = chain_state.get(\"accept\", jnp.zeros(n_steps.value))\n\n            # Apply burn-in and thinning\n            start_idx = burn_in.value\n            end_idx = n_steps.value\n            indices = jnp.arange(start_idx, end_idx, autocorrelation_resampling.value)\n\n            # Apply selection to traces and accepts\n            final_traces = jax.tree_util.tree_map(\n                lambda x: x[indices] if hasattr(x, \"shape\") and len(x.shape) &gt; 0 else x,\n                all_traces,\n            )\n            final_accepts = accepts[indices]\n\n            # Compute final acceptance rate\n            acceptance_rate = jnp.mean(final_accepts)\n            final_n_steps = len(indices)\n\n            return MCMCResult(\n                traces=final_traces,\n                accepts=final_accepts,\n                acceptance_rate=acceptance_rate,\n                n_steps=const(final_n_steps),\n                n_chains=n_chains,\n            )\n\n        else:\n            # Multiple chains case - use vmap to run parallel chains\n            # Vectorize the scan function over chains\n            vectorized_run = modular_vmap(\n                lambda trace: run_chain(\n                    trace,\n                    n_steps,\n                    burn_in=burn_in,\n                    autocorrelation_resampling=autocorrelation_resampling,\n                    n_chains=const(1),  # Each vectorized call runs 1 chain\n                ),\n                in_axes=0,\n            )\n\n            # Create multiple initial traces by repeating the single trace\n            # This creates independent starting points\n            initial_traces = jax.tree_util.tree_map(\n                lambda x: jnp.repeat(x[None, ...], n_chains.value, axis=0),\n                initial_trace,\n            )\n\n            # Run multiple chains in parallel\n            multi_chain_results = vectorized_run(initial_traces)\n\n            # Combine results from multiple chains\n            # Traces shape: (n_chains, n_steps, ...)\n            combined_traces = multi_chain_results.traces\n            combined_accepts = multi_chain_results.accepts  # (n_chains, n_steps)\n\n            # Per-chain acceptance rates\n            acceptance_rates = jnp.mean(combined_accepts, axis=1)  # (n_chains,)\n            overall_acceptance_rate = jnp.mean(acceptance_rates)\n\n            final_n_steps = multi_chain_results.n_steps.value\n\n            # Compute between-chain diagnostics using Pytree utilities\n            rhat_values = None\n            ess_bulk_values = None\n            ess_tail_values = None\n\n            if n_chains.value &gt; 1:\n                # Extract choices for diagnostics computation\n                choices = combined_traces.get_choices()\n\n                # Helper function to compute all diagnostics for scalar arrays\n                def compute_all_diagnostics(samples):\n                    \"\"\"Compute all diagnostics if samples are scalar over (chains, steps).\"\"\"\n                    if samples.ndim == 2:  # (n_chains, n_steps) - scalar samples\n                        rhat_val = compute_rhat(samples)\n                        ess_bulk_val = compute_ess(samples, kind=\"bulk\")\n                        ess_tail_val = compute_ess(samples, kind=\"tail\")\n                        # Return as JAX array so we can index into it\n                        return jnp.array([rhat_val, ess_bulk_val, ess_tail_val])\n                    else:\n                        # For non-scalar arrays, return NaN for all diagnostics\n                        return jnp.array([jnp.nan, jnp.nan, jnp.nan])\n\n                # Compute all diagnostics in one tree_map pass\n                all_diagnostics = jax.tree_util.tree_map(\n                    compute_all_diagnostics, choices\n                )\n\n                # Extract individual diagnostics using indexing\n                rhat_values = jax.tree_util.tree_map(lambda x: x[0], all_diagnostics)\n                ess_bulk_values = jax.tree_util.tree_map(\n                    lambda x: x[1], all_diagnostics\n                )\n                ess_tail_values = jax.tree_util.tree_map(\n                    lambda x: x[2], all_diagnostics\n                )\n\n            return MCMCResult(\n                traces=combined_traces,\n                accepts=combined_accepts,\n                acceptance_rate=overall_acceptance_rate,\n                n_steps=const(final_n_steps),\n                n_chains=n_chains,\n                rhat=rhat_values,\n                ess_bulk=ess_bulk_values,\n                ess_tail=ess_tail_values,\n            )\n\n    return run_chain\n</code></pre>"},{"location":"reference/mcmc/#available-algorithms","title":"Available Algorithms","text":""},{"location":"reference/mcmc/#metropolis_hastings","title":"metropolis_hastings","text":"<p>Basic Metropolis-Hastings algorithm with custom proposals.</p>"},{"location":"reference/mcmc/#hmc","title":"hmc","text":"<p>Hamiltonian Monte Carlo for efficient exploration of continuous spaces.</p>"},{"location":"reference/mcmc/#mala","title":"mala","text":"<p>Metropolis-Adjusted Langevin Algorithm for gradient-informed proposals.</p>"},{"location":"reference/mcmc/#usage-examples","title":"Usage Examples","text":""},{"location":"reference/mcmc/#metropolis-hastings","title":"Metropolis-Hastings","text":"<pre><code>from genjax.inference.mcmc import metropolis_hastings\nfrom genjax import select\n\n# Define selection of variables to update\nselection = select(\"mu\", \"sigma\")\n\n# Single MH step\nnew_trace = metropolis_hastings(trace, selection, key)\n\n# Run MCMC chain\ndef mcmc_step(carry, key):\n    trace = carry\n    new_trace = metropolis_hastings(trace, selection, key)\n    return new_trace, new_trace[\"mu\"]\n\nkeys = jax.random.split(key, 1000)\nfinal_trace, samples = jax.lax.scan(mcmc_step, initial_trace, keys)\n</code></pre>"},{"location":"reference/mcmc/#hamiltonian-monte-carlo","title":"Hamiltonian Monte Carlo","text":"<pre><code>from genjax.inference.mcmc import hmc\n\n# HMC with custom parameters\nnew_trace = hmc(\n    trace, \n    selection,\n    key,\n    step_size=0.01,\n    num_leapfrog_steps=10\n)\n</code></pre>"},{"location":"reference/mcmc/#best-practices","title":"Best Practices","text":"<ol> <li>Warm-up Period: Discard initial samples during burn-in</li> <li>Thinning: Keep every nth sample to reduce autocorrelation</li> <li>Multiple Chains: Run parallel chains for convergence diagnostics</li> <li>Adaptive Step Size: Tune step sizes during warm-up for HMC</li> </ol>"},{"location":"reference/smc/","title":"genjax.inference.smc","text":"<p>Sequential Monte Carlo methods for particle-based inference.</p>"},{"location":"reference/smc/#genjax.inference.smc","title":"smc","text":"<p>Standard library of programmable inference algorithms for GenJAX.</p> <p>This module provides implementations of common inference algorithms that can be composed with generative functions through the GFI (Generative Function Interface). Uses GenJAX distributions and modular_vmap for efficient vectorized computation.</p> References <p>[1] P. D. Moral, A. Doucet, and A. Jasra, \"Sequential Monte Carlo samplers,\"     Journal of the Royal Statistical Society: Series B (Statistical Methodology),     vol. 68, no. 3, pp. 411\u2013436, 2006.</p>"},{"location":"reference/smc/#genjax.inference.smc.ParticleCollection","title":"ParticleCollection","text":"<p>               Bases: <code>Pytree</code></p> <p>Result of importance sampling containing traces, weights, and statistics.</p>"},{"location":"reference/smc/#genjax.inference.smc.ParticleCollection.log_marginal_likelihood","title":"log_marginal_likelihood","text":"<pre><code>log_marginal_likelihood() -&gt; jnp.ndarray\n</code></pre> <p>Estimate log marginal likelihood using importance sampling.</p> Source code in <code>src/genjax/inference/smc.py</code> <pre><code>def log_marginal_likelihood(self) -&gt; jnp.ndarray:\n    \"\"\"\n    Estimate log marginal likelihood using importance sampling.\n\n    Returns:\n        Log marginal likelihood estimate using log-sum-exp of importance weights\n        plus any accumulated marginal estimate from previous resampling steps\n    \"\"\"\n    current_marginal = jax.scipy.special.logsumexp(self.log_weights) - jnp.log(\n        self.n_samples.value\n    )\n    return self.log_marginal_estimate + current_marginal\n</code></pre>"},{"location":"reference/smc/#genjax.inference.smc.ParticleCollection.estimate","title":"estimate","text":"<pre><code>estimate(fn: Callable[[X], Any]) -&gt; Any\n</code></pre> <p>Compute weighted estimate of a function applied to particle traces.</p> <p>Properly accounts for importance weights to give unbiased estimates.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import jax.numpy as jnp\n&gt;&gt;&gt; # particles.estimate(lambda choices: choices[\"param\"])  # Posterior mean\n&gt;&gt;&gt; # particles.estimate(lambda choices: choices[\"param\"]**2) - mean**2  # Variance\n&gt;&gt;&gt; # particles.estimate(lambda choices: jnp.sin(choices[\"x\"]) + choices[\"y\"])  # Custom\n</code></pre> Source code in <code>src/genjax/inference/smc.py</code> <pre><code>def estimate(self, fn: Callable[[X], Any]) -&gt; Any:\n    \"\"\"\n    Compute weighted estimate of a function applied to particle traces.\n\n    Properly accounts for importance weights to give unbiased estimates.\n\n    Args:\n        fn: Function to apply to each particle's choices (X -&gt; Any)\n\n    Returns:\n        Weighted estimate: sum(w_i * fn(x_i)) / sum(w_i)\n        where w_i are normalized importance weights\n\n    Examples:\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt; # particles.estimate(lambda choices: choices[\"param\"])  # Posterior mean\n        &gt;&gt;&gt; # particles.estimate(lambda choices: choices[\"param\"]**2) - mean**2  # Variance\n        &gt;&gt;&gt; # particles.estimate(lambda choices: jnp.sin(choices[\"x\"]) + choices[\"y\"])  # Custom\n    \"\"\"\n    # Get particle choices\n    choices = self.traces.get_choices()\n\n    # Apply function to each particle\n    values = jax.vmap(fn)(choices)\n\n    # Compute normalized weights (in log space for numerical stability)\n    log_weights_normalized = self.log_weights - jax.scipy.special.logsumexp(\n        self.log_weights\n    )\n    weights_normalized = jnp.exp(log_weights_normalized)\n\n    # Compute weighted average\n    # For scalar values: sum(w_i * v_i)\n    # For arrays: maintains shape of values\n    if values.ndim == 1:\n        # Simple weighted average for scalar values per particle\n        return jnp.sum(weights_normalized * values)\n    else:\n        # For multi-dimensional values, weight along the particle dimension (axis 0)\n        return jnp.sum(weights_normalized[:, None] * values, axis=0)\n</code></pre>"},{"location":"reference/smc/#genjax.inference.smc.effective_sample_size","title":"effective_sample_size","text":"<pre><code>effective_sample_size(log_weights: ndarray) -&gt; jnp.ndarray\n</code></pre> <p>Compute the effective sample size (ESS) from log importance weights.</p> <p>The ESS measures the efficiency of importance sampling by estimating the number of independent samples that would provide equivalent statistical information. It quantifies particle degeneracy in SMC algorithms.</p> Mathematical Formulation <p>Given N particles with normalized weights w\u2081, ..., w\u2099:</p> <p>ESS = 1 / \u03a3\u1d62 w\u1d62\u00b2 = (\u03a3\u1d62 w\u1d62)\u00b2 / \u03a3\u1d62 w\u1d62\u00b2</p> <p>Since \u03a3\u1d62 w\u1d62 = 1 for normalized weights:</p> <p>ESS = 1 / \u03a3\u1d62 w\u1d62\u00b2</p> Interpretation <ul> <li>ESS = N: Perfect sampling (uniform weights)</li> <li>ESS = 1: Complete degeneracy (single particle has all weight)</li> <li>ESS/N: Efficiency ratio, often used to trigger resampling when &lt; 0.5</li> </ul> Connection to Importance Sampling <p>The ESS approximates the variance inflation factor for importance sampling estimates. For self-normalized importance sampling:</p> <p>Var[\ud835\udd3c[f]] \u2248 (N/ESS) \u00d7 Var_\u03c0[f]</p> <p>where \u03c0 is the target distribution.</p> References <p>.. [1] Kong, A., Liu, J. S., &amp; Wong, W. H. (1994). \"Sequential imputations        and Bayesian missing data problems\". Journal of the American        Statistical Association, 89(425), 278-288. .. [2] Liu, J. S. (2001). \"Monte Carlo strategies in scientific computing\".        Springer, Chapter 3. .. [3] Doucet, A., de Freitas, N., &amp; Gordon, N. (2001). \"Sequential Monte        Carlo methods in practice\". Springer, Chapter 1.</p> Notes <ul> <li>Computed in log-space for numerical stability</li> <li>Input weights need not be normalized (handled internally)</li> <li>Common resampling threshold: ESS &lt; N/2 (Doucet et al., 2001)</li> </ul> Source code in <code>src/genjax/inference/smc.py</code> <pre><code>def effective_sample_size(log_weights: jnp.ndarray) -&gt; jnp.ndarray:\n    \"\"\"\n    Compute the effective sample size (ESS) from log importance weights.\n\n    The ESS measures the efficiency of importance sampling by estimating the\n    number of independent samples that would provide equivalent statistical\n    information. It quantifies particle degeneracy in SMC algorithms.\n\n    Mathematical Formulation:\n        Given N particles with normalized weights w\u2081, ..., w\u2099:\n\n        ESS = 1 / \u03a3\u1d62 w\u1d62\u00b2 = (\u03a3\u1d62 w\u1d62)\u00b2 / \u03a3\u1d62 w\u1d62\u00b2\n\n        Since \u03a3\u1d62 w\u1d62 = 1 for normalized weights:\n\n        ESS = 1 / \u03a3\u1d62 w\u1d62\u00b2\n\n    Interpretation:\n        - ESS = N: Perfect sampling (uniform weights)\n        - ESS = 1: Complete degeneracy (single particle has all weight)\n        - ESS/N: Efficiency ratio, often used to trigger resampling when &lt; 0.5\n\n    Connection to Importance Sampling:\n        The ESS approximates the variance inflation factor for importance\n        sampling estimates. For self-normalized importance sampling:\n\n        Var[\ud835\udd3c[f]] \u2248 (N/ESS) \u00d7 Var_\u03c0[f]\n\n        where \u03c0 is the target distribution.\n\n    Args:\n        log_weights: Array of unnormalized log importance weights of shape (N,)\n\n    Returns:\n        Effective sample size as a scalar in range [1, N]\n\n    References:\n        .. [1] Kong, A., Liu, J. S., &amp; Wong, W. H. (1994). \"Sequential imputations\n               and Bayesian missing data problems\". Journal of the American\n               Statistical Association, 89(425), 278-288.\n        .. [2] Liu, J. S. (2001). \"Monte Carlo strategies in scientific computing\".\n               Springer, Chapter 3.\n        .. [3] Doucet, A., de Freitas, N., &amp; Gordon, N. (2001). \"Sequential Monte\n               Carlo methods in practice\". Springer, Chapter 1.\n\n    Notes:\n        - Computed in log-space for numerical stability\n        - Input weights need not be normalized (handled internally)\n        - Common resampling threshold: ESS &lt; N/2 (Doucet et al., 2001)\n    \"\"\"\n    log_weights_normalized = log_weights - jax.scipy.special.logsumexp(log_weights)\n    weights_normalized = jnp.exp(log_weights_normalized)\n    return 1.0 / jnp.sum(weights_normalized**2)\n</code></pre>"},{"location":"reference/smc/#genjax.inference.smc.systematic_resample","title":"systematic_resample","text":"<pre><code>systematic_resample(log_weights: ndarray, n_samples: int) -&gt; jnp.ndarray\n</code></pre> <p>Systematic resampling from importance weights with minimal variance.</p> <p>Implements the systematic resampling algorithm (Kitagawa, 1996), which has lower variance than multinomial resampling while maintaining unbiasedness. This is the preferred resampling method for particle filters.</p> Mathematical Formulation <p>Given normalized weights w\u2081, ..., w\u2099 and cumulative sum C\u1d62 = \u03a3\u2c7c\u2264\u1d62 w\u2c7c:</p> <ol> <li>Draw U ~ Uniform(0, 1/M) where M is the output sample size</li> <li>For i = 1, ..., M:</li> <li>Set pointer position: u\u1d62 = (i-1)/M + U</li> <li>Select particle: I\u1d62 = min{j : C\u2c7c \u2265 u\u1d62}</li> </ol> Properties <ul> <li>Unbiased: \ud835\udd3c[N\u1d62] = M \u00d7 w\u1d62 where N\u1d62 is count of particle i</li> <li>Lower variance than multinomial: Var[N\u1d62] \u2264 M \u00d7 w\u1d62 \u00d7 (1 - w\u1d62)</li> <li>Deterministic given U: reduces Monte Carlo variance</li> <li>Preserves particle order (stratified structure)</li> </ul> <p>Time Complexity: O(N + M) using binary search Space Complexity: O(N) for cumulative weights</p> References <p>.. [1] Kitagawa, G. (1996). \"Monte Carlo filter and smoother for non-Gaussian        nonlinear state space models\". Journal of Computational and Graphical        Statistics, 5(1), 1-25. .. [2] Doucet, A., &amp; Johansen, A. M. (2009). \"A tutorial on particle filtering        and smoothing: Fifteen years later\". Handbook of Nonlinear Filtering,        12(656-704), 3. .. [3] Hol, J. D., Schon, T. B., &amp; Gustafsson, F. (2006). \"On resampling        algorithms for particle filters\". In IEEE Nonlinear Statistical Signal        Processing Workshop (pp. 79-82).</p> Notes <ul> <li>Systematic resampling is preferred over multinomial for most applications</li> <li>Maintains particle diversity better than multinomial resampling</li> <li>For theoretical analysis of resampling methods, see [3]</li> </ul> Source code in <code>src/genjax/inference/smc.py</code> <pre><code>def systematic_resample(log_weights: jnp.ndarray, n_samples: int) -&gt; jnp.ndarray:\n    \"\"\"\n    Systematic resampling from importance weights with minimal variance.\n\n    Implements the systematic resampling algorithm (Kitagawa, 1996), which has\n    lower variance than multinomial resampling while maintaining unbiasedness.\n    This is the preferred resampling method for particle filters.\n\n    Mathematical Formulation:\n        Given normalized weights w\u2081, ..., w\u2099 and cumulative sum C\u1d62 = \u03a3\u2c7c\u2264\u1d62 w\u2c7c:\n\n        1. Draw U ~ Uniform(0, 1/M) where M is the output sample size\n        2. For i = 1, ..., M:\n           - Set pointer position: u\u1d62 = (i-1)/M + U\n           - Select particle: I\u1d62 = min{j : C\u2c7c \u2265 u\u1d62}\n\n    Properties:\n        - Unbiased: \ud835\udd3c[N\u1d62] = M \u00d7 w\u1d62 where N\u1d62 is count of particle i\n        - Lower variance than multinomial: Var[N\u1d62] \u2264 M \u00d7 w\u1d62 \u00d7 (1 - w\u1d62)\n        - Deterministic given U: reduces Monte Carlo variance\n        - Preserves particle order (stratified structure)\n\n    Time Complexity: O(N + M) using binary search\n    Space Complexity: O(N) for cumulative weights\n\n    Args:\n        log_weights: Unnormalized log importance weights of shape (N,)\n        n_samples: Number of samples to draw (M)\n\n    Returns:\n        Array of particle indices of shape (M,) for resampling\n\n    References:\n        .. [1] Kitagawa, G. (1996). \"Monte Carlo filter and smoother for non-Gaussian\n               nonlinear state space models\". Journal of Computational and Graphical\n               Statistics, 5(1), 1-25.\n        .. [2] Doucet, A., &amp; Johansen, A. M. (2009). \"A tutorial on particle filtering\n               and smoothing: Fifteen years later\". Handbook of Nonlinear Filtering,\n               12(656-704), 3.\n        .. [3] Hol, J. D., Schon, T. B., &amp; Gustafsson, F. (2006). \"On resampling\n               algorithms for particle filters\". In IEEE Nonlinear Statistical Signal\n               Processing Workshop (pp. 79-82).\n\n    Notes:\n        - Systematic resampling is preferred over multinomial for most applications\n        - Maintains particle diversity better than multinomial resampling\n        - For theoretical analysis of resampling methods, see [3]\n    \"\"\"\n    log_weights_normalized = log_weights - jax.scipy.special.logsumexp(log_weights)\n    weights = jnp.exp(log_weights_normalized)\n\n    # Use uniform distribution for systematic resampling offset\n    u = uniform.sample(0.0, 1.0)\n    positions = (jnp.arange(n_samples) + u) / n_samples\n    cumsum = jnp.cumsum(weights)\n\n    indices = jnp.searchsorted(cumsum, positions)\n    return indices\n</code></pre>"},{"location":"reference/smc/#genjax.inference.smc.resample_vectorized_trace","title":"resample_vectorized_trace","text":"<pre><code>resample_vectorized_trace(trace: Trace[X, R], log_weights: ndarray, n_samples: int, method: str = 'categorical') -&gt; Trace[X, R]\n</code></pre> <p>Resample a vectorized trace using importance weights.</p> <p>Uses categorical or systematic sampling to select indices and jax.tree_util.tree_map to index into the Pytree leaves.</p> Source code in <code>src/genjax/inference/smc.py</code> <pre><code>def resample_vectorized_trace(\n    trace: Trace[X, R],\n    log_weights: jnp.ndarray,\n    n_samples: int,\n    method: str = \"categorical\",\n) -&gt; Trace[X, R]:\n    \"\"\"\n    Resample a vectorized trace using importance weights.\n\n    Uses categorical or systematic sampling to select indices and jax.tree_util.tree_map\n    to index into the Pytree leaves.\n\n    Args:\n        trace: Vectorized trace to resample\n        log_weights: Log importance weights\n        n_samples: Number of samples to draw\n        method: Resampling method - \"categorical\" or \"systematic\"\n\n    Returns:\n        Resampled vectorized trace\n    \"\"\"\n    if method == \"categorical\":\n        # Sample indices using categorical distribution\n        indices = categorical.sample(log_weights, sample_shape=(n_samples,))\n    elif method == \"systematic\":\n        # Use systematic resampling\n        indices = systematic_resample(log_weights, n_samples)\n    else:\n        raise ValueError(f\"Unknown resampling method: {method}\")\n\n    # Use tree_map to index into all leaves of the trace Pytree\n    def index_leaf(leaf):\n        # Index into the first dimension (batch dimension) of each leaf\n        return leaf[indices]\n\n    resampled_trace = jtu.tree_map(index_leaf, trace)\n    return resampled_trace\n</code></pre>"},{"location":"reference/smc/#genjax.inference.smc.init","title":"init","text":"<pre><code>init(target_gf: GFI[X, R], target_args: tuple, n_samples: Const[int], constraints: X, proposal_gf: GFI[X, Any] | None = None) -&gt; ParticleCollection\n</code></pre> <p>Initialize particle collection using importance sampling.</p> <p>Uses either the target's default internal proposal or a custom proposal. Proposals use signature (constraints, *target_args).</p> Source code in <code>src/genjax/inference/smc.py</code> <pre><code>def init(\n    target_gf: GFI[X, R],\n    target_args: tuple,\n    n_samples: Const[int],\n    constraints: X,\n    proposal_gf: GFI[X, Any] | None = None,\n) -&gt; ParticleCollection:\n    \"\"\"\n    Initialize particle collection using importance sampling.\n\n    Uses either the target's default internal proposal or a custom proposal.\n    Proposals use signature (constraints, *target_args).\n\n    Args:\n        target_gf: Target generative function (model)\n        target_args: Arguments for target generative function\n        n_samples: Number of importance samples to draw (static value)\n        constraints: Dictionary of constrained random choices\n        proposal_gf: Optional custom proposal generative function.\n                    If None, uses target's default internal proposal.\n\n    Returns:\n        ParticleCollection with traces, weights, and diagnostics\n    \"\"\"\n    if proposal_gf is None:\n        # Use default importance sampling with target's internal proposal\n        def _single_default_importance_sample(\n            target_gf: GFI[X, R],\n            target_args: tuple,\n            constraints: X,\n        ) -&gt; tuple[Trace[X, R], Weight]:\n            \"\"\"Single importance sampling step using target's default proposal.\"\"\"\n            # Use target's generate method with constraints\n            # This will use the target's internal proposal to fill in missing choices\n            target_trace, log_weight = target_gf.generate(constraints, *target_args)\n            return target_trace, log_weight\n\n        # Vectorize the single importance sampling step\n        vectorized_sample = modular_vmap(\n            _single_default_importance_sample,\n            in_axes=(None, None, None),\n            axis_size=n_samples.value,\n        )\n\n        # Run vectorized importance sampling\n        traces, log_weights = vectorized_sample(target_gf, target_args, constraints)\n    else:\n        # Use custom proposal importance sampling\n        def _single_importance_sample(\n            target_gf: GFI[X, R],\n            proposal_gf: GFI[X, Any],\n            target_args: tuple,\n            constraints: X,\n        ) -&gt; tuple[Trace[X, R], Weight]:\n            \"\"\"\n            Single importance sampling step using custom proposal.\n\n            Proposal uses signature (constraints, *target_args).\n            \"\"\"\n            # Sample from proposal using new signature\n            proposal_trace = proposal_gf.simulate(constraints, *target_args)\n            proposal_choices = proposal_trace.get_choices()\n\n            # Get proposal score: log(1/P_proposal)\n            proposal_score = proposal_trace.get_score()\n\n            # Merge proposal choices with constraints\n            merged_choices, _ = target_gf.merge(proposal_choices, constraints)\n\n            # Generate from target using merged choices\n            target_trace, target_weight = target_gf.generate(\n                merged_choices, *target_args\n            )\n\n            # Compute importance weight: P/Q\n            # target_weight is the weight from generate (density of model at merged choices)\n            # proposal_score is log(1/P_proposal)\n            # importance_weight = target_weight + proposal_score\n            log_weight = target_weight + proposal_score\n\n            return target_trace, log_weight\n\n        # Vectorize the single importance sampling step\n        vectorized_sample = modular_vmap(\n            _single_importance_sample,\n            in_axes=(None, None, None, None),\n            axis_size=n_samples.value,\n        )\n\n        # Run vectorized importance sampling\n        traces, log_weights = vectorized_sample(\n            target_gf, proposal_gf, target_args, constraints\n        )\n\n    return _create_particle_collection(\n        traces=traces,  # vectorized\n        log_weights=log_weights,\n        n_samples=const(n_samples.value),\n        log_marginal_estimate=jnp.array(0.0),\n    )\n</code></pre>"},{"location":"reference/smc/#genjax.inference.smc.change","title":"change","text":"<pre><code>change(particles: ParticleCollection, new_target_gf: GFI[X, R], new_target_args: tuple, choice_fn: Callable[[X], X]) -&gt; ParticleCollection\n</code></pre> <p>Change target move for particle collection.</p> <p>Translates particles from one model to another by: 1. Mapping each particle's choices using choice_fn 2. Using generate with the new model to get new weights 3. Accumulating importance weights</p> Choice Function Specification <p>CRITICAL: choice_fn must be a bijection on address space only.</p> <ul> <li>If X is a scalar type (e.g., float): Must be identity function</li> <li>If X is dict[str, Any]: May remap keys but CANNOT modify values</li> <li>Values must be preserved exactly to maintain probability density</li> </ul> <p>Valid Examples: - lambda x: x  (identity mapping) - lambda d: {\"new_key\": d[\"old_key\"]}  (key remapping) - lambda d: {\"mu\": d[\"mean\"], \"sigma\": d[\"std\"]}  (multiple key remap)</p> <p>Invalid Examples: - lambda x: x + 1  (modifies scalar values - breaks assumptions) - lambda d: {\"key\": d[\"key\"] * 2}  (modifies dict values - breaks assumptions)</p> Source code in <code>src/genjax/inference/smc.py</code> <pre><code>def change(\n    particles: ParticleCollection,\n    new_target_gf: GFI[X, R],\n    new_target_args: tuple,\n    choice_fn: Callable[[X], X],\n) -&gt; ParticleCollection:\n    \"\"\"\n    Change target move for particle collection.\n\n    Translates particles from one model to another by:\n    1. Mapping each particle's choices using choice_fn\n    2. Using generate with the new model to get new weights\n    3. Accumulating importance weights\n\n    Args:\n        particles: Current particle collection\n        new_target_gf: New target generative function\n        new_target_args: Arguments for new target\n        choice_fn: Bijective function mapping choices X -&gt; X\n\n    Choice Function Specification:\n        CRITICAL: choice_fn must be a bijection on address space only.\n\n        - If X is a scalar type (e.g., float): Must be identity function\n        - If X is dict[str, Any]: May remap keys but CANNOT modify values\n        - Values must be preserved exactly to maintain probability density\n\n        Valid Examples:\n        - lambda x: x  (identity mapping)\n        - lambda d: {\"new_key\": d[\"old_key\"]}  (key remapping)\n        - lambda d: {\"mu\": d[\"mean\"], \"sigma\": d[\"std\"]}  (multiple key remap)\n\n        Invalid Examples:\n        - lambda x: x + 1  (modifies scalar values - breaks assumptions)\n        - lambda d: {\"key\": d[\"key\"] * 2}  (modifies dict values - breaks assumptions)\n\n    Returns:\n        New ParticleCollection with translated particles\n    \"\"\"\n\n    def _single_change_target(\n        old_trace: Trace[X, R], old_log_weight: jnp.ndarray\n    ) -&gt; tuple[Trace[X, R], jnp.ndarray]:\n        # Map choices to new space\n        old_choices = old_trace.get_choices()\n        mapped_choices = choice_fn(old_choices)\n\n        # Generate with new model using mapped choices as constraints\n        new_trace, log_weight = new_target_gf.generate(mapped_choices, *new_target_args)\n\n        # Accumulate importance weight\n        new_log_weight = old_log_weight + log_weight\n\n        return new_trace, new_log_weight\n\n    # Vectorize across particles\n    vectorized_change = modular_vmap(\n        _single_change_target,\n        in_axes=(0, 0),\n        axis_size=particles.n_samples.value,\n    )\n\n    new_traces, new_log_weights = vectorized_change(\n        particles.traces, particles.log_weights\n    )\n\n    return _create_particle_collection(\n        traces=new_traces,\n        log_weights=new_log_weights,\n        n_samples=particles.n_samples,\n        log_marginal_estimate=particles.log_marginal_estimate,\n        # diagnostic_weights will be computed from new_log_weights in _create_particle_collection\n    )\n</code></pre>"},{"location":"reference/smc/#genjax.inference.smc.extend","title":"extend","text":"<pre><code>extend(particles: ParticleCollection, extended_target_gf: GFI[X, R], extended_target_args: Any, constraints: X, extension_proposal: GFI[X, Any] | None = None) -&gt; ParticleCollection\n</code></pre> <p>Extension move for particle collection.</p> <p>Extends each particle by generating from the extended target model: 1. Without extension proposal: Uses extended target's generate with constraints directly 2. With extension proposal: Samples extension, merges with constraints, then generates</p> <p>The extended target model is responsible for recognizing and incorporating existing particle state through its internal structure.</p> Source code in <code>src/genjax/inference/smc.py</code> <pre><code>def extend(\n    particles: ParticleCollection,\n    extended_target_gf: GFI[X, R],\n    extended_target_args: Any,  # Can be tuple or vectorized args\n    constraints: X,\n    extension_proposal: GFI[X, Any] | None = None,\n) -&gt; ParticleCollection:\n    \"\"\"\n    Extension move for particle collection.\n\n    Extends each particle by generating from the extended target model:\n    1. Without extension proposal: Uses extended target's generate with constraints directly\n    2. With extension proposal: Samples extension, merges with constraints, then generates\n\n    The extended target model is responsible for recognizing and incorporating\n    existing particle state through its internal structure.\n\n    Args:\n        particles: Current particle collection\n        extended_target_gf: Extended target generative function that recognizes particle state\n        extended_target_args: Arguments for extended target\n        constraints: Constraints on the new variables (e.g., observations at current timestep)\n        extension_proposal: Optional proposal for the extension. If None, uses extended target's internal proposal.\n\n    Returns:\n        New ParticleCollection with extended particles\n    \"\"\"\n\n    def _single_extension(\n        old_trace: Trace[X, R], old_log_weight: jnp.ndarray, particle_args: Any\n    ) -&gt; tuple[Trace[X, R], jnp.ndarray]:\n        # Convert particle_args to tuple if it's not already\n        if isinstance(particle_args, tuple):\n            args = particle_args\n        else:\n            args = (particle_args,)\n\n        if extension_proposal is None:\n            # Generate with extended target using constraints\n            new_trace, log_weight = extended_target_gf.generate(constraints, *args)\n\n            # Weight is just the target weight (no proposal correction needed)\n            new_log_weight = old_log_weight + log_weight\n        else:\n            # Use custom extension proposal\n            # Proposal gets: (obs, prev_particle_choices, *model_args)\n            old_choices = old_trace.get_choices()\n            extension_trace = extension_proposal.simulate(\n                constraints, old_choices, *args\n            )\n            extension_choices = extension_trace.get_choices()\n            proposal_score = extension_trace.get_score()\n\n            # Merge old choices, extension choices, and constraints\n            merged_choices, _ = extended_target_gf.merge(constraints, extension_choices)\n\n            # Generate with extended target\n            new_trace, log_weight = extended_target_gf.generate(merged_choices, *args)\n\n            # Importance weight: target_weight + proposal_score + old_weight\n            new_log_weight = old_log_weight + log_weight + proposal_score\n\n        return new_trace, new_log_weight\n\n    # Vectorize across particles\n    vectorized_extension = modular_vmap(\n        _single_extension,\n        in_axes=(0, 0, 0),  # Add axis for particle_args\n        axis_size=particles.n_samples.value,\n    )\n\n    new_traces, new_log_weights = vectorized_extension(\n        particles.traces, particles.log_weights, extended_target_args\n    )\n\n    return _create_particle_collection(\n        traces=new_traces,\n        log_weights=new_log_weights,\n        n_samples=particles.n_samples,\n        log_marginal_estimate=particles.log_marginal_estimate,\n        # diagnostic_weights will be computed from new_log_weights in _create_particle_collection\n    )\n</code></pre>"},{"location":"reference/smc/#genjax.inference.smc.rejuvenate","title":"rejuvenate","text":"<pre><code>rejuvenate(particles: ParticleCollection, mcmc_kernel: Callable[[Trace[X, R]], Trace[X, R]]) -&gt; ParticleCollection\n</code></pre> <p>Rejuvenate move for particle collection.</p> <p>Applies an MCMC kernel to each particle independently to improve particle diversity and reduce degeneracy. The importance weights and diagnostic weights remain unchanged due to detailed balance.</p> Mathematical Foundation <p>For an MCMC kernel satisfying detailed balance, the log incremental weight is 0:</p> <p>log_incremental_weight = log[p(x_new | args) / p(x_old | args)]                         + log[q(x_old | x_new) / q(x_new | x_old)]</p> <p>Where: - p(x_new | args) / p(x_old | args) is the model density ratio - q(x_old | x_new) / q(x_new | x_old) is the proposal density ratio</p> <p>Detailed balance ensures: p(x_old) * q(x_new | x_old) = p(x_new) * q(x_old | x_new)</p> <p>Therefore: p(x_new) / p(x_old) = q(x_new | x_old) / q(x_old | x_new)</p> <p>The model density ratio and proposal density ratio exactly cancel: log[p(x_new) / p(x_old)] + log[q(x_old | x_new) / q(x_new | x_old)] = 0</p> <p>This means the importance weight contribution from the MCMC move is 0, preserving the particle weights while improving sample diversity.</p> Source code in <code>src/genjax/inference/smc.py</code> <pre><code>def rejuvenate(\n    particles: ParticleCollection,\n    mcmc_kernel: Callable[[Trace[X, R]], Trace[X, R]],\n) -&gt; ParticleCollection:\n    \"\"\"\n    Rejuvenate move for particle collection.\n\n    Applies an MCMC kernel to each particle independently to improve\n    particle diversity and reduce degeneracy. The importance weights and\n    diagnostic weights remain unchanged due to detailed balance.\n\n    Mathematical Foundation:\n        For an MCMC kernel satisfying detailed balance, the log incremental weight is 0:\n\n        log_incremental_weight = log[p(x_new | args) / p(x_old | args)]\n                                + log[q(x_old | x_new) / q(x_new | x_old)]\n\n        Where:\n        - p(x_new | args) / p(x_old | args) is the model density ratio\n        - q(x_old | x_new) / q(x_new | x_old) is the proposal density ratio\n\n        Detailed balance ensures: p(x_old) * q(x_new | x_old) = p(x_new) * q(x_old | x_new)\n\n        Therefore: p(x_new) / p(x_old) = q(x_new | x_old) / q(x_old | x_new)\n\n        The model density ratio and proposal density ratio exactly cancel:\n        log[p(x_new) / p(x_old)] + log[q(x_old | x_new) / q(x_new | x_old)] = 0\n\n        This means the importance weight contribution from the MCMC move is 0,\n        preserving the particle weights while improving sample diversity.\n\n    Args:\n        particles: Current particle collection\n        mcmc_kernel: MCMC kernel function that takes a trace and returns\n                    a new trace. Should be compatible with kernels from mcmc.py like mh.\n\n    Returns:\n        New ParticleCollection with rejuvenated particles\n    \"\"\"\n\n    def _single_rejuvenate(\n        old_trace: Trace[X, R], old_log_weight: jnp.ndarray\n    ) -&gt; tuple[Trace[X, R], jnp.ndarray]:\n        # Apply MCMC kernel\n        new_trace = mcmc_kernel(old_trace)\n\n        # Weights remain unchanged for MCMC moves (detailed balance)\n        # Log incremental weight = 0 because model density ratio cancels with proposal density ratio\n        return new_trace, old_log_weight\n\n    # Vectorize across particles\n    vectorized_rejuvenate = modular_vmap(\n        _single_rejuvenate,\n        in_axes=(0, 0),\n        axis_size=particles.n_samples.value,\n    )\n\n    new_traces, new_log_weights = vectorized_rejuvenate(\n        particles.traces, particles.log_weights\n    )\n\n    return _create_particle_collection(\n        traces=new_traces,\n        log_weights=new_log_weights,\n        n_samples=particles.n_samples,\n        log_marginal_estimate=particles.log_marginal_estimate,\n        diagnostic_weights=particles.diagnostic_weights,  # Propagate diagnostic weights unchanged\n    )\n</code></pre>"},{"location":"reference/smc/#genjax.inference.smc.resample","title":"resample","text":"<pre><code>resample(particles: ParticleCollection, method: str = 'categorical') -&gt; ParticleCollection\n</code></pre> <p>Resample particle collection to combat degeneracy.</p> <p>Computes log normalized weights for diagnostics before resampling. After resampling, weights are reset to uniform (zero in log space) and the marginal likelihood estimate is updated to include the average weight before resampling.</p> Source code in <code>src/genjax/inference/smc.py</code> <pre><code>def resample(\n    particles: ParticleCollection,\n    method: str = \"categorical\",\n) -&gt; ParticleCollection:\n    \"\"\"\n    Resample particle collection to combat degeneracy.\n\n    Computes log normalized weights for diagnostics before resampling.\n    After resampling, weights are reset to uniform (zero in log space)\n    and the marginal likelihood estimate is updated to include the\n    average weight before resampling.\n\n    Args:\n        particles: Current particle collection\n        method: Resampling method - \"categorical\" or \"systematic\"\n\n    Returns:\n        New ParticleCollection with resampled particles and updated marginal estimate\n    \"\"\"\n    # Compute log normalized weights before resampling for diagnostics\n    log_normalized_weights = particles.log_weights - jax.scipy.special.logsumexp(\n        particles.log_weights\n    )\n\n    # Compute current marginal contribution before resampling\n    current_marginal = jax.scipy.special.logsumexp(particles.log_weights) - jnp.log(\n        particles.n_samples.value\n    )\n\n    # Update accumulated marginal estimate\n    new_log_marginal_estimate = particles.log_marginal_estimate + current_marginal\n\n    # Resample traces using existing function\n    resampled_traces = resample_vectorized_trace(\n        particles.traces,\n        particles.log_weights,\n        particles.n_samples.value,\n        method=method,\n    )\n\n    # Reset weights to uniform (zero in log space)\n    uniform_log_weights = jnp.zeros(particles.n_samples.value)\n\n    return _create_particle_collection(\n        traces=resampled_traces,\n        log_weights=uniform_log_weights,\n        n_samples=particles.n_samples,\n        log_marginal_estimate=new_log_marginal_estimate,\n        diagnostic_weights=log_normalized_weights,  # Store pre-resampling normalized weights\n    )\n</code></pre>"},{"location":"reference/smc/#genjax.inference.smc.rejuvenation_smc","title":"rejuvenation_smc","text":"<pre><code>rejuvenation_smc(model: GFI[X, R], transition_proposal: GFI[X, Any] | None = None, mcmc_kernel: Const[Callable[[Trace[X, R]], Trace[X, R]]] | None = None, observations: X | None = None, initial_model_args: tuple | None = None, n_particles: Const[int] = const(1000), return_all_particles: Const[bool] = const(False), n_rejuvenation_moves: Const[int] = const(1)) -&gt; ParticleCollection\n</code></pre> <p>Complete SMC algorithm with rejuvenation using jax.lax.scan.</p> <p>Implements sequential Monte Carlo with particle extension, resampling, and MCMC rejuvenation. Uses a single model with feedback loop where the return value becomes the next timestep's arguments, creating sequential dependencies.</p> Note on Return Value <p>This function returns only the FINAL ParticleCollection after processing all observations. Intermediate timesteps are computed but not returned. If you need all timesteps, you can modify the return statement to:</p> <pre><code>final_particles, all_particles = jax.lax.scan(smc_step, particles, remaining_obs)\nreturn all_particles  # Returns vectorized ParticleCollection with time dimension\n</code></pre> <p>The all_particles object would have an additional leading time dimension in all its fields (traces, log_weights, etc.), allowing access to the full particle trajectory across all timesteps.</p> Source code in <code>src/genjax/inference/smc.py</code> <pre><code>def rejuvenation_smc(\n    model: GFI[X, R],\n    transition_proposal: GFI[X, Any] | None = None,\n    mcmc_kernel: Const[Callable[[Trace[X, R]], Trace[X, R]]] | None = None,\n    observations: X | None = None,\n    initial_model_args: tuple | None = None,\n    n_particles: Const[int] = const(1000),\n    return_all_particles: Const[bool] = const(False),\n    n_rejuvenation_moves: Const[int] = const(1),\n) -&gt; ParticleCollection:\n    \"\"\"\n    Complete SMC algorithm with rejuvenation using jax.lax.scan.\n\n    Implements sequential Monte Carlo with particle extension, resampling,\n    and MCMC rejuvenation. Uses a single model with feedback loop where\n    the return value becomes the next timestep's arguments, creating\n    sequential dependencies.\n\n\n    Note on Return Value:\n        This function returns only the FINAL ParticleCollection after processing\n        all observations. Intermediate timesteps are computed but not returned.\n        If you need all timesteps, you can modify the return statement to:\n\n        ```python\n        final_particles, all_particles = jax.lax.scan(smc_step, particles, remaining_obs)\n        return all_particles  # Returns vectorized ParticleCollection with time dimension\n        ```\n\n        The all_particles object would have an additional leading time dimension\n        in all its fields (traces, log_weights, etc.), allowing access to the\n        full particle trajectory across all timesteps.\n\n    Args:\n        model: Single generative function where return value feeds into next timestep\n        transition_proposal: Optional proposal for extending particles at each timestep.\n                           If None, uses the model's internal proposal. (default: None)\n        mcmc_kernel: Optional MCMC kernel for particle rejuvenation (wrapped in Const).\n                    If None, no rejuvenation moves are performed. (default: None)\n        observations: Sequence of observations (can be Pytree structure)\n        initial_model_args: Arguments for the first timestep\n        n_particles: Number of particles to maintain (default: const(1000))\n        return_all_particles: If True, returns all particles across time (default: const(False))\n        n_rejuvenation_moves: Number of MCMC rejuvenation moves per timestep (default: const(1))\n\n    Returns:\n        If return_all_particles=False: Final ParticleCollection (no time dimension)\n        If return_all_particles=True: ParticleCollection with leading time dimension (T, ...)\n    \"\"\"\n    # Extract first observation using tree_map (handles Pytree structure)\n    first_obs = jtu.tree_map(lambda x: x[0], observations)\n\n    # Initialize with first observation using the single model\n    particles = init(model, initial_model_args, n_particles, first_obs)\n\n    # Resample initial particles if needed\n    ess = particles.effective_sample_size()\n    particles = jax.lax.cond(\n        ess &lt; n_particles.value // 2,\n        lambda p: resample(p),\n        lambda p: p,\n        particles,\n    )\n\n    # Apply initial rejuvenation moves (only if mcmc_kernel is provided)\n    if mcmc_kernel is not None:\n\n        def rejuvenation_step(particles, _):\n            \"\"\"Single rejuvenation move.\"\"\"\n            return rejuvenate(particles, mcmc_kernel.value), None\n\n        # Apply n_rejuvenation_moves steps\n        particles, _ = jax.lax.scan(\n            rejuvenation_step, particles, jnp.arange(n_rejuvenation_moves.value)\n        )\n\n    def smc_step(particles, obs):\n        # Extract return values from current particles to use as next model args\n        # Get vectorized return values from all particles\n        current_retvals = particles.traces.get_retval()\n\n        # Extend particles with new observation constraints\n        # Use current return values as the model arguments for the next step\n        particles = extend(\n            particles,\n            model,\n            current_retvals,  # Feed return values as next model args\n            obs,\n            extension_proposal=transition_proposal,  # None is allowed - uses model's internal proposal\n        )\n\n        # Resample if needed\n        ess = particles.effective_sample_size()\n        particles = jax.lax.cond(\n            ess &lt; n_particles.value // 2,\n            lambda p: resample(p),\n            lambda p: p,\n            particles,\n        )\n\n        # Multiple rejuvenation moves (only if mcmc_kernel is provided)\n        if mcmc_kernel is not None:\n\n            def rejuvenation_step(particles, _):\n                \"\"\"Single rejuvenation move.\"\"\"\n                return rejuvenate(particles, mcmc_kernel.value), None\n\n            # Apply n_rejuvenation_moves steps\n            particles, _ = jax.lax.scan(\n                rejuvenation_step, particles, jnp.arange(n_rejuvenation_moves.value)\n            )\n\n        return particles, particles  # (carry, output)\n\n    # Sequential updates using scan over remaining observations\n    # Slice remaining observations using tree_map (handles Pytree structure)\n    remaining_obs = jtu.tree_map(lambda x: x[1:], observations)\n\n    final_particles, all_particles = jax.lax.scan(smc_step, particles, remaining_obs)\n\n    if return_all_particles.value:\n        # Prepend initial particles to create complete sequence\n        # all_particles has shape (T-1, ...) from scan over remaining_obs\n        # We need to add the initial particles to get shape (T, ...)\n        return jtu.tree_map(\n            lambda init, rest: jnp.concatenate([init[None, ...], rest], axis=0),\n            particles,\n            all_particles,\n        )\n    else:\n        return final_particles\n</code></pre>"},{"location":"reference/smc/#genjax.inference.smc.init_csmc","title":"init_csmc","text":"<pre><code>init_csmc(target_gf: GFI[X, R], target_args: tuple, n_samples: Const[int], constraints: X, retained_choices: X, proposal_gf: GFI[X, Any] | None = None) -&gt; ParticleCollection\n</code></pre> <p>Initialize particle collection for conditional SMC with retained particle.</p> <p>Simple approach: run regular init and manually override particle 0.</p> Source code in <code>src/genjax/inference/smc.py</code> <pre><code>def init_csmc(\n    target_gf: GFI[X, R],\n    target_args: tuple,\n    n_samples: Const[int],\n    constraints: X,\n    retained_choices: X,\n    proposal_gf: GFI[X, Any] | None = None,\n) -&gt; ParticleCollection:\n    \"\"\"\n    Initialize particle collection for conditional SMC with retained particle.\n\n    Simple approach: run regular init and manually override particle 0.\n\n    Args:\n        target_gf: Target generative function (model)\n        target_args: Arguments for target generative function\n        n_samples: Number of importance samples to draw (static value)\n        constraints: Dictionary of constrained random choices\n        retained_choices: Choices for the retained particle (one particle fixed)\n        proposal_gf: Optional custom proposal generative function\n\n    Returns:\n        ParticleCollection where particle 0 matches retained_choices exactly\n    \"\"\"\n    if n_samples.value &lt; 1:\n        raise ValueError(\"n_samples must be at least 1 for conditional SMC\")\n\n    # Run regular init to get the particle structure\n    particles = init(\n        target_gf=target_gf,\n        target_args=target_args,\n        n_samples=n_samples,\n        constraints=constraints,\n        proposal_gf=proposal_gf,\n    )\n\n    # Override the choices in particle 0 with retained choices\n    # This is a simplified approach - we manually set the choice values\n    current_choices = particles.traces.get_choices()\n\n    # Create a function to override specific keys\n    def override_with_retained(choices_dict):\n        # Make a copy and override keys that exist in retained_choices\n        new_dict = {}\n        for key, value in choices_dict.items():\n            if key in retained_choices:\n                # Set index 0 to the retained value\n                new_dict[key] = value.at[0].set(retained_choices[key])\n            else:\n                new_dict[key] = value\n        return new_dict\n\n    # Apply the override\n    new_choices_dict = override_with_retained(current_choices)\n\n    # Assess the retained choices to get the correct weight\n    retained_log_density, _ = target_gf.assess(retained_choices, *target_args)\n\n    # Set particle 0's weight to match the retained choice assessment\n    new_log_weights = particles.log_weights.at[0].set(retained_log_density)\n\n    # For now, return the particles with updated weight\n    # The choice override would require rebuilding the trace, which is complex\n    # This simplified version just ensures the weight is correct\n    return ParticleCollection(\n        traces=particles.traces,\n        log_weights=new_log_weights,\n        diagnostic_weights=particles.diagnostic_weights,\n        n_samples=particles.n_samples,\n        log_marginal_estimate=particles.log_marginal_estimate,\n    )\n</code></pre>"},{"location":"reference/smc/#genjax.inference.smc.extend_csmc","title":"extend_csmc","text":"<pre><code>extend_csmc(particles: ParticleCollection, extended_target_gf: GFI[X, R], extended_target_args: Any, constraints: X, retained_choices: X, extension_proposal: GFI[X, Any] | None = None) -&gt; ParticleCollection\n</code></pre> <p>Extension move for conditional SMC with retained particle.</p> <p>Like extend() but ensures particle 0 follows retained trajectory.</p> Source code in <code>src/genjax/inference/smc.py</code> <pre><code>def extend_csmc(\n    particles: ParticleCollection,\n    extended_target_gf: GFI[X, R],\n    extended_target_args: Any,\n    constraints: X,\n    retained_choices: X,\n    extension_proposal: GFI[X, Any] | None = None,\n) -&gt; ParticleCollection:\n    \"\"\"\n    Extension move for conditional SMC with retained particle.\n\n    Like extend() but ensures particle 0 follows retained trajectory.\n\n    Args:\n        particles: Current particle collection\n        extended_target_gf: Extended target generative function\n        extended_target_args: Arguments for extended target\n        constraints: Constraints on the new variables\n        retained_choices: Choices for retained particle at this timestep\n        extension_proposal: Optional proposal for the extension\n\n    Returns:\n        New ParticleCollection where particle 0 matches retained_choices\n    \"\"\"\n    def _single_extension_csmc(\n        old_trace: Trace[X, R], old_log_weight: jnp.ndarray, particle_args: Any, is_retained: bool\n    ) -&gt; tuple[Trace[X, R], jnp.ndarray]:\n        # Convert particle_args to tuple if needed\n        if isinstance(particle_args, tuple):\n            args = particle_args\n        else:\n            args = (particle_args,)\n\n        # For retained particle (index 0), use retained_choices exactly\n        def retained_extension():\n            # Assess retained choices with extended model\n            log_density, retval = extended_target_gf.assess(retained_choices, *args)\n\n            from genjax.core import Tr\n            new_trace = Tr(\n                _gen_fn=extended_target_gf,\n                _args=(args, {}),\n                _choices=retained_choices,\n                _retval=retval,\n                _score=-log_density\n            )\n            # Weight accumulation: old weight + log density\n            new_log_weight = old_log_weight + log_density\n            return new_trace, new_log_weight\n\n        # For regular particles, use standard extension\n        def regular_extension():\n            if extension_proposal is None:\n                # Generate with extended target using constraints\n                new_trace, log_weight = extended_target_gf.generate(constraints, *args)\n                new_log_weight = old_log_weight + log_weight\n            else:\n                # Use custom extension proposal\n                old_choices = old_trace.get_choices()\n                extension_trace = extension_proposal.simulate(constraints, old_choices, *args)\n                extension_choices = extension_trace.get_choices()\n                proposal_score = extension_trace.get_score()\n\n                # Merge and generate\n                merged_choices, _ = extended_target_gf.merge(constraints, extension_choices)\n                new_trace, log_weight = extended_target_gf.generate(merged_choices, *args)\n                new_log_weight = old_log_weight + log_weight + proposal_score\n\n            return new_trace, new_log_weight\n\n        # Choose extension type based on whether this is the retained particle\n        return jax.lax.cond(\n            is_retained,\n            retained_extension,\n            regular_extension\n        )\n\n    # Create is_retained flags: True for index 0, False for others\n    is_retained_flags = jnp.arange(particles.n_samples.value) == 0\n\n    # Vectorize across particles with is_retained flag\n    vectorized_extension = modular_vmap(\n        _single_extension_csmc,\n        in_axes=(0, 0, 0, 0),  # Add axis for is_retained\n        axis_size=particles.n_samples.value,\n    )\n\n    new_traces, new_log_weights = vectorized_extension(\n        particles.traces, particles.log_weights, extended_target_args, is_retained_flags\n    )\n\n    return _create_particle_collection(\n        traces=new_traces,\n        log_weights=new_log_weights,\n        n_samples=particles.n_samples,\n        log_marginal_estimate=particles.log_marginal_estimate,\n    )\n</code></pre>"},{"location":"reference/smc/#core-functions","title":"Core Functions","text":""},{"location":"reference/smc/#importance_sampling","title":"importance_sampling","text":"<p>Basic importance sampling with multiple particles.</p>"},{"location":"reference/smc/#particle_filter","title":"particle_filter","text":"<p>Sequential Monte Carlo for state-space models.</p>"},{"location":"reference/smc/#rejuvenation_smc","title":"rejuvenation_smc","text":"<p>SMC with MCMC rejuvenation steps for better particle diversity.</p>"},{"location":"reference/smc/#usage-examples","title":"Usage Examples","text":""},{"location":"reference/smc/#importance-sampling","title":"Importance Sampling","text":"<pre><code>from genjax.inference.smc import importance_sampling\n\n# Run with 1000 particles\nkeys = jax.random.split(key, 1000)\ntraces = jax.vmap(lambda k: model.generate(k, constraints, args))(keys)\n\n# Extract weights\nlog_weights = traces.score\nweights = jax.nn.softmax(log_weights)\n\n# Weighted posterior mean\nposterior_mean = jnp.sum(weights * traces[\"parameter\"])\n</code></pre>"},{"location":"reference/smc/#particle-filter","title":"Particle Filter","text":"<pre><code>from genjax.inference.smc import particle_filter\n\n# For sequential data\n@gen\ndef transition(prev_state, t):\n    return distributions.normal(prev_state, 0.1) @ f\"state_{t}\"\n\n@gen\ndef observation(state, t):\n    return distributions.normal(state, 0.5) @ f\"obs_{t}\"\n\n# Run particle filter\nparticles = particle_filter(\n    initial_model,\n    transition,\n    observation,\n    observations,\n    n_particles=100,\n    key=key\n)\n</code></pre>"},{"location":"reference/smc/#smc-with-rejuvenation","title":"SMC with Rejuvenation","text":"<pre><code>from genjax.inference.smc import rejuvenation_smc\n\n# SMC with optional MCMC moves\nresult = rejuvenation_smc(\n    model,\n    observations,\n    n_particles=100,\n    n_mcmc_steps=5,  # Optional: rejuvenation steps\n    key=key\n)\n</code></pre>"},{"location":"reference/smc/#best-practices","title":"Best Practices","text":"<ol> <li>Particle Count: Use enough particles (typically 100-10000)</li> <li>Resampling: Monitor effective sample size for resampling</li> <li>Proposal Design: Use good proposal distributions</li> <li>Rejuvenation: Add MCMC steps to maintain diversity</li> </ol>"}]}